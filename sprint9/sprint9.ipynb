{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題1 - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "(28, 28)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0].shape)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,784)\n",
    "X_test = X_test.reshape(-1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'label : 5')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.33823529 -105.27941176 -105.27941176\n",
      "  -105.27941176 -104.85588235 -104.81666667 -104.66372549 -105.24803922\n",
      "  -104.69901961 -104.35       -104.38137255 -104.85196078 -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.23235294 -105.20882353\n",
      "  -104.98137255 -104.74607843 -104.68333333 -104.35784314 -104.35784314\n",
      "  -104.35784314 -104.35784314 -104.35784314 -104.46764706 -104.6754902\n",
      "  -104.35784314 -104.40098039 -104.58529412 -105.09901961 -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.15784314 -104.41666667 -104.35784314\n",
      "  -104.35784314 -104.35784314 -104.35784314 -104.35784314 -104.35784314\n",
      "  -104.35784314 -104.35784314 -104.36568627 -104.98529412 -105.02843137\n",
      "  -105.02843137 -105.13039216 -105.19705882 -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.27941176 -104.49117647 -104.35784314\n",
      "  -104.35784314 -104.35784314 -104.35784314 -104.35784314 -104.57352941\n",
      "  -104.63627451 -104.38137255 -104.40490196 -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.03627451 -104.73823529\n",
      "  -104.93039216 -104.35784314 -104.35784314 -104.54607843 -105.30686275\n",
      "  -105.35       -105.18137255 -104.74607843 -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.29509804\n",
      "  -105.34607843 -104.74607843 -104.35784314 -104.99705882 -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -104.80490196 -104.35784314 -104.60490196 -105.34215686\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.30686275 -104.60490196 -104.35784314 -105.0754902\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.2127451  -104.40490196 -104.46764706\n",
      "  -104.72254902 -104.92647059 -105.34607843 -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.03235294 -104.40882353\n",
      "  -104.35784314 -104.35784314 -104.88333333 -105.25196078 -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.17352941\n",
      "  -104.62058824 -104.35784314 -104.35784314 -104.76176471 -105.24411765\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.2872549  -104.98529412 -104.36176471 -104.35784314 -104.61666667\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -104.37352941 -104.35784314 -104.37352941\n",
      "  -105.09901961 -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.16960784\n",
      "  -104.84019608 -104.63235294 -104.35784314 -104.35784314 -104.53823529\n",
      "  -105.34215686 -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.19705882 -104.76960784 -104.45196078\n",
      "  -104.35784314 -104.35784314 -104.35784314 -104.36960784 -104.63627451\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.25588235 -104.90294118 -104.48333333 -104.35784314 -104.35784314\n",
      "  -104.35784314 -104.35784314 -104.56176471 -105.04411765 -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.25980392 -105.09117647\n",
      "  -104.51470588 -104.35784314 -104.35784314 -104.35784314 -104.35784314\n",
      "  -104.57352941 -105.03235294 -105.34215686 -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.27941176 -104.67941176 -104.49117647 -104.35784314\n",
      "  -104.35784314 -104.35784314 -104.35784314 -104.58529412 -105.03627451\n",
      "  -105.31470588 -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.13431373\n",
      "  -104.6754902  -104.46372549 -104.35784314 -104.35784314 -104.35784314\n",
      "  -104.35784314 -104.39313725 -104.82843137 -105.30686275 -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -104.81666667\n",
      "  -104.35784314 -104.35784314 -104.35784314 -104.51862745 -104.82058824\n",
      "  -104.83235294 -105.2872549  -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]\n",
      " [-105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35       -105.35       -105.35\n",
      "  -105.35       -105.35       -105.35      ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "image = image.astype(np.float) # float型に変換\n",
    "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "print(image) # 値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    def __init__(self, X, y, batch_size=20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0] / self.batch_size).astype(np.int)\n",
    "        #self.stopは作成するバッチサイズ数。１エポック分作成する\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    #指定したバッチ番号を取ってきてくれる\n",
    "    def __getitem__(self, item):\n",
    "        p0 = item * self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0 : p1], self._y[p0 : p1]\n",
    "\n",
    "    \n",
    "    \n",
    "    #batchカウンターを初期化する\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    \n",
    "    #batchを前から一つずつ取ってくる\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter * self.batch_size\n",
    "        p1 = self._counter * self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0 : p1], self._y[p0 : p1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float32\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# enc = OneHotEncoder()\n",
    "# y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=10)\n",
    "print(y_train.shape)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64\n",
    "print(type(y_train_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier:\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose = True):\n",
    "        self.lr = 0.01\n",
    "        self.loss_list = []\n",
    "        self.epoch_loss_list = []\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = 20\n",
    "        self.n_features = 784\n",
    "        self.n_nodes1 = 400\n",
    "        self.n_nodes2 = 200\n",
    "        self.n_output = 10\n",
    "        self.sigma = 0.01\n",
    "        self.W1 = np.random.randn(self.n_features,\n",
    "                                               self.n_nodes1) / np.sqrt(self.n_features)\n",
    "        self.W1_list = []\n",
    "        #print('初期値W1:', self.W1)\n",
    "        self.b1 = np.random.randn(self.n_nodes1,) / np.sqrt(self.n_features)\n",
    "        self.W2 = self.sigma * np.random.randn(self.n_nodes1,\n",
    "                                               self.n_nodes2) / np.sqrt(self.n_nodes1)\n",
    "        self.W2_list = []\n",
    "        #print('初期値W2:', self.W2)\n",
    "        self.b2 = np.random.randn(self.n_nodes2,) / np.sqrt(self.n_nodes1)\n",
    "        self.W3 = self.sigma * np.random.randn(self.n_nodes2, \n",
    "                                               self.n_output) / np.sqrt(self.n_nodes2)\n",
    "        self.W3_list = []\n",
    "        #print('初期値W3:', self.W3)\n",
    "        self.b3 = np.random.randn(self.n_output,) / np.sqrt(self.n_nodes2)\n",
    "        \n",
    "        self.b1_list = []\n",
    "        \n",
    "        \n",
    "        self.a1 = None\n",
    "        self.z1 = None\n",
    "        self.a2 = None\n",
    "        self.z2 = None\n",
    "        self.a3 = None\n",
    "        self.z3 = None\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.dW1 = np.zeros_like(self.W1)\n",
    "        self.dW1_list = []\n",
    "        self.epoch_dW1_list = []\n",
    "        self.db1 = np.zeros_like(self.b1)\n",
    "        self.dW2 = np.zeros_like(self.W2)\n",
    "        self.db2 = np.zeros_like(self.b2)\n",
    "        self.dW3 = np.zeros_like(self.W3)\n",
    "        self.db3 = np.zeros_like(self.b3)\n",
    "    \n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        print('====fit処理を実行します。====')\n",
    "        \n",
    "        self.epochs = 20\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            print('************' + str(i+1) + '回目エポック**************')\n",
    "            \n",
    "        \n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=20)\n",
    "            count = 1\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "\n",
    "                if self.verbose:\n",
    "#                     print(mini_y_train.shape)\n",
    "\n",
    "#                     print('mini_X_trainのタイプ：', type(mini_X_train))\n",
    "#                     print('mini_y_trainのタイプ：', type(mini_y_train))\n",
    "                #verboseをTrueにした際は学習過程などを出力する\n",
    "#                     print('-------' + str(count) + '回目の処理----------')\n",
    "\n",
    "\n",
    "#                     print('--------self.lossを実行します---------')\n",
    "                    z3,loss = self.loss(mini_X_train, mini_y_train)\n",
    "#                     print('-------self.lossの実行を終了します。中身;loss: {}, z3: {} --------------'.format(loss, z3[:5,:]))\n",
    "#                     print('lossの形状：',loss.shape)\n",
    "                    self.loss_list.append(loss)\n",
    "#                     print('--------backward処理を実行します---------')\n",
    "                    self.backward(mini_X_train, mini_y_train, self.z3)\n",
    "#                     print('--------backward処理の実行を終了します---------')\n",
    "\n",
    "#                     print('------パラメータの更新処理を実行します------')\n",
    "\n",
    "                    self.W1 -= self.lr * self.dW1\n",
    "                    self.b1 -= self.lr * self.db1\n",
    "                    self.b1_list.append(self.b1)\n",
    "                    self.W2 -= self.lr * self.dW2\n",
    "                    self.b2 -= self.lr * self.db2\n",
    "                    self.W3 -= self.lr * self.dW3\n",
    "                    self.b3 -= self.lr * self.db3\n",
    "\n",
    "#                     print('------パラメータの更新処理の実行を終了します------')\n",
    "                    count += 1\n",
    "                    \n",
    "             \n",
    "                else:\n",
    "\n",
    "                    z3,y_pred = self.loss(mini_X_train, mini_y_train)\n",
    "#                     print('lossの形状：',loss.shape)\n",
    "                    self.loss_list.append(loss)\n",
    "                    self.backward(mini_X_train, mini_y_train, z3)\n",
    "\n",
    "\n",
    "\n",
    "                    self.W1 -= self.lr * self.dW1\n",
    "                    self.b1 -= self.lr * self.db1\n",
    "                    self.W2 -= self.lr * self.dW2\n",
    "                    self.b2 -= self.lr * self.db2\n",
    "                    self.W3 -= self.lr * self.dW3\n",
    "                    self.b3 -= self.lr * self.db3\n",
    "                    count += 1\n",
    "                    \n",
    "            self.epoch_loss_list.append(self.loss_list[-1])\n",
    "            #self.epoch_dW1_list.append(self.dW1_list[-1][0,0])\n",
    "            self.W1_list.append(self.W1)\n",
    "            self.W2_list.append(self.W2)\n",
    "            self.W3_list.append(self.W3)\n",
    "            print('loss: {}'.format(self.loss_list[-1]))\n",
    "            self.loss_list = []\n",
    "            self.dW1_list = []\n",
    "\n",
    "#             \"\"\"\n",
    "#             ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "#             Parameters\n",
    "#             ----------\n",
    "#             X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#                 訓練用データの特徴量\n",
    "#             y : 次の形のndarray, shape (n_samples, )\n",
    "#                 訓練用データの正解値\n",
    "#             X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "#                 検証用データの特徴量\n",
    "#             y_val : 次の形のndarray, shape (n_samples, )\n",
    "#                 検証用データの正解値\n",
    "#             \"\"\"\n",
    "        \n",
    "    def Sigmoid(self, y):\n",
    "        \n",
    "        #print('sigmoidの通す値：', y[:2,:3])\n",
    "        z = 1 / (1 + np.exp(-y))\n",
    "        #print('zの値：', z[:5,:5])\n",
    "        return z\n",
    "    \n",
    "#     def Softmax(self, a):\n",
    "        \n",
    "#         C = np.max(a, axis=1).reshape(-1,1)\n",
    "#         a_exp = np.exp(a - C)\n",
    "#         #print('a_expの形状：', a_exp.shape)\n",
    "#         a_sum = np.sum(a_exp,axis=1).reshape(-1,1)\n",
    "#         #print('a_sumの形状：', a_sum.shape)\n",
    "#         z = a_exp / a_sum\n",
    "#         print('z3の値：', z[:2,:5])\n",
    "#         print('zsumの値：', np.sum(z[0,:]))\n",
    "#         return z\n",
    "\n",
    "    def Softmax(self, x):\n",
    "        if x.ndim == 2:\n",
    "            #print('xの値：', x[:2,:5])\n",
    "            x = x.T\n",
    "            x = x - np.max(x, axis=0)\n",
    "            y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "            z3 = y.T\n",
    "            #print('z3の値：', z3[:2,:5])\n",
    "            return z3\n",
    "        x = x - np.max(x)   # オーバーフロー対策\n",
    "        z3 = np.exp(x) / np.sum(np.exp(x))\n",
    "        #print('z3の値：', z3[:2,:5])\n",
    "        return z3\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.a1 = np.dot(X, self.W1) + self.b1\n",
    "        #print('a1の中身：', self.a1[:3,:3])\n",
    "        self.z1 = self.Sigmoid(self.a1)\n",
    "        #print('z1の中身：', self.z1[:3,:3])\n",
    "        self.a2 = np.dot(self.z1, self.W2) + self.b2\n",
    "        #print('a2の中身：', self.a2[:3,:3])\n",
    "        self.z2 = self.Sigmoid(self.a2)\n",
    "        #print('z2の中身：', self.z2[:3,:3])\n",
    "        self.a3 = np.dot(self.z2, self.W3) + self.b3\n",
    "        #print('a3の中身：', self.a3[:3,:3])\n",
    "        self.z3 = self.Softmax(self.a3)\n",
    "        #print('z3の中身：', self.z3[:3,:3])\n",
    "        return self.z3\n",
    "    \n",
    "    \n",
    "    def backward(self, X, y, y_pred):\n",
    "        \n",
    "#         print('y_predのタイプ：',type(y_pred))\n",
    "#         print('yのタイプ：',type(y))\n",
    "#         print('Xのタイプ：', type(X))\n",
    "        #print('yの中身:', y[:3,:])\n",
    "        #print('y_predの中身：', y_pred[:3,:])\n",
    "        da3 = self.backprop_from_SoftmaxWithLoss(y, y_pred)\n",
    "        #print('da3の中身：', da3[:3,:])\n",
    "        #print('da3のタイプ：', type(da3))\n",
    "        dz2,self.dW3,self.db3 = self.backprop_Mutmul_layer(self.z2, self.W3, self.b3, da3)\n",
    "        #print('dz2の中身：', dz2[:3,:])\n",
    "#         print('dz2のタイプ：', type(dz2))\n",
    "        da2 = self.backprop_Sigmoid_layer(self.z2, dz2)#第一→全結合の値。\n",
    "        #print('da2の中身：', da2[:3,:])\n",
    "#         print('da2のタイプ：', type(da2))\n",
    "        dz1,self.dW2,self.db2 = self.backprop_Mutmul_layer(self.z1, self.W2, self.b2, da2)\n",
    "        #print('dz1の中身：', dz1[:3,:])\n",
    "#         print('dz1のタイプ：', type(dz1))\n",
    "        da1 = self.backprop_Sigmoid_layer(self.z1, dz1)\n",
    "        #print('da1の中身：', da1[:3,:])\n",
    "#         print('da1のタイプ：', type(da1))\n",
    "        dX, self.dW1, self.db1= self.backprop_Mutmul_layer(X, self.W1, self.b1, da1)\n",
    "        #print('dXの中身：', dX[:3,:])\n",
    "#         print('dXのタイプ：', type(dX))\n",
    "        \n",
    "        \n",
    "    \n",
    "    #平均交差エントロピーを返す\n",
    "    def crossentropy(self,y,t,delta = 1e-7):\n",
    "#         print('クロスエントロピーの形状：', (np.sum(t * np.log(y)) / t.shape[0]).shape)\n",
    "        return - np.sum(t * np.log(y + delta)) / t.shape[0]\n",
    "    \n",
    "        \n",
    "    \n",
    "    def loss(self, X, t):\n",
    "        y_pred = self.forward(X)\n",
    "#         print('y_predshape: ', y_pred.shape)\n",
    "        loss = self.crossentropy(y_pred, t)\n",
    "#         print('lossの形状：{}'.format(loss.shape))\n",
    "        return y_pred, loss\n",
    "    \n",
    "    \n",
    "    def backprop_from_SoftmaxWithLoss(self, t, y, dout=1):\n",
    "#         print('-----SoftmaxWithlossを実行します----')\n",
    "#         print(type(y), 'yのタイプ')\n",
    "        \n",
    "        #print('tの中身：', t[:3,:])\n",
    "#         print(type(t), 'tのタイプ')\n",
    "        return y - t\n",
    "    \n",
    "    def backprop_Mutmul_layer(self, X,W, b, dout):\n",
    "        #print('doutの形状', dout.shape)\n",
    "        #print('Xの形状',X.shape)\n",
    "        #print('Xの中身：', X[:2,:2])\n",
    "        #print('Wの中身：', W[:2,:2])\n",
    "        #print('bの中身：', b[:2])\n",
    "        #print('doutの中身；', dout[:2,:2])\n",
    "        dX = np.dot(dout, W.T)\n",
    "        dW = np.dot(X.T, dout)\n",
    "        db = np.sum(dout, axis=0)\n",
    "        #print('dWの形状', dW.shape)\n",
    "        #print('dXの形状', dX.shape)\n",
    "        #print('dbの形状', db.shape)\n",
    "        return dX, dW,db\n",
    "        \n",
    "        \n",
    "    def backprop_Sigmoid_layer(self, a, dout):\n",
    "        #print('勾配消失が起きているか確認：',a * (1 - a))\n",
    "        return a * (1 - a) * dout\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        z3 = self.forward(X)\n",
    "        \n",
    "        y_pred = np.argmax(z3,axis=1)\n",
    "        return y_pred\n",
    "        \n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "       \n",
    "       サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "\n",
    "    def accuracy(self,X,y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_argmax = np.argmax(y,axis=1)\n",
    "        print('y_pred:', y_pred)\n",
    "        print('y:', y_argmax)\n",
    "        print(np.sum(y_pred == y_argmax))\n",
    "        return np.sum(y_pred == y_argmax) * 100 /len(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "====fit処理を実行します。====\n",
      "************1回目エポック**************\n",
      "loss: 1.37590929217452\n",
      "************2回目エポック**************\n",
      "loss: 0.2209877143861152\n",
      "************3回目エポック**************\n",
      "loss: 0.14268468693901792\n",
      "************4回目エポック**************\n",
      "loss: 0.1018407824985729\n",
      "************5回目エポック**************\n",
      "loss: 0.08489673213024031\n",
      "************6回目エポック**************\n",
      "loss: 0.07606723062823376\n",
      "************7回目エポック**************\n",
      "loss: 0.06964019336382762\n",
      "************8回目エポック**************\n",
      "loss: 0.06501256274324213\n",
      "************9回目エポック**************\n",
      "loss: 0.06040045120678729\n",
      "************10回目エポック**************\n",
      "loss: 0.05447328215328416\n",
      "************11回目エポック**************\n",
      "loss: 0.04726232971070158\n",
      "************12回目エポック**************\n",
      "loss: 0.0408223713453368\n",
      "************13回目エポック**************\n",
      "loss: 0.03638261462400398\n",
      "************14回目エポック**************\n",
      "loss: 0.03301747068730719\n",
      "************15回目エポック**************\n",
      "loss: 0.029717452164063546\n",
      "************16回目エポック**************\n",
      "loss: 0.02592633777830325\n",
      "************17回目エポック**************\n",
      "loss: 0.02169224926202494\n",
      "************18回目エポック**************\n",
      "loss: 0.017585906004646885\n",
      "************19回目エポック**************\n",
      "loss: 0.014147409219833434\n",
      "************20回目エポック**************\n",
      "loss: 0.01151818534902525\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "network = ScratchSimpleNeuralNetrowkClassifier()\n",
    "print(y_train_one_hot.shape)\n",
    "network.fit(X_train, y_train_one_hot)\n",
    "print(len(network.loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = network.W3_list[0].shape[0]\n",
    "w = network.W3_list[0].shape[1]\n",
    "short = np.zeros((len(network.W3_list), 3, 3))\n",
    "for idx, w3_list in enumerate(network.W3_list):\n",
    "    short[idx,:,:] = w3_list[:3,:3]\n",
    "short = short.reshape(len(network.W3_list),-1)\n",
    "for i in range(short.shape[1]):\n",
    "    plt.plot(np.arange(1,short.shape[0] + 1), short[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.20600674e-04,  1.09573658e-03,  1.07553145e-03, ...,\n",
      "        -4.35060010e-04, -2.06489880e-05,  4.51479549e-04],\n",
      "       [ 4.21262705e-04,  6.27789852e-04, -1.45985149e-04, ...,\n",
      "        -1.16805949e-03, -2.59014644e-04,  7.83695155e-04],\n",
      "       [ 5.30771852e-04, -3.27636603e-04,  2.28240692e-04, ...,\n",
      "        -7.79966223e-04,  5.94829266e-04,  6.20709790e-04],\n",
      "       ...,\n",
      "       [ 7.94674080e-04, -7.95359395e-05, -1.51286533e-03, ...,\n",
      "        -1.70883341e-03, -3.92546105e-05,  9.36192737e-04],\n",
      "       [ 8.80676485e-04, -5.49888815e-04,  1.38455673e-04, ...,\n",
      "        -2.73868381e-04,  9.00597032e-04, -3.48754627e-04],\n",
      "       [ 5.70051966e-04, -2.95821719e-04,  6.33894037e-04, ...,\n",
      "        -4.35576257e-04,  5.15412159e-06,  1.12806526e-03]]), array([[ 1.20600674e-04,  1.09573658e-03,  1.07553145e-03, ...,\n",
      "        -4.35060010e-04, -2.06489880e-05,  4.51479549e-04],\n",
      "       [ 4.21262705e-04,  6.27789852e-04, -1.45985149e-04, ...,\n",
      "        -1.16805949e-03, -2.59014644e-04,  7.83695155e-04],\n",
      "       [ 5.30771852e-04, -3.27636603e-04,  2.28240692e-04, ...,\n",
      "        -7.79966223e-04,  5.94829266e-04,  6.20709790e-04],\n",
      "       ...,\n",
      "       [ 7.94674080e-04, -7.95359395e-05, -1.51286533e-03, ...,\n",
      "        -1.70883341e-03, -3.92546105e-05,  9.36192737e-04],\n",
      "       [ 8.80676485e-04, -5.49888815e-04,  1.38455673e-04, ...,\n",
      "        -2.73868381e-04,  9.00597032e-04, -3.48754627e-04],\n",
      "       [ 5.70051966e-04, -2.95821719e-04,  6.33894037e-04, ...,\n",
      "        -4.35576257e-04,  5.15412159e-06,  1.12806526e-03]]), array([[ 1.20600674e-04,  1.09573658e-03,  1.07553145e-03, ...,\n",
      "        -4.35060010e-04, -2.06489880e-05,  4.51479549e-04],\n",
      "       [ 4.21262705e-04,  6.27789852e-04, -1.45985149e-04, ...,\n",
      "        -1.16805949e-03, -2.59014644e-04,  7.83695155e-04],\n",
      "       [ 5.30771852e-04, -3.27636603e-04,  2.28240692e-04, ...,\n",
      "        -7.79966223e-04,  5.94829266e-04,  6.20709790e-04],\n",
      "       ...,\n",
      "       [ 7.94674080e-04, -7.95359395e-05, -1.51286533e-03, ...,\n",
      "        -1.70883341e-03, -3.92546105e-05,  9.36192737e-04],\n",
      "       [ 8.80676485e-04, -5.49888815e-04,  1.38455673e-04, ...,\n",
      "        -2.73868381e-04,  9.00597032e-04, -3.48754627e-04],\n",
      "       [ 5.70051966e-04, -2.95821719e-04,  6.33894037e-04, ...,\n",
      "        -4.35576257e-04,  5.15412159e-06,  1.12806526e-03]]), array([[ 1.20600674e-04,  1.09573658e-03,  1.07553145e-03, ...,\n",
      "        -4.35060010e-04, -2.06489880e-05,  4.51479549e-04],\n",
      "       [ 4.21262705e-04,  6.27789852e-04, -1.45985149e-04, ...,\n",
      "        -1.16805949e-03, -2.59014644e-04,  7.83695155e-04],\n",
      "       [ 5.30771852e-04, -3.27636603e-04,  2.28240692e-04, ...,\n",
      "        -7.79966223e-04,  5.94829266e-04,  6.20709790e-04],\n",
      "       ...,\n",
      "       [ 7.94674080e-04, -7.95359395e-05, -1.51286533e-03, ...,\n",
      "        -1.70883341e-03, -3.92546105e-05,  9.36192737e-04],\n",
      "       [ 8.80676485e-04, -5.49888815e-04,  1.38455673e-04, ...,\n",
      "        -2.73868381e-04,  9.00597032e-04, -3.48754627e-04],\n",
      "       [ 5.70051966e-04, -2.95821719e-04,  6.33894037e-04, ...,\n",
      "        -4.35576257e-04,  5.15412159e-06,  1.12806526e-03]]), array([[ 1.20600674e-04,  1.09573658e-03,  1.07553145e-03, ...,\n",
      "        -4.35060010e-04, -2.06489880e-05,  4.51479549e-04],\n",
      "       [ 4.21262705e-04,  6.27789852e-04, -1.45985149e-04, ...,\n",
      "        -1.16805949e-03, -2.59014644e-04,  7.83695155e-04],\n",
      "       [ 5.30771852e-04, -3.27636603e-04,  2.28240692e-04, ...,\n",
      "        -7.79966223e-04,  5.94829266e-04,  6.20709790e-04],\n",
      "       ...,\n",
      "       [ 7.94674080e-04, -7.95359395e-05, -1.51286533e-03, ...,\n",
      "        -1.70883341e-03, -3.92546105e-05,  9.36192737e-04],\n",
      "       [ 8.80676485e-04, -5.49888815e-04,  1.38455673e-04, ...,\n",
      "        -2.73868381e-04,  9.00597032e-04, -3.48754627e-04],\n",
      "       [ 5.70051966e-04, -2.95821719e-04,  6.33894037e-04, ...,\n",
      "        -4.35576257e-04,  5.15412159e-06,  1.12806526e-03]])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(network.W2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題7 学習曲線のプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1381e3dd8>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(np.arange(1,len(network.epoch_loss_list)+1), network.epoch_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下完成前の作業"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.epoch_dW1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: [1 1 6 ... 7 7 4]\n",
      "y: [1 1 6 ... 7 7 4]\n",
      "47739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.45625"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.accuracy(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.epoch_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "for i in range(5):\n",
    "    test_list.append(network.b1_list[i][0])\n",
    "print(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 3s 254us/step - loss: 2.3304 - accuracy: 0.0985 - val_loss: 2.2974 - val_accuracy: 0.1037\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 2s 241us/step - loss: 2.2940 - accuracy: 0.1133 - val_loss: 2.2891 - val_accuracy: 0.1151\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 2s 243us/step - loss: 2.2862 - accuracy: 0.1187 - val_loss: 2.2814 - val_accuracy: 0.1361\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 2s 240us/step - loss: 2.2783 - accuracy: 0.1445 - val_loss: 2.2738 - val_accuracy: 0.1546\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 2s 243us/step - loss: 2.2708 - accuracy: 0.1624 - val_loss: 2.2657 - val_accuracy: 0.1266\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 3s 264us/step - loss: 2.2627 - accuracy: 0.1845 - val_loss: 2.2581 - val_accuracy: 0.1666\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 3s 250us/step - loss: 2.2548 - accuracy: 0.2050 - val_loss: 2.2501 - val_accuracy: 0.1529\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 2s 237us/step - loss: 2.2467 - accuracy: 0.2469 - val_loss: 2.2426 - val_accuracy: 0.1437\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 2s 242us/step - loss: 2.2389 - accuracy: 0.2306 - val_loss: 2.2338 - val_accuracy: 0.2676\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 3s 255us/step - loss: 2.2302 - accuracy: 0.2598 - val_loss: 2.2261 - val_accuracy: 0.4289\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras import optimizers\n",
    "model = Sequential()\n",
    "model.add(Dense(400,input_dim=784, activation='sigmoid',\n",
    "               kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(200,activation='sigmoid',\n",
    "               kernel_initializer='glorot_uniform'))\n",
    "model.add(Dense(10,activation='softmax',\n",
    "               kernel_initializer='glorot_uniform'))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.001)\n",
    "model.compile(optimizer=sgd,\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train[:10000,:], y_train[:10000], epochs=10,batch_size=20,\n",
    "                   verbose=1,validation_data = (X_train[:10000,:],y_train[:10000]))\n",
    "score = model.evaluate(X_train[:10000,:],y_train[:10000,:],verbose=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下の実行で初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1,784)\n",
    "X_test = X_test.reshape(-1,784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max())\n",
    "print(X_train.min())\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot,\n",
    "                                                 test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここまで"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    def __init__(self, X, y, batch_size=20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0] / self.batch_size).astype(np.int)\n",
    "        #self.stopは作成するバッチサイズ数。１エポック分作成する\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    #指定したバッチ番号を取ってきてくれる\n",
    "    def __getitem__(self, item):\n",
    "        p0 = item * self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0 : p1], self._y[p0 : p1]\n",
    "\n",
    "    \n",
    "    \n",
    "    #batchカウンターを初期化する\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    \n",
    "    #batchを前から一つずつ取ってくる\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter * self.batch_size\n",
    "        p1 = self._counter * self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0 : p1], self._y[p0 : p1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "\n",
    "print(len(get_mini_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    #print(mini_X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題1 重みの初期値を決めるコードの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "n_features = 784\n",
    "n_nodes1 = 400\n",
    "n_nodes2 = 200\n",
    "n_output = 10\n",
    "sigma = 0.01\n",
    "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "b1 = np.random.randn(n_nodes1,)\n",
    "W2 = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "b2 = np.random.randn(n_nodes2,)\n",
    "W3 = sigma * np.random.randn(n_nodes2, n_output)\n",
    "b3 = np.random.randn(n_output,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題2 フォワードプロパゲーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(y):\n",
    "    z = 1 / (1 + np.exp(-y))\n",
    "    return z\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Softmax(a,):\n",
    "    a_exp = np.exp(a)\n",
    "    a_sum = np.sum(a_exp)\n",
    "    z = a_exp / a_sum\n",
    "    return z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeedForward(X):\n",
    "    \n",
    "    a1 = np.dot(X, W1) + b1\n",
    "    #print(a1[0],'a1')\n",
    "    z1 = Sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    #print(a2,'a2')\n",
    "    z2 = Sigmoid(a2)\n",
    "    #print(z2,'z2')\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    #print(a3, 'a3')\n",
    "    z3 = Softmax(a3)\n",
    "    #print(z3,'z3')\n",
    "    #print('z3のタイプ', type(z3))\n",
    "    return a1, z1, a2, z2, a3, z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mini, y_mini = get_mini_batch[0]\n",
    "\n",
    "a1, z1, a2, z2, a3,z3 = FeedForward(X_mini)\n",
    "print(z3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z3[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.log(z3)[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題3 交差エントロピー誤差の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy(X,t):\n",
    "        \n",
    "    a1, z1, a2, z2, a3, z3 = FeedForward(X)#y_pred(N,10), t(N,10)=(N,10)\n",
    "    print(np.sum(z3 < 0), 'マイナスのz3がないかチェック')\n",
    "\n",
    "    print(type(z3),'z3のタイプ')\n",
    "    print(type(t),'tのタイプ')\n",
    "    #print(z3,'z3')\n",
    "    print(np.log(z3 + 1e-20).shape,'logz3の形')\n",
    "    print(t.shape)\n",
    "    L = -np.sum(t * np.log(z3 + 1e-50))\n",
    "    return L\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_mini_array = np.squeeze(np.asarray(y_mini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = crossentropy(X_mini,y_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,len(network.loss_list)+1, network.loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "network = ScratchSimpleNeuralNetrowkClassifier()\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    loss += network.loss(mini_X_train,mini_y_train)\n",
    "mean_loss = loss / len(get_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題4 バックプロパゲーションの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_from_SoftmaxWithLoss(t, y, dout=1):\n",
    "    return y - t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_Mutmul_layer(X,W, b, dout):\n",
    "    #print('doutの形状', dout.shape)\n",
    "    #print('Xの形状',X.shape)\n",
    "    dX = np.dot(dout, W.T)\n",
    "    dW = np.dot(X.T, dout)\n",
    "    db = np.sum(dout, axis=0)\n",
    "    #print('dWの形状', dW.shape)\n",
    "    #print('dXの形状', dX.shape)\n",
    "    #print('dbの形状', db.shape)\n",
    "    return dX, dW,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_Sigmoid_layer(dout):\n",
    "    return dout * (1 - dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#あえてクラスを作成せずにやってみる\n",
    "#backward\n",
    "lr = 0.001\n",
    "loss_list = []\n",
    "batch_size = 20\n",
    "n_features = 784\n",
    "n_nodes1 = 400\n",
    "n_nodes2 = 200\n",
    "n_output = 10\n",
    "sigma = 0.01\n",
    "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "b1 = np.random.randn(n_nodes1,)\n",
    "W2 = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "b2 = np.random.randn(n_nodes2,)\n",
    "W3 = sigma * np.random.randn(n_nodes2, n_output)\n",
    "b3 = np.random.randn(n_output,)\n",
    "\n",
    "\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    #print(mini_X_train[0])\n",
    "    print(W1.shape)\n",
    "    print(type(mini_X_train),'mini_X_trainのタイプ')\n",
    "    a1,z1, a2, z2, a3, z3 = FeedForward(mini_X_train)\n",
    "    \n",
    "    \n",
    "    #print(z3,'z3の値')\n",
    "    da3 = backprop_from_SoftmaxWithLoss(mini_y_train, z3)\n",
    "    dz2,dW3,db3 = backprop_Mutmul_layer(z2, W3, b3, da3)\n",
    "    da2 = backprop_Sigmoid_layer(dz2)\n",
    "    dz1,dW2,db2 = backprop_Mutmul_layer(z1, W2, b2, da2)\n",
    "    da1 = backprop_Sigmoid_layer(dz1)\n",
    "    dX, dW1, db1= backprop_Mutmul_layer(mini_X_train, W1, b1, da1)\n",
    "\n",
    "        #勾配の更新\n",
    "    W1 -= lr * dW1\n",
    "    b1 -= lr * db1\n",
    "    W2 -= lr * dW2\n",
    "    b2 -= lr * db2\n",
    "    W3 -= lr * dW3\n",
    "    b3 -= lr * db3\n",
    "    \n",
    "    #lossを求める\n",
    "    loss = crossentropy(mini_X_train,mini_y_train)\n",
    "    #print(loss)\n",
    "    loss_list.append(loss)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(W1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(np.arange(1,len(loss_list) + 1), loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss_list[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.array([[8,8,9],\n",
    "                       [9,1,2]])\n",
    "print(np.argmax(test_array,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "def step_function(x):\n",
    "    return np.array(x > 0, dtype=np.int)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))    \n",
    "\n",
    "\n",
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)\n",
    "    \n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def relu_grad(x):\n",
    "    grad = np.zeros(x)\n",
    "    grad[x>=0] = 1\n",
    "    return grad\n",
    "    \n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # オーバーフロー対策\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "\n",
    "def mean_squared_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)\n",
    "\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 教師データがone-hot-vectorの場合、正解ラベルのインデックスに変換\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "\n",
    "def softmax_loss(X, t):\n",
    "    y = softmax(X)\n",
    "    return cross_entropy_error(y, t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#coding: utf-8\n",
    "import numpy as np\n",
    "\n",
    "#from common.util import im2col, col2im\n",
    "\n",
    "\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = sigmoid(x)\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W =W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        # 重み・バイアスパラメータの微分\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # テンソル対応\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)  # 入力データの形状に戻す（テンソル対応）\n",
    "        return dx\n",
    "\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None # softmaxの出力\n",
    "        self.t = None # 教師データ\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if self.t.size == self.y.size: # 教師データがone-hot-vectorの場合\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx / batch_size\n",
    "        \n",
    "        return dx\n",
    "\n",
    "\n",
    "class Dropout:\n",
    "    \"\"\"\n",
    "    http://arxiv.org/abs/1207.0580\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout_ratio=0.5):\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        if train_flg:\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x * (1.0 - self.dropout_ratio)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask\n",
    "\n",
    "\n",
    "class BatchNormalization:\n",
    "    \"\"\"\n",
    "    http://arxiv.org/abs/1502.03167\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma, beta, momentum=0.9, running_mean=None, running_var=None):\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.momentum = momentum\n",
    "        self.input_shape = None # Conv層の場合は4次元、全結合層の場合は2次元  \n",
    "\n",
    "        # テスト時に使用する平均と分散\n",
    "        self.running_mean = running_mean\n",
    "        self.running_var = running_var  \n",
    "        \n",
    "        # backward時に使用する中間データ\n",
    "        self.batch_size = None\n",
    "        self.xc = None\n",
    "        self.std = None\n",
    "        self.dgamma = None\n",
    "        self.dbeta = None\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        self.input_shape = x.shape\n",
    "        if x.ndim != 2:\n",
    "            N, C, H, W = x.shape\n",
    "            x = x.reshape(N, -1)\n",
    "\n",
    "        out = self.__forward(x, train_flg)\n",
    "        \n",
    "        return out.reshape(*self.input_shape)\n",
    "            \n",
    "    def __forward(self, x, train_flg):\n",
    "        if self.running_mean is None:\n",
    "            N, D = x.shape\n",
    "            self.running_mean = np.zeros(D)\n",
    "            self.running_var = np.zeros(D)\n",
    "                        \n",
    "        if train_flg:\n",
    "            mu = x.mean(axis=0)\n",
    "            xc = x - mu\n",
    "            var = np.mean(xc**2, axis=0)\n",
    "            std = np.sqrt(var + 10e-7)\n",
    "            xn = xc / std\n",
    "            \n",
    "            self.batch_size = x.shape[0]\n",
    "            self.xc = xc\n",
    "            self.xn = xn\n",
    "            self.std = std\n",
    "            self.running_mean = self.momentum * self.running_mean + (1-self.momentum) * mu\n",
    "            self.running_var = self.momentum * self.running_var + (1-self.momentum) * var            \n",
    "        else:\n",
    "            xc = x - self.running_mean\n",
    "            xn = xc / ((np.sqrt(self.running_var + 10e-7)))\n",
    "            \n",
    "        out = self.gamma * xn + self.beta \n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        if dout.ndim != 2:\n",
    "            N, C, H, W = dout.shape\n",
    "            dout = dout.reshape(N, -1)\n",
    "\n",
    "        dx = self.__backward(dout)\n",
    "\n",
    "        dx = dx.reshape(*self.input_shape)\n",
    "        return dx\n",
    "\n",
    "    def __backward(self, dout):\n",
    "        dbeta = dout.sum(axis=0)\n",
    "        dgamma = np.sum(self.xn * dout, axis=0)\n",
    "        dxn = self.gamma * dout\n",
    "        dxc = dxn / self.std\n",
    "        dstd = -np.sum((dxn * self.xc) / (self.std * self.std), axis=0)\n",
    "        dvar = 0.5 * dstd / self.std\n",
    "        dxc += (2.0 / self.batch_size) * self.xc * dvar\n",
    "        dmu = np.sum(dxc, axis=0)\n",
    "        dx = dxc - dmu / self.batch_size\n",
    "        \n",
    "        self.dgamma = dgamma\n",
    "        self.dbeta = dbeta\n",
    "        \n",
    "        return dx\n",
    "\n",
    "\n",
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 中間データ（backward時に使用）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        # 重み・バイアスパラメータの勾配\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "\n",
    "class TestLayerNet:\n",
    "    \"\"\"全結合による多層ニューラルネットワーク\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 入力サイズ（MNISTの場合は784）\n",
    "    hidden_size_list : 隠れ層のニューロンの数のリスト（e.g. [100, 100, 100]）\n",
    "    output_size : 出力サイズ（MNISTの場合は10）\n",
    "    activation : 'relu' or 'sigmoid'\n",
    "    weight_init_std : 重みの標準偏差を指定（e.g. 0.01）\n",
    "        'relu'または'he'を指定した場合は「Heの初期値」を設定\n",
    "        'sigmoid'または'xavier'を指定した場合は「Xavierの初期値」を設定\n",
    "    weight_decay_lambda : Weight Decay（L2ノルム）の強さ\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size_list, output_size,\n",
    "                 activation='relu', weight_init_std='relu', weight_decay_lambda=0):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size_list = hidden_size_list\n",
    "        self.hidden_layer_num = len(hidden_size_list)\n",
    "        self.weight_decay_lambda = weight_decay_lambda\n",
    "        self.params = {}\n",
    "\n",
    "        # 重みの初期化\n",
    "        self.__init_weight(weight_init_std)\n",
    "\n",
    "        # レイヤの生成\n",
    "        activation_layer = {'sigmoid': Sigmoid, 'relu': Relu}\n",
    "        self.layers = OrderedDict()\n",
    "        for idx in range(1, self.hidden_layer_num+1):\n",
    "            self.layers['Affine' + str(idx)] = Affine(self.params['W' + str(idx)],\n",
    "                                                      self.params['b' + str(idx)])\n",
    "            self.layers['Activation_function' + str(idx)] = activation_layer[activation]()\n",
    "\n",
    "        idx = self.hidden_layer_num + 1\n",
    "        self.layers['Affine' + str(idx)] = Affine(self.params['W' + str(idx)],\n",
    "            self.params['b' + str(idx)])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def __init_weight(self, weight_init_std):\n",
    "        \"\"\"重みの初期値設定\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        weight_init_std : 重みの標準偏差を指定（e.g. 0.01）\n",
    "            'relu'または'he'を指定した場合は「Heの初期値」を設定\n",
    "            'sigmoid'または'xavier'を指定した場合は「Xavierの初期値」を設定\n",
    "        \"\"\"\n",
    "        all_size_list = [self.input_size] + self.hidden_size_list + [self.output_size]\n",
    "        for idx in range(1, len(all_size_list)):\n",
    "            scale = weight_init_std\n",
    "            if str(weight_init_std).lower() in ('relu', 'he'):\n",
    "                scale = np.sqrt(2.0 / all_size_list[idx - 1])  # ReLUを使う場合に推奨される初期値\n",
    "            elif str(weight_init_std).lower() in ('sigmoid', 'xavier'):\n",
    "                scale = np.sqrt(1.0 / all_size_list[idx - 1])  # sigmoidを使う場合に推奨される初期値\n",
    "\n",
    "            self.params['W' + str(idx)] = scale * np.random.randn(all_size_list[idx-1], all_size_list[idx])\n",
    "            self.params['b' + str(idx)] = np.zeros(all_size_list[idx])\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"損失関数を求める\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        損失関数の値\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "\n",
    "        weight_decay = 0\n",
    "        for idx in range(1, self.hidden_layer_num + 2):\n",
    "            W = self.params['W' + str(idx)]\n",
    "            weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W ** 2)\n",
    "\n",
    "        return self.last_layer.forward(y, t) + weight_decay\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "\n",
    "#     def numerical_gradient(self, x, t):\n",
    "#         \"\"\"勾配を求める（数値微分）\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         x : 入力データ\n",
    "#         t : 教師ラベル\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         各層の勾配を持ったディクショナリ変数\n",
    "#             grads['W1']、grads['W2']、...は各層の重み\n",
    "#             grads['b1']、grads['b2']、...は各層のバイアス\n",
    "#         \"\"\"\n",
    "#         loss_W = lambda W: self.loss(x, t)\n",
    "\n",
    "#         grads = {}\n",
    "#         for idx in range(1, self.hidden_layer_num+2):\n",
    "#             grads['W' + str(idx)] = numerical_gradient(loss_W, self.params['W' + str(idx)])\n",
    "#             grads['b' + str(idx)] = numerical_gradient(loss_W, self.params['b' + str(idx)])\n",
    "\n",
    "#         return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（誤差逆伝搬法）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        for idx in range(1, self.hidden_layer_num+2):\n",
    "            grads['W' + str(idx)] = self.layers['Affine' + str(idx)].dW + self.weight_decay_lambda * self.layers['Affine' + str(idx)].W\n",
    "            grads['b' + str(idx)] = self.layers['Affine' + str(idx)].db\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SGD:\n",
    "\n",
    "    \"\"\"確率的勾配降下法（Stochastic Gradient Descent）\"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シグモイドの微分値を調べれば勾配が消失しているか確認できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
