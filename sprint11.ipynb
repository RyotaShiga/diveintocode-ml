{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        grads = layer.grads\n",
    "        for key in layer.params.keys():\n",
    "            #print('勾配：', grads[key])\n",
    "            layer.params[key] -= self.lr * grads[key]\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        self.filter_num = None\n",
    "        \n",
    "    def W(self, filter_num, filter_length):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = np.random.randn(filter_num, filter_length) * self.sigma\n",
    "        self.filter_num = filter_num\n",
    "        return W\n",
    "    \n",
    "    def B(self):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        \n",
    "        B = np.random.randn(self.filter_num,)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題1,問題2,問題3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    \n",
    "    def __init__(self,filter_num, filter_length,\n",
    "                 initializer, optimizer,sigma,\n",
    "                 opt_params, stride=1, padding=0):\n",
    "        #self.input_shape= input_shape\n",
    "        self.filter_num = filter_num\n",
    "        self.filter_length = filter_length\n",
    "        print(self.filter_length)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.sigma = sigma\n",
    "        self.initializer = initializer(self.sigma)\n",
    "        self.optimizer = optimizer(**opt_params)\n",
    "        \n",
    "        \n",
    "        self.params = {}\n",
    "        self.grads = {}\n",
    "        self.X = None\n",
    "        self.out_size = None\n",
    "        #self.params['W'] = self.initializer.W(self.filter_num, self.filter_length)\n",
    "        self.params['W'] = np.array([3,5,7]).reshape(1,-1)\n",
    "        #self.params['B'] = self.initializer.B()\n",
    "        self.params['B'] = np.array([1])\n",
    "        self.dW = np.zeros_like(self.params['W'])\n",
    "        self.dB = np.zeros_like(self.params['B'])\n",
    "        self.grads['W'] = self.dW\n",
    "        self.grads['B'] = self.dB\n",
    "        \n",
    "        \n",
    "    def forward(self,X):\n",
    "        self.X = X\n",
    "        self.dX = np.zeros_like(X)\n",
    "        D = len(X)\n",
    "        #N,D = X.shape\n",
    "        self.out_size = self.calc_out_size(D, self.filter_length, self.padding,\n",
    "                                    self.stride)\n",
    "        print('出力サイズ：',self.out_size)\n",
    "        x_out = np.zeros((self.out_size,self.filter_num))\n",
    "        #x_out = np.zeros((N, out_size,self.filter_num))\n",
    "        count = 0\n",
    "        for i in range(self.out_size):\n",
    "            x_out[i,:] = np.dot(X[i : i + self.filter_length], self.params['W'].T) + \\\n",
    "            self.params['B']\n",
    "            #x_out[:, i, :] = np.dot(X[:,i : self.filter_length+ i], self.params['W'].T) + \\\n",
    "            #self.params['B']#shape=(N,FN)\n",
    "            #print('一つの領域', x_out[:,i,:])\n",
    "            count += 1\n",
    "        \n",
    "        print('count',count)\n",
    "        self.x_out = x_out\n",
    "        return x_out\n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        #shape: dout=(1,FN), x=(1,filter_size), W=(FN, filter_size)\n",
    "        for i in range(self.out_size):\n",
    "            print(dout[i,:].reshape(1,-1).shape,'dout[i,:].T.shape')\n",
    "            print(self.X[i : i + self.filter_length].reshape(1,-1).shape,\n",
    "                  'xshape')\n",
    "            print(self.grads['W'].shape, 'Wshape')\n",
    "            self.grads['W'] += np.dot(dout[i,:].T.reshape(1,-1),\n",
    "                                      self.X[i : i + self.filter_length].reshape(1,-1))\n",
    "            self.grads['B'] += dout[i,:]\n",
    "            self.dX[i : i + self.filter_length] += np.dot(dout[i,:], \n",
    "                                                          self.params['W'])\n",
    "            \n",
    "        self.grads['W'] = self.grads['W'] #/ self.out_size\n",
    "        self.grads['B'] = self.grads['B']# / self.out_size\n",
    "        self.dX = self.dX #/ self.out_size\n",
    "        return self.dX \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def calc_out_size(self, D, filter_length, padding, stride):\n",
    "        return (D - filter_length + 2 * padding) // stride + 1\n",
    "            \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "出力サイズ： 2\n",
      "count 2\n",
      "[[35.]\n",
      " [50.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "filter_num = 1\n",
    "filter_length = 3\n",
    "sigma = 0.01\n",
    "X_sample = np.array([1,2,3,4])\n",
    "\n",
    "\n",
    "conv1d = SimpleConv1d(filter_num=filter_num,\n",
    "                      filter_length=filter_length, sigma = sigma,\n",
    "                      initializer=ConvSimpleInitializer, optimizer=SGD,\n",
    "                 opt_params={'lr' : 0.01})\n",
    "out = conv1d.forward(X_sample)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1) dout[i,:].T.shape\n",
      "(1, 3) xshape\n",
      "(1, 3) Wshape\n",
      "(1, 1) dout[i,:].T.shape\n",
      "(1, 3) xshape\n",
      "(1, 3) Wshape\n"
     ]
    }
   ],
   "source": [
    "delta_a = np.array([10,20]).reshape(-1,1)\n",
    "dout = conv1d.backward(delta_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30 110 170 140]\n",
      "{'W': array([[ 50,  80, 110]]), 'B': array([30])}\n"
     ]
    }
   ],
   "source": [
    "print(dout)\n",
    "print(conv1d.grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d_ver1_2:\n",
    "    \n",
    "    def __init__(self,filter_num, filter_length,\n",
    "                 initializer, optimizer,sigma,\n",
    "                 opt_params, stride=1, padding=0):\n",
    "        #self.input_shape= input_shape\n",
    "        self.filter_num = filter_num\n",
    "        self.filter_length = filter_length\n",
    "        print(self.filter_length)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.sigma = sigma\n",
    "        self.initializer = initializer(self.sigma)\n",
    "        self.optimizer = optimizer(**opt_params)\n",
    "        \n",
    "        \n",
    "        self.params = {}\n",
    "        self.grads = {}\n",
    "        self.X = None\n",
    "        self.out_size = None\n",
    "        #self.params['W'] = self.initializer.W(self.filter_num, self.filter_length)\n",
    "        \n",
    "        #Wを縦ベクトルで定義する\n",
    "        self.params['W'] = np.array([3,5,7]).reshape(-1,1)\n",
    "        #self.params['B'] = self.initializer.B()\n",
    "        self.params['B'] = np.array([1])\n",
    "        self.dW = np.zeros_like(self.params['W'])\n",
    "        self.dB = np.zeros_like(self.params['B'])\n",
    "        self.grads['W'] = self.dW\n",
    "        self.grads['B'] = self.dB\n",
    "        \n",
    "        \n",
    "    def forward(self,X):\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(1,-1)\n",
    "        \n",
    "        N,D = X.shape\n",
    "        self.X = X\n",
    "        self.out_size = self.calc_out_size(D, self.filter_length,\n",
    "                                           self.padding,self.stride)\n",
    "        print('out_size',self.out_size)\n",
    "\n",
    "        self.col = np.zeros((self.out_size, self.filter_length))\n",
    "\n",
    "        #Xをcolに変換\n",
    "        for i in range(self.out_size):\n",
    "            self.col[i,:] = X[:, i : i + self.filter_length]\n",
    "        \n",
    "        out = np.dot(self.col, self.params['W']) + self.params['B']\n",
    "        return out\n",
    "        \n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        #shape: dout=(out_size,FN), col=(out_size,filter_length),\n",
    "        #W=(FN, filter_length)\n",
    "        \n",
    "        col_dX = np.dot(dout, self.params['W'].T)\n",
    "        dX = np.zeros_like(self.X).astype(np.float64)\n",
    "        print('dxshape',dX.shape)\n",
    "        self.grads['W'] = np.dot(self.col.T, dout)\n",
    "        self.grads['B'] = np.sum(dout,axis=0)# / self.out_size\n",
    "        print('beforedx:', dX)\n",
    "        for i in range(self.out_size):\n",
    "            dX[:,i : i + self.filter_length] += col_dX[i,:]\n",
    "            print(str(i) + '回目dX:', dX)\n",
    "     \n",
    "        return dX \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def calc_out_size(self, D, filter_length, padding, stride):\n",
    "        return (D - filter_length + 2 * padding) // stride + 1\n",
    "            \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "out_size 2\n",
      "[[35.]\n",
      " [50.]]\n",
      "dxshape (1, 4)\n",
      "beforedx: [[0. 0. 0. 0.]]\n",
      "0回目dX: [[30. 50. 70.  0.]]\n",
      "1回目dX: [[ 30. 110. 170. 140.]]\n",
      "[[ 30. 110. 170. 140.]]\n"
     ]
    }
   ],
   "source": [
    "filter_num = 1\n",
    "filter_length = 3\n",
    "sigma = 0.01\n",
    "X_sample = np.array([1,2,3,4])\n",
    "\n",
    "\n",
    "conv1d = SimpleConv1d_ver1_2(filter_num=filter_num,\n",
    "                      filter_length=filter_length, sigma = sigma,\n",
    "                      initializer=ConvSimpleInitializer, optimizer=SGD,\n",
    "                 opt_params={'lr' : 0.01})\n",
    "out = conv1d.forward(X_sample)\n",
    "print(out)\n",
    "\n",
    "delta_a = np.array([10,20]).reshape(-1,1)\n",
    "dout = conv1d.backward(delta_a)\n",
    "\n",
    "\n",
    "\n",
    "print(dout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題4 チャンネル数を限定しない1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d_ver2_1:\n",
    "    \n",
    "    def __init__(self,filter_num, filter_length,\n",
    "                 initializer, optimizer,sigma,\n",
    "                 opt_params, stride=1, padding=0):\n",
    "        #self.input_shape= input_shape\n",
    "        self.filter_num = filter_num\n",
    "        self.filter_length = filter_length\n",
    "        print(self.filter_length)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.sigma = sigma\n",
    "        self.initializer = initializer(self.sigma)\n",
    "        self.optimizer = optimizer(**opt_params)\n",
    "        \n",
    "        \n",
    "        self.params = {}\n",
    "        self.grads = {}\n",
    "        self.X = None\n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        self.out_size = None\n",
    "        #self.params['W'] = self.initializer.W(self.filter_num, self.filter_length)\n",
    "        \n",
    "        #Wを縦ベクトルで定義する\n",
    "        self.params['W'] = np.array([[[1,1,2],[2,1,1]],\n",
    "                                   [[2,1,1],[1,1,1]],\n",
    "                                   [[1,1,1],[1,1,1]]])#(FN,C,filter_length)\n",
    "        \n",
    "        #self.params['B'] = self.initializer.B()\n",
    "        self.params['B'] = np.array([1, 2, 3]).reshape(1,-1)\n",
    "        self.dW = np.zeros_like(self.params['W'])\n",
    "        self.dB = np.zeros_like(self.params['B'])\n",
    "        self.grads['W'] = self.dW\n",
    "        self.grads['B'] = self.dB\n",
    "        \n",
    "        \n",
    "    def forward(self,X):\n",
    "        #batchsize,channel共に１のとき\n",
    "#         if X.ndim == 1:\n",
    "#             X = X[np.newaxis,np.newaxis,:]\n",
    "#         #batchsizeが１のとき\n",
    "#         if X.ndim == 2:\n",
    "#             X = X[np.newaxis,:,:]\n",
    "            \n",
    "        C,D = X.shape\n",
    "        self.C = C\n",
    "        self.X = X\n",
    "        self.out_size = self.calc_out_size(D, self.filter_length,\n",
    "                                           self.padding,self.stride)\n",
    "        print('out_size',self.out_size)\n",
    "        \n",
    "        #Wをcolに変換\n",
    "        print('変換前：', self.params['W'])\n",
    "        col_W = self.params['W'].transpose(1,2,0)\n",
    "        col_W = col_W.reshape(-1,self.filter_num)\n",
    "        self.col_W = col_W\n",
    "        print('col_W', col_W)\n",
    "\n",
    "        self.col = np.zeros((self.out_size, C * self.filter_length))\n",
    "        print('初期化時colshape', self.col.shape)\n",
    "\n",
    "        #Xをcolに変換\n",
    "        for i in range(self.out_size):\n",
    "            print('x部分shape', X[:, i : i + self.filter_length].shape)\n",
    "            self.col[i,:] = X[:, i : i + self.filter_length].reshape(1,-1)\n",
    "            print(str(i) + '番目のcol', self.col)\n",
    "            \n",
    "        print('colshape:', self.col.shape)\n",
    "        out_col = np.dot(self.col, col_W) + \\\n",
    "        self.params['B']\n",
    "        out = out_col.T\n",
    "        return out#(FN,out_size)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        #shape: dout=(out_size,FN), col=(out_size,filter_length),\n",
    "        #W=(FN, filter_length)\n",
    "        dout = dout.T#(out_size, FN)\n",
    "        print('dout:', dout)\n",
    "        print('col_W.T', self.col_W.T)\n",
    "        col_dX = np.dot(dout, self.col_W.T)\n",
    "        print('col_dX:', col_dX)\n",
    "        #(out_size,FN)dot(FN,filter_length*C)\n",
    "        dX = np.zeros_like(self.X).astype(np.float64)\n",
    "        print('dxshape',dX.shape)\n",
    "        #(filter_length * C, out_size)dot(out_size, FN)\n",
    "        self.grads['W'] = np.dot(self.col.T, dout)\n",
    "        self.grads['B'] = np.sum(dout,axis=0)\n",
    "        print('beforedx:', dX)\n",
    "        \n",
    "        #col_dXをdXに変換\n",
    "        col_dX_3d = col_dX.reshape(self.out_size, self.C, self.filter_length)\n",
    "        col_dX_3d = col_dX_3d.transpose(1,2,0)\n",
    "        for i in range(self.out_size):\n",
    "            dX[:,i : i + self.filter_length] += col_dX_3d[:,:,i]\n",
    "            print(str(i) + '回目dX:', col_dX_3d[:,:,i])\n",
    "     \n",
    "        return dX \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def calc_out_size(self, D, filter_length, padding, stride):\n",
    "        return (D - filter_length + 2 * padding) // stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d.params['W'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "3\n",
      "out_size 2\n",
      "変換前： [[[1 1 2]\n",
      "  [2 1 1]]\n",
      "\n",
      " [[2 1 1]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[1 1 1]\n",
      "  [1 1 1]]]\n",
      "col_W [[1 2 1]\n",
      " [1 1 1]\n",
      " [2 1 1]\n",
      " [2 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]]\n",
      "初期化時colshape (2, 6)\n",
      "x部分shape (2, 3)\n",
      "0番目のcol [[1. 2. 3. 2. 3. 4.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "x部分shape (2, 3)\n",
      "1番目のcol [[1. 2. 3. 2. 3. 4.]\n",
      " [2. 3. 4. 3. 4. 5.]]\n",
      "colshape: (2, 6)\n",
      "out [[21. 29.]\n",
      " [18. 25.]\n",
      " [18. 24.]]\n",
      "dout: [[ 9 32 52]\n",
      " [11 35 56]]\n",
      "col_W.T [[1 1 2 2 1 1]\n",
      " [2 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "col_dX: [[125  93 102 102  93  93]\n",
      " [137 102 113 113 102 102]]\n",
      "dxshape (2, 4)\n",
      "beforedx: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "0回目dX: [[125  93 102]\n",
      " [102  93  93]]\n",
      "1回目dX: [[137 102 113]\n",
      " [113 102 102]]\n",
      "dout [[125. 230. 204. 113.]\n",
      " [102. 206. 195. 102.]]\n"
     ]
    }
   ],
   "source": [
    "#x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "#w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "#b = np.array([1, 2, 3])\n",
    "\n",
    "import numpy as np\n",
    "filter_num = 3\n",
    "filter_length = 3\n",
    "sigma = 0.01\n",
    "\n",
    "print(type(np.array([[1, 2, 3, 4], [2, 3, 4, 5]])))\n",
    "X_sample =np.array([[1, 2, 3, 4],[2, 3, 4, 5]])\n",
    "\n",
    "\n",
    "conv1d = SimpleConv1d_ver2_1(filter_num=filter_num,\n",
    "                      filter_length=filter_length, sigma = sigma,\n",
    "                      initializer=ConvSimpleInitializer, optimizer=SGD,\n",
    "                 opt_params={'lr' : 0.01})\n",
    "out = conv1d.forward(X_sample)\n",
    "print('out', out)\n",
    "\n",
    "delta_a  = np.array([[9, 11],[32, 35],[52, 56]])\n",
    "dout = conv1d.backward(delta_a)\n",
    "\n",
    "\n",
    "\n",
    "print('dout', dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題5 パディングの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d_ver3_1:\n",
    "    \n",
    "    def __init__(self,filter_num, filter_length,\n",
    "                 initializer, optimizer,sigma,\n",
    "                 opt_params, stride=1, padding=0):\n",
    "        #self.input_shape= input_shape\n",
    "        self.filter_num = filter_num\n",
    "        self.filter_length = filter_length\n",
    "        print(self.filter_length)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.sigma = sigma\n",
    "        self.initializer = initializer(self.sigma)\n",
    "        self.optimizer = optimizer(**opt_params)\n",
    "        \n",
    "        \n",
    "        self.params = {}\n",
    "        self.grads = {}\n",
    "        self.X = None\n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        self.out_size = None\n",
    "        #self.params['W'] = self.initializer.W(self.filter_num, self.filter_length)\n",
    "        \n",
    "        #Wを縦ベクトルで定義する\n",
    "        self.params['W'] = np.ones((3, 2, 3))#(FN,C,filter_length)\n",
    "        \n",
    "        #self.params['B'] = self.initializer.B()\n",
    "        self.params['B'] = np.array([1, 2, 3]).reshape(1,-1)\n",
    "        self.dW = np.zeros_like(self.params['W'])\n",
    "        self.dB = np.zeros_like(self.params['B'])\n",
    "        self.grads['W'] = self.dW\n",
    "        self.grads['B'] = self.dB\n",
    "        \n",
    "        \n",
    "    def forward(self,X):\n",
    "        #batchsize,channel共に１のとき\n",
    "#         if X.ndim == 1:\n",
    "#             X = X[np.newaxis,np.newaxis,:]\n",
    "#         #batchsizeが１のとき\n",
    "#         if X.ndim == 2:\n",
    "#             X = X[np.newaxis,:,:]\n",
    "            \n",
    "        C,D = X.shape\n",
    "        self.C = C\n",
    "        X = np.pad(X,[(0,0),(self.padding,self.padding)],'constant')\n",
    "        print('pad後x:', X)\n",
    "        print('Wshape:',self.params['W'].shape)\n",
    "        self.X = X\n",
    "        \n",
    "        \n",
    "        self.out_size = self.calc_out_size(D, self.filter_length,\n",
    "                                           self.padding,self.stride)\n",
    "        print('out_size',self.out_size)\n",
    "        \n",
    "        #Wをcolに変換\n",
    "        col_W = self.params['W'].reshape(-1,self.filter_num)\n",
    "        self.col_W = col_W\n",
    "        print('col_Wshape:', col_W.shape)\n",
    "\n",
    "        self.col = np.zeros((self.out_size, C * self.filter_length))\n",
    "        print('初期化時colshape', self.col.shape)\n",
    "\n",
    "        #Xをcolに変換\n",
    "        for i in range(self.out_size):\n",
    "            print('x部分shape', X[:, i : i + self.filter_length].shape)\n",
    "            self.col[i,:] = X[:, i : i + self.filter_length].reshape(1,-1)\n",
    "            \n",
    "        print('colshape:', self.col.shape)\n",
    "        out_col = np.dot(self.col, col_W) + \\\n",
    "        self.params['B']\n",
    "        out = out_col.T\n",
    "        print('outshape:', out.shape)\n",
    "        return out#(FN,out_size)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        #shape: dout=(out_size,FN), col=(out_size,filter_length),\n",
    "        #W=(FN, filter_length)\n",
    "        dout = dout.T#(out_size, FN)\n",
    "        col_dX = np.dot(dout, self.col_W.T)\n",
    "        print('col_dX:', col_dX)\n",
    "        #(out_size,FN)dot(FN,filter_length*C)\n",
    "        dX = np.zeros_like(self.X).astype(np.float64)\n",
    "        print('dxshape',dX.shape)\n",
    "        #(filter_length * C, out_size)dot(out_size, FN)\n",
    "        self.grads['W'] = np.dot(self.col.T, dout)\n",
    "        self.grads['B'] = np.sum(dout,axis=0)\n",
    "        print('beforedx:', dX)\n",
    "        \n",
    "        #col_dXをdXに変換\n",
    "        col_dX_3d = col_dX.reshape(self.C,self.filter_length, self.out_size)\n",
    "        for i in range(self.out_size):\n",
    "            dX[:,i : i + self.filter_length] += col_dX_3d[:,:,i]\n",
    "            print(str(i) + '回目dX:', dX)\n",
    "     \n",
    "        return dX\n",
    "    \n",
    "    def padding(self,X,padding):\n",
    "        return np.pad(X,[0,padding],'constant')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def calc_out_size(self, D, filter_length, padding, stride):\n",
    "        return (D - filter_length + 2 * padding) // stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "pad後x: [[0 1 2 3 4 0]\n",
      " [0 2 3 4 5 0]]\n",
      "Wshape: (3, 2, 3)\n",
      "out_size 4\n",
      "col_Wshape: (6, 3)\n",
      "初期化時colshape (4, 6)\n",
      "x部分shape (2, 3)\n",
      "x部分shape (2, 3)\n",
      "x部分shape (2, 3)\n",
      "x部分shape (2, 3)\n",
      "colshape: (4, 6)\n",
      "outshape: (3, 4)\n",
      "[[ 9. 16. 22. 17.]\n",
      " [10. 17. 23. 18.]\n",
      " [11. 18. 24. 19.]]\n",
      "col_dX: [[30. 30. 30. 30. 30. 30.]\n",
      " [51. 51. 51. 51. 51. 51.]\n",
      " [69. 69. 69. 69. 69. 69.]\n",
      " [54. 54. 54. 54. 54. 54.]]\n",
      "dxshape (2, 6)\n",
      "beforedx: [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "0回目dX: [[30. 30. 51.  0.  0.  0.]\n",
      " [69. 69. 54.  0.  0.  0.]]\n",
      "1回目dX: [[ 30.  60.  81.  51.   0.   0.]\n",
      " [ 69. 138. 123.  54.   0.   0.]]\n",
      "2回目dX: [[ 30.  60. 111. 102.  51.   0.]\n",
      " [ 69. 138. 192. 108.  54.   0.]]\n",
      "3回目dX: [[ 30.  60. 111. 132. 102.  51.]\n",
      " [ 69. 138. 192. 177. 108.  54.]]\n",
      "dout [[ 30.  60. 111. 132. 102.  51.]\n",
      " [ 69. 138. 192. 177. 108.  54.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3])\n",
    "\n",
    "\n",
    "filter_num = 3\n",
    "filter_length = 3\n",
    "sigma = 0.01\n",
    "X_sample =np.array([[1, 2, 3, 4], [2, 3, 4, 5]])\n",
    "\n",
    "\n",
    "conv1d = SimpleConv1d_ver3_1(filter_num=filter_num,\n",
    "                      filter_length=filter_length, sigma = sigma,\n",
    "                      initializer=ConvSimpleInitializer, optimizer=SGD,\n",
    "                 opt_params={'lr' : 0.01}, padding=1)\n",
    "out = conv1d.forward(X_sample)\n",
    "print(out)\n",
    "delta_a = out\n",
    "\n",
    "#delta_a  = np.array([[16, 22], [17, 23], [18, 24]])\n",
    "dout = conv1d.backward(delta_a)\n",
    "\n",
    "\n",
    "\n",
    "print('dout', dout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題6 ミニバッチへの対応"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d_ver3_1:\n",
    "    \n",
    "    def __init__(self,filter_num, filter_length,\n",
    "                 initializer, optimizer,sigma,\n",
    "                 opt_params, stride=1, padding=0):\n",
    "        #self.input_shape= input_shape\n",
    "        self.filter_num = filter_num\n",
    "        self.filter_length = filter_length\n",
    "        print(self.filter_length)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.sigma = sigma\n",
    "        self.initializer = initializer(self.sigma)\n",
    "        self.optimizer = optimizer(**opt_params)\n",
    "        \n",
    "        \n",
    "        self.params = {}\n",
    "        self.grads = {}\n",
    "        self.X = None\n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        self.out_size = None\n",
    "        #self.params['W'] = self.initializer.W(self.filter_num, self.filter_length)\n",
    "        \n",
    "        #Wを縦ベクトルで定義する\n",
    "        self.params['W'] = np.ones((3, 2, 3))#(FN,C,filter_length)\n",
    "        \n",
    "        #self.params['B'] = self.initializer.B()\n",
    "        self.params['B'] = np.array([1, 2, 3]).reshape(1,-1)\n",
    "        self.dW = np.zeros_like(self.params['W'])\n",
    "        self.dB = np.zeros_like(self.params['B'])\n",
    "        self.grads['W'] = self.dW\n",
    "        self.grads['B'] = self.dB\n",
    "        \n",
    "        \n",
    "    def forward(self,X):\n",
    "        #batchsize,channel共に１のとき\n",
    "#         if X.ndim == 1:\n",
    "#             X = X[np.newaxis,np.newaxis,:]\n",
    "#         #batchsizeが１のとき\n",
    "#         if X.ndim == 2:\n",
    "#             X = X[np.newaxis,:,:]\n",
    "            \n",
    "        N,C,D = X.shape\n",
    "        self.C = C\n",
    "        self.D = D\n",
    "        self.N = N\n",
    "        \n",
    "        X = np.pad(X,[(0,0),(0,0),(self.padding,self.padding)],'constant')\n",
    "        print('pad後x:', X)\n",
    "        print('Wshape:',self.params['W'].shape)\n",
    "        self.X = X\n",
    "        \n",
    "        \n",
    "        self.out_size = self.calc_out_size(D, self.filter_length,\n",
    "                                           self.padding,self.stride)\n",
    "        print('out_size',self.out_size)\n",
    "        \n",
    "        #Wをcolに変換\n",
    "        col_W = self.params['W'].reshape(-1,self.filter_num)\n",
    "        self.col_W = col_W\n",
    "        print('col_Wshape:', col_W.shape)\n",
    "\n",
    "        self.col = np.zeros((self.N * self.out_size,\n",
    "                             self.C * self.filter_length))\n",
    "        \n",
    "        print('初期化時colshape', self.col.shape)\n",
    "\n",
    "        #Xをcolに変換\n",
    "        for i in range(self.out_size):\n",
    "            idxes =np.arange(i,self.N * self.out_size,self.out_size)\n",
    "            print('idxes',idxes)\n",
    "            print('x部分shape', X[:, :, i : i + self.filter_length].shape)\n",
    "            self.col[idxes,:] = X[:, :, i : i + self.filter_length].reshape(self.N,\n",
    "                                                                            -1)\n",
    "            \n",
    "        print('self.col',self.col)    \n",
    "        print('colshape:', self.col.shape)\n",
    "        out_col = np.dot(self.col, col_W) + \\\n",
    "        self.params['B']\n",
    "        print('out_col:', out_col)\n",
    "        out_col = out_col.reshape(self.N, self.out_size, self.filter_num)\n",
    "        out = out_col.transpose(0,2,1)\n",
    "        print('outshape:', out.shape)\n",
    "        return out#(N,FN,out_size)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        #shape: dout=(out_size,FN), col=(out_size,filter_length),\n",
    "        #W=(FN, filter_length)\n",
    "        #まず、受け取ったdout→(4,3)(N*out, FN)の形に直してから微分する\n",
    "        dout = dout.transpose(0,2,1)#(N,out_size,FN)\n",
    "        dout = dout.reshape(-1,self.filter_num)#(N*out_size, FN)\n",
    "        col_dX = np.dot(dout, self.col_W.T)\n",
    "        print('col_dX:', col_dX)\n",
    "        #(out_size,FN)dot(FN,filter_length*C)\n",
    "        dX = np.zeros_like(self.X).astype(np.float64)\n",
    "        print('dxshape',dX.shape)\n",
    "        #(filter_length * C, out_size)dot(out_size, FN)\n",
    "        self.grads['W'] = np.dot(self.col.T, dout)\n",
    "        print('gradW:', self.grads['W'])\n",
    "        self.grads['B'] = np.sum(dout,axis=0)\n",
    "        print('gradB:', self.grads['B'])\n",
    "        print('beforedx:', dX)\n",
    "        \n",
    "        #col_dXをdXに変換\n",
    "        col_dX_4d = \\\n",
    "        col_dX.reshape(self.N, self.out_size, self.C, self.filter_length)\n",
    "        col_dX_4d = col_dX_4d.transpose(0,2,3,1)\n",
    "        \n",
    "        for i in range(self.out_size):\n",
    "            dX[:,:,i : i + self.filter_length] += col_dX_4d[:,:,:,i]\n",
    "            print(str(i) + '回目dX:', dX)\n",
    "     \n",
    "        return dX\n",
    "    \n",
    "    def padding(self,X,padding):\n",
    "        return np.pad(X,[0,padding],'constant')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def calc_out_size(self, D, filter_length, padding, stride):\n",
    "        return (D - filter_length + 2 * padding) // stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "pad後x: [[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [13 14 15 16]]]\n",
      "Wshape: (3, 2, 3)\n",
      "out_size 2\n",
      "col_Wshape: (6, 3)\n",
      "初期化時colshape (4, 6)\n",
      "idxes [0 2]\n",
      "x部分shape (2, 2, 3)\n",
      "idxes [1 3]\n",
      "x部分shape (2, 2, 3)\n",
      "self.col [[ 1.  2.  3.  5.  6.  7.]\n",
      " [ 2.  3.  4.  6.  7.  8.]\n",
      " [ 9. 10. 11. 13. 14. 15.]\n",
      " [10. 11. 12. 14. 15. 16.]]\n",
      "colshape: (4, 6)\n",
      "out_col: [[25. 26. 27.]\n",
      " [31. 32. 33.]\n",
      " [73. 74. 75.]\n",
      " [79. 80. 81.]]\n",
      "outshape: (2, 3, 2)\n",
      "[[[25. 31.]\n",
      "  [26. 32.]\n",
      "  [27. 33.]]\n",
      "\n",
      " [[73. 79.]\n",
      "  [74. 80.]\n",
      "  [75. 81.]]]\n",
      "col_dX: [[ 78.  78.  78.  78.  78.  78.]\n",
      " [ 96.  96.  96.  96.  96.  96.]\n",
      " [222. 222. 222. 222. 222. 222.]\n",
      " [240. 240. 240. 240. 240. 240.]]\n",
      "dxshape (2, 2, 4)\n",
      "gradW: [[1534. 1556. 1578.]\n",
      " [1742. 1768. 1794.]\n",
      " [1950. 1980. 2010.]\n",
      " [2366. 2404. 2442.]\n",
      " [2574. 2616. 2658.]\n",
      " [2782. 2828. 2874.]]\n",
      "gradB: [208. 212. 216.]\n",
      "beforedx: [[[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]]\n",
      "0回目dX: [[[ 78.  78.  78.   0.]\n",
      "  [ 78.  78.  78.   0.]]\n",
      "\n",
      " [[222. 222. 222.   0.]\n",
      "  [222. 222. 222.   0.]]]\n",
      "1回目dX: [[[ 78. 174. 174.  96.]\n",
      "  [ 78. 174. 174.  96.]]\n",
      "\n",
      " [[222. 462. 462. 240.]\n",
      "  [222. 462. 462. 240.]]]\n",
      "dout [[[ 78. 174. 174.  96.]\n",
      "  [ 78. 174. 174.  96.]]\n",
      "\n",
      " [[222. 462. 462. 240.]\n",
      "  [222. 462. 462. 240.]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3])\n",
    "\n",
    "\n",
    "filter_num = 3\n",
    "filter_length = 3\n",
    "sigma = 0.01\n",
    "X_sample =np.arange(1,17,1).reshape(2,2,4)\n",
    "\n",
    "conv1d = SimpleConv1d_ver3_1(filter_num=filter_num,\n",
    "                      filter_length=filter_length, sigma = sigma,\n",
    "                      initializer=ConvSimpleInitializer, optimizer=SGD,\n",
    "                 opt_params={'lr' : 0.01}, padding=0)\n",
    "out = conv1d.forward(X_sample)\n",
    "print(out)\n",
    "delta_a = out\n",
    "\n",
    "#delta_a  = np.array([[16, 22], [17, 23], [18, 24]])\n",
    "dout = conv1d.backward(delta_a)\n",
    "\n",
    "\n",
    "\n",
    "print('dout', dout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題7 任意のストライド数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d_ver4_1:\n",
    "    \n",
    "    def __init__(self,filter_num, filter_length,\n",
    "                 initializer, optimizer,sigma,\n",
    "                 opt_params, stride=1, padding=0):\n",
    "        #self.input_shape= input_shape\n",
    "        self.filter_num = filter_num\n",
    "        self.filter_length = filter_length\n",
    "        print(self.filter_length)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.sigma = sigma\n",
    "        self.initializer = initializer(self.sigma)\n",
    "        self.optimizer = optimizer(**opt_params)\n",
    "        \n",
    "        \n",
    "        self.params = {}\n",
    "        self.grads = {}\n",
    "        self.X = None\n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        self.out_size = None\n",
    "        #self.params['W'] = self.initializer.W(self.filter_num, self.filter_length)\n",
    "        \n",
    "        #Wを縦ベクトルで定義する\n",
    "        self.params['W'] = np.ones((3, 2, 2))#(FN,C,filter_length)\n",
    "        \n",
    "        #self.params['B'] = self.initializer.B()\n",
    "        self.params['B'] = np.array([1, 2, 3]).reshape(1,-1)\n",
    "        self.dW = np.zeros_like(self.params['W'])\n",
    "        self.dB = np.zeros_like(self.params['B'])\n",
    "        self.grads['W'] = self.dW\n",
    "        self.grads['B'] = self.dB\n",
    "        \n",
    "        \n",
    "    def forward(self,X):\n",
    "        #batchsize,channel共に１のとき\n",
    "#         if X.ndim == 1:\n",
    "#             X = X[np.newaxis,np.newaxis,:]\n",
    "#         #batchsizeが１のとき\n",
    "#         if X.ndim == 2:\n",
    "#             X = X[np.newaxis,:,:]\n",
    "            \n",
    "        N,C,D = X.shape\n",
    "        self.C = C\n",
    "        self.D = D\n",
    "        self.N = N\n",
    "        \n",
    "        X = np.pad(X,[(0,0),(0,0),(self.padding,self.padding)],'constant')\n",
    "        print('pad後x:', X)\n",
    "        print('Wshape:',self.params['W'].shape)\n",
    "        self.X = X\n",
    "        \n",
    "        \n",
    "        self.out_size = self.calc_out_size(D, self.filter_length,\n",
    "                                           self.padding,self.stride)\n",
    "        print('out_size',self.out_size)\n",
    "        \n",
    "        #Wをcolに変換\n",
    "        col_W = self.params['W'].reshape(-1,self.filter_num)\n",
    "        self.col_W = col_W\n",
    "        print('col_Wshape:', col_W.shape)\n",
    "\n",
    "        self.col = np.zeros((self.N * self.out_size,\n",
    "                             self.C * self.filter_length))\n",
    "        \n",
    "        print('初期化時colshape', self.col.shape)\n",
    "\n",
    "        #Xをcolに変換\n",
    "        for i in range(self.out_size):\n",
    "            print('i',i)\n",
    "            idxes =np.arange(i,self.N * self.out_size,self.out_size)\n",
    "            print('idxes',idxes)\n",
    "            filtered_idx = self.stride * i\n",
    "            print('x部分shape', X[:, :,filtered_idx : filtered_idx+ \\\n",
    "                                self.filter_length].shape)\n",
    "            self.col[idxes,:] = X[:, :, i : i + self.filter_length].reshape(self.N,\n",
    "                                                                            -1)\n",
    "            \n",
    "        print('self.col',self.col)    \n",
    "        print('colshape:', self.col.shape)\n",
    "        out_col = np.dot(self.col, col_W) + \\\n",
    "        self.params['B']\n",
    "        print('out_col:', out_col)\n",
    "        out_col = out_col.reshape(self.N, self.out_size, self.filter_num)\n",
    "        out = out_col.transpose(0,2,1)\n",
    "        print('outshape:', out.shape)\n",
    "        return out#(N,FN,out_size)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        #shape: dout=(out_size,FN), col=(out_size,filter_length),\n",
    "        #W=(FN, filter_length)\n",
    "        #まず、受け取ったdout→(4,3)(N*out, FN)の形に直してから微分する\n",
    "        dout = dout.transpose(0,2,1)#(N,out_size,FN)\n",
    "        dout = dout.reshape(-1,self.filter_num)#(N*out_size, FN)\n",
    "        col_dX = np.dot(dout, self.col_W.T)\n",
    "        print('col_dX:', col_dX)\n",
    "        #(out_size,FN)dot(FN,filter_length*C)\n",
    "        dX = np.zeros_like(self.X).astype(np.float64)\n",
    "        print('dxshape',dX.shape)\n",
    "        #(filter_length * C, out_size)dot(out_size, FN)\n",
    "        self.grads['W'] = np.dot(self.col.T, dout)\n",
    "        print('gradW:', self.grads['W'])\n",
    "        self.grads['B'] = np.sum(dout,axis=0)\n",
    "        print('gradB:', self.grads['B'])\n",
    "        print('beforedx:', dX)\n",
    "        \n",
    "        #col_dXをdXに変換\n",
    "        col_dX_4d = \\\n",
    "        col_dX.reshape(self.N, self.out_size, self.C, self.filter_length)\n",
    "        col_dX_4d = col_dX_4d.transpose(0,2,3,1)\n",
    "        \n",
    "        for i in range(self.out_size):\n",
    "            filtered_idx = self.stride * i\n",
    "            dX[:,:,filtered_idx : filtered_idx + self.filter_length] \\\n",
    "            += col_dX_4d[:,:,:,i]\n",
    "            print(str(i) + '回目dX:', dX)\n",
    "     \n",
    "        return dX\n",
    "    \n",
    "    def padding(self,X,padding):\n",
    "        return np.pad(X,[0,padding],'constant')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def calc_out_size(self, D, filter_length, padding, stride):\n",
    "        print('fl',filter_length)\n",
    "        print('D',D)\n",
    "        return (D - filter_length + 2 * padding) // stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "pad後x: [[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [13 14 15 16]]]\n",
      "Wshape: (3, 2, 2)\n",
      "fl 2\n",
      "D 4\n",
      "out_size 2\n",
      "col_Wshape: (4, 3)\n",
      "初期化時colshape (4, 4)\n",
      "i 0\n",
      "idxes [0 2]\n",
      "x部分shape (2, 2, 2)\n",
      "i 1\n",
      "idxes [1 3]\n",
      "x部分shape (2, 2, 2)\n",
      "self.col [[ 1.  2.  5.  6.]\n",
      " [ 2.  3.  6.  7.]\n",
      " [ 9. 10. 13. 14.]\n",
      " [10. 11. 14. 15.]]\n",
      "colshape: (4, 4)\n",
      "out_col: [[15. 16. 17.]\n",
      " [19. 20. 21.]\n",
      " [47. 48. 49.]\n",
      " [51. 52. 53.]]\n",
      "outshape: (2, 3, 2)\n",
      "[[[15. 19.]\n",
      "  [16. 20.]\n",
      "  [17. 21.]]\n",
      "\n",
      " [[47. 51.]\n",
      "  [48. 52.]\n",
      "  [49. 53.]]]\n",
      "col_dX: [[ 48.  48.  48.  48.]\n",
      " [ 60.  60.  60.  60.]\n",
      " [144. 144. 144. 144.]\n",
      " [156. 156. 156. 156.]]\n",
      "dxshape (2, 2, 4)\n",
      "gradW: [[ 986. 1008. 1030.]\n",
      " [1118. 1144. 1170.]\n",
      " [1514. 1552. 1590.]\n",
      " [1646. 1688. 1730.]]\n",
      "gradB: [132. 136. 140.]\n",
      "beforedx: [[[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]]\n",
      "0回目dX: [[[ 48.  48.   0.   0.]\n",
      "  [ 48.  48.   0.   0.]]\n",
      "\n",
      " [[144. 144.   0.   0.]\n",
      "  [144. 144.   0.   0.]]]\n",
      "1回目dX: [[[ 48.  48.  60.  60.]\n",
      "  [ 48.  48.  60.  60.]]\n",
      "\n",
      " [[144. 144. 156. 156.]\n",
      "  [144. 144. 156. 156.]]]\n",
      "dout [[[ 48.  48.  60.  60.]\n",
      "  [ 48.  48.  60.  60.]]\n",
      "\n",
      " [[144. 144. 156. 156.]\n",
      "  [144. 144. 156. 156.]]]\n"
     ]
    }
   ],
   "source": [
    "filter_num = 3\n",
    "filter_length = 2\n",
    "sigma = 0.01\n",
    "X_sample =np.arange(1,17,1).reshape(2,2,4)\n",
    "\n",
    "conv1d = SimpleConv1d_ver4_1(filter_num=filter_num,\n",
    "                      filter_length=filter_length, sigma = sigma,\n",
    "                      initializer=ConvSimpleInitializer, optimizer=SGD,\n",
    "                 opt_params={'lr' : 0.01}, padding=0,stride=2)\n",
    "out = conv1d.forward(X_sample)\n",
    "print(out)\n",
    "delta_a = out\n",
    "\n",
    "#delta_a  = np.array([[16, 22], [17, 23], [18, 24]])\n",
    "dout = conv1d.backward(delta_a)\n",
    "\n",
    "\n",
    "\n",
    "print('dout', dout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題8 学習と推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d_completed:\n",
    "    \n",
    "    def __init__(self,filter_num, filter_length,\n",
    "                optimizer,sigma,\n",
    "                 opt_params, C,stride=1, padding=0):\n",
    "        #self.input_shape= input_shape\n",
    "        self.filter_num = filter_num\n",
    "        self.filter_length = filter_length\n",
    "        print(self.filter_length)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.sigma = sigma\n",
    "        self.C = C\n",
    "        #self.initializer = initializer(self.sigma)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        \n",
    "        self.params = {}\n",
    "        self.grads = {}\n",
    "        self.X = None\n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        self.out_size = None\n",
    "        #self.params['W'] = self.initializer.W(self.filter_num, self.filter_length)\n",
    "        \n",
    "        #Wを縦ベクトルで定義する\n",
    "        self.params['W'] = np.random.randn(self.filter_num,self.C, \n",
    "                                    self.filter_length) * self.sigma\n",
    "        #(FN,C,filter_length)\n",
    "        \n",
    "        #self.params['B'] = self.initializer.B()\n",
    "        self.params['B'] = np.random.randn(self.filter_num).reshape(1,-1) *\\\n",
    "        self.sigma\n",
    "        self.dW = np.zeros_like(self.params['W'])\n",
    "        self.dB = np.zeros_like(self.params['B'])\n",
    "        self.grads['W'] = self.dW\n",
    "        self.grads['B'] = self.dB\n",
    "        \n",
    "        \n",
    "    def forward(self,X):\n",
    "        #batchsize,channel共に１のとき\n",
    "#         if X.ndim == 1:\n",
    "#             X = X[np.newaxis,np.newaxis,:]\n",
    "#         #batchsizeが１のとき\n",
    "#         if X.ndim == 2:\n",
    "#             X = X[np.newaxis,:,:]\n",
    "            \n",
    "        N,C,D = X.shape\n",
    "        self.D = D\n",
    "        self.N = N\n",
    "        \n",
    "        X = np.pad(X,[(0,0),(0,0),(self.padding,self.padding)],'constant')\n",
    "#         print('pad後x:', X)\n",
    "#         print('Wshape:',self.params['W'].shape)\n",
    "        self.X = X\n",
    "        \n",
    "        \n",
    "        self.out_size = self.calc_out_size(D, self.filter_length,\n",
    "                                           self.padding,self.stride)\n",
    "#         print('out_size',self.out_size)\n",
    "        \n",
    "        #Wをcolに変換\n",
    "        col_W = self.params['W'].reshape(-1,self.filter_num)\n",
    "        self.col_W = col_W\n",
    "#         print('col_Wshape:', col_W.shape)\n",
    "\n",
    "        self.col = np.zeros((self.N * self.out_size,\n",
    "                             self.C * self.filter_length))\n",
    "        \n",
    "#         print('初期化時colshape', self.col.shape)\n",
    "\n",
    "        #Xをcolに変換\n",
    "        for i in range(self.out_size):\n",
    "#             print('i',i)\n",
    "            idxes =np.arange(i,self.N * self.out_size,self.out_size)\n",
    "#             print('idxes',idxes)\n",
    "            filtered_idx = self.stride * i\n",
    "#             print('x部分shape', X[:, :,filtered_idx : filtered_idx+ \\\n",
    "#                                 self.filter_length].shape)\n",
    "            self.col[idxes,:] = X[:, :, i : i + self.filter_length].reshape(self.N,\n",
    "                                                                            -1)\n",
    "            \n",
    "#         print('self.col',self.col)    \n",
    "#         print('colshape:', self.col.shape)\n",
    "        out_col = np.dot(self.col, col_W) + \\\n",
    "        self.params['B']\n",
    "#         print('out_col:', out_col)\n",
    "        out_col = out_col.reshape(self.N, self.out_size, self.filter_num)\n",
    "        out = out_col.transpose(0,2,1)\n",
    "#         print('outshape:', out.shape)\n",
    "        return out#(N,FN,out_size)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        #shape: dout=(out_size,FN), col=(out_size,filter_length),\n",
    "        #W=(FN, filter_length)\n",
    "        #まず、受け取ったdout→(4,3)(N*out, FN)の形に直してから微分する\n",
    "        dout = dout.transpose(0,2,1)#(N,out_size,FN)\n",
    "        dout = dout.reshape(-1,self.filter_num)#(N*out_size, FN)\n",
    "        col_dX = np.dot(dout, self.col_W.T)\n",
    "#         print('col_dX:', col_dX)\n",
    "        #(out_size,FN)dot(FN,filter_length*C)\n",
    "        dX = np.zeros_like(self.X).astype(np.float64)\n",
    "#         print('dxshape',dX.shape)\n",
    "        #(filter_length * C, out_size)dot(out_size, FN)\n",
    "        self.grads['W'] = np.dot(self.col.T, dout)\n",
    "#         print('gradW:', self.grads['W'])\n",
    "        self.grads['B'] = np.sum(dout,axis=0)\n",
    "#         print('gradB:', self.grads['B'])\n",
    "#         print('beforedx:', dX)\n",
    "        \n",
    "        #col_dXをdXに変換\n",
    "        col_dX_4d = \\\n",
    "        col_dX.reshape(self.N, self.out_size, self.C, self.filter_length)\n",
    "        col_dX_4d = col_dX_4d.transpose(0,2,3,1)\n",
    "        \n",
    "        for i in range(self.out_size):\n",
    "            filtered_idx = self.stride * i\n",
    "            dX[:,:,filtered_idx : filtered_idx + self.filter_length] \\\n",
    "            += col_dX_4d[:,:,:,i]\n",
    "#             print(str(i) + '回目dX:', dX)\n",
    "     \n",
    "        return dX\n",
    "    \n",
    "    def padding(self,X,padding):\n",
    "        return np.pad(X,[0,padding],'constant')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def calc_out_size(self, D, filter_length, padding, stride):\n",
    "#         print('fl',filter_length)\n",
    "#         print('D',D)\n",
    "        return (D - filter_length + 2 * padding) // stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "(60000, 784)\n",
      "(60000,)\n",
      "(60000,)\n",
      "(60000, 10)\n",
      "float32\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1,784)\n",
    "X_test = X_test.reshape(-1,784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max())\n",
    "print(X_train.min())\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=10)\n",
    "print(y_train.shape)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64\n",
    "print(type(y_train_one_hot))\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot,\n",
    "                                                 test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "out_size: 782\n",
      "affine_input_shape: 2346\n",
      "*********1エポック*********\n",
      "loss: 2.308711457179881\n",
      "*********2エポック*********\n",
      "loss: 2.307944453203697\n",
      "*********3エポック*********\n",
      "loss: 2.3071999207398917\n",
      "*********4エポック*********\n",
      "loss: 2.3064799426649785\n",
      "*********5エポック*********\n",
      "loss: 2.3057859117647914\n"
     ]
    }
   ],
   "source": [
    "network = ScratchSimpleNeuralNetrowkClassifier(input_shape=784, n_classes=10, n_nodes1=400,\n",
    "                                              n_nodes2 = 200, initializer=SimpleInitializer, optimizer=SGD,sigma = 0.01, opt_params={'lr' : 0.01})\n",
    "\n",
    "\n",
    "trainer = Trainer(model=network, n_epochs=5, batch=20)\n",
    "trainer.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class ScratchSimpleNeuralNetrowkClassifier:\n",
    "    def __init__(self, input_shape, n_classes, n_nodes1, n_nodes2,\n",
    "                 initializer,optimizer, sigma,opt_params):\n",
    "        self.input_shape = input_shape\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.sigma = sigma \n",
    "        self.initializer = initializer(sigma)\n",
    "        self.optimizer_0 = optimizer(**opt_params)\n",
    "        self.optimizer_1 = optimizer(**opt_params)\n",
    "        self.optimizer_2 = optimizer(**opt_params)\n",
    "        self.optimizer_3 = optimizer(**opt_params)\n",
    "        #self.optimizer = optimizer(self.alpha, self.batch)\n",
    "        self.conv_layer = SimpleConv1d_completed(\n",
    "        filter_num=3, filter_length=3,\n",
    "                 optimizer=self.optimizer_0,sigma=0.01,\n",
    "                 opt_params={'lr' : 0.01}, C=1)\n",
    "        #out=(N,FN,out_size)\n",
    "        #out_sizeを計算：\n",
    "        self.out_size = self.conv_layer.calc_out_size(self.input_shape, filter_length=3, padding=0, stride=1)\n",
    "        print('out_size:', self.out_size)\n",
    "        affine_input_shape = 3 * self.out_size\n",
    "        print('affine_input_shape:', affine_input_shape)\n",
    "        self.layers = OrderedDict()\n",
    "   \n",
    "        self.layers['Affine1'] = FC(affine_input_shape, self.n_nodes1,\n",
    "                                   self.initializer, self.optimizer_1)\n",
    "        self.layers['Sigmoid1'] = Sigmoid()\n",
    "        self.layers['Affine2'] = FC(self.n_nodes1, self.n_nodes2,\n",
    "                                   self.initializer, self.optimizer_2)\n",
    "        self.layers['Sigmoid2'] = Sigmoid()\n",
    "        self.layers['Affine3'] = FC(self.n_nodes2, n_classes,self.initializer,\n",
    "                                   self.optimizer_3)\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "        \n",
    "    def forward(self,X,y):\n",
    "        \n",
    "        self.N,self.D = X.shape\n",
    "        X = X[:,np.newaxis,:]\n",
    "        X = self.conv_layer.forward(X)\n",
    "        N,self.filter_num,self.out_size = X.shape\n",
    "        X = X.reshape(N,-1)\n",
    "        \n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        loss = self.last_layer.forward(X,y)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def backward(self,dout=1):\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "        \n",
    "        dout = dout.reshape(self.N,self.filter_num,self.out_size)\n",
    "        dout = self.conv_layer.backward(dout)\n",
    "    \n",
    "    def predict(self,X):\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "        return np.argmax(X,axis=1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def accuracy(self,X,y):\n",
    "        y_pred = self.predict(X)\n",
    "        y = np.argmax(y,axis=1)\n",
    "        print('y_pred: ', y_pred)\n",
    "        print('y: ', y)\n",
    "        return 100 * np.sum(y_pred == y) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここから前回の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        \n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.params = {}\n",
    "        self.grads = {}\n",
    "        self.W = self.initializer.W(self.n_nodes1, self.n_nodes2)\n",
    "        self.B = self.initializer.B(self.n_nodes2)\n",
    "        self.params['W'] = self.W\n",
    "        self.params['B'] = self.B\n",
    "        self.X = None\n",
    "        self.dW = np.zeros_like(self.W)\n",
    "        self.dB = np.zeros_like(self.B)\n",
    "        self.grads['W'] = self.dW\n",
    "        self.grads['B'] = self.dB\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        self.X = X\n",
    "        A = np.dot(X,self.W) + self.B\n",
    "        return A\n",
    "    def backward(self, dA):#x=(N,D) w=(D,H),A=(N,H))\n",
    "#         print('dAの値：', dA)\n",
    "#         print('Xの値：', self.X)\n",
    "        dZ = np.dot(dA, self.W.T)\n",
    "        self.grads['W'][...] = np.dot(self.X.T, dA)\n",
    "        self.grads['B'][...] = np.sum(dA,axis=0)\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = np.random.randn(n_nodes1, n_nodes2) * self.sigma\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        \n",
    "        B = np.random.randn(n_nodes2,)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        grads = layer.grads\n",
    "        for key in layer.params.keys():\n",
    "            #print('勾配：', grads[key])\n",
    "            layer.params[key] -= self.lr * grads[key]\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.z = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        z = 1 / (1 + np.exp(-x))\n",
    "        self.z = z\n",
    "        return z\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        return self.z * (1 - self.z) * dout\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def init(self):\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    \n",
    "    def forward(self,a,t):\n",
    "        self.t = t\n",
    "        a_max = np.max(a,axis=1).reshape(-1,1)\n",
    "        a_exp = np.exp(a - a_max)\n",
    "        a_sum = np.sum(a_exp,axis=1)\n",
    "        y = a_exp / a_sum.reshape(-1,1)\n",
    "        self.y = y\n",
    "        \n",
    "        loss = self.mean_cross_entropy(y,t)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self,dout=1):\n",
    "        return (self.y - self.t) / len(self.t)\n",
    "    \n",
    "    def mean_cross_entropy(self,y,t,eps=1e-7):\n",
    "        return - np.sum(t * np.log(y + eps)) / len(t)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self,model, n_epochs, batch):\n",
    "        self.model = model\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch = batch\n",
    "        self.loss_list = []\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \n",
    "        for i in range(self.n_epochs):\n",
    "            print('*********' + str(i+1) + 'エポック*********')\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=20)\n",
    "            count = 0\n",
    "            for x_mini, y_mini in get_mini_batch:\n",
    "                count += 1\n",
    "                loss = self.model.forward(x_mini,y_mini)\n",
    "                \n",
    "                self.model.backward()\n",
    "                if count == len(get_mini_batch):\n",
    "                    self.loss_list.append(loss)\n",
    "                    print('loss:',loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    def __init__(self, X, y, batch_size=20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0] / self.batch_size).astype(np.int)\n",
    "        #self.stopは作成するバッチサイズ数。１エポック分作成する\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    #指定したバッチ番号を取ってきてくれる\n",
    "    def __getitem__(self, item):\n",
    "        p0 = item * self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0 : p1], self._y[p0 : p1]\n",
    "\n",
    "    \n",
    "    \n",
    "    #batchカウンターを初期化する\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    \n",
    "    #batchを前から一つずつ取ってくる\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter * self.batch_size\n",
    "        p1 = self._counter * self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0 : p1], self._y[p0 : p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
