{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題1 学習と推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faster_R-CNN.ipynb参照"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題2 論文と実装の対応"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重要だと思う部分のコードに関して、#の青文字で記載"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'losses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6b66fbec9b83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'losses'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "from model import losses as losses\n",
    "from model import resnet as nn\n",
    "\n",
    "#おそらくCがRPNの何か\n",
    "def get_model(C, classes_count):\n",
    "    #画像の入力\n",
    "    img_input = Input(shape=(None, None, 3))\n",
    "    #region_proposalの入力\n",
    "    roi_input = Input(shape=(C.num_rois, 4))\n",
    "\n",
    "    # define the base network (resnet here)\n",
    "    # RPNとFast R-CNNで共有する特徴マップ\n",
    "    shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "    # define the RPN, built on the base layers\n",
    "    #アンカーボックス数を設定\n",
    "    num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
    "    #アンカーの数、特徴マップを渡してrpnを生成\n",
    "    #特徴マップに対してconv2dを適用して各アンカーボックスに対する奥行き（オフセット、クラス）を生成する\n",
    "    rpn = nn.rpn(shared_layers, num_anchors)\n",
    "\n",
    "    # define the classifer, built on the base layers\n",
    "    #引数=(resnetによって抽出された特徴マップ、roiのインプット、roiのインプット数、クラス数、trainable)\n",
    "    classifier = nn.classifier(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count), trainable=True)\n",
    "\n",
    "    # defining the models and a model that holds both the RPN and the classifier\n",
    "    model_rpn = Model(img_input, rpn[:2])\n",
    "    model_classifier = Model([img_input, roi_input], classifier)\n",
    "    model_all = Model([img_input, roi_input], rpn[:2] + classifier)\n",
    "\n",
    "    model_rpn.compile(optimizer=Adam(lr=1e-4), loss=[losses.rpn_loss_cls(num_anchors), losses.rpn_loss_regr(num_anchors)])\n",
    "    model_classifier.compile(optimizer=Adam(lr=1e-4), loss=[losses.class_loss_cls, losses.class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n",
    "    model_all.compile(optimizer='sgd', loss='mae')\n",
    "\n",
    "    return model_rpn, model_classifier, model_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__future__は言語に関数基本的な事柄を変更する\n",
    "\n",
    "from __future__ import print_function\n",
    "#相対インポートの設定\n",
    "from __future__ import absolute_import \n",
    "\n",
    "from keras.layers import Input, Add, Dense, Activation, Flatten,\\\n",
    "Convolution2D, AveragePooling2D,TimeDistributed\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "def nn_base(input_tensor=None, trainable=False):\n",
    "    \n",
    "    #resnetへの入力の形状(不明のとき)\n",
    "    input_shape = (None, None, 3)\n",
    "    \n",
    "    if input_tensor is None:\n",
    "        #input_tensorが空の場合ここでkerasのinputを生成\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        #input_tensorが空出ないが、kerasのテンソルでない場合\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            #keras化する\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            #keras型なのでそのまま入れる\n",
    "            img_input = input_tensor\n",
    "    \n",
    "    bn_axis = 3#channel数\n",
    "    #ZeroPadding2Dで上下にpaddingを追加する\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    #trainable=Trueで訓練する\n",
    "    x = Convolution2D(64,(7,7), strides=(2,2), name='conv1',\n",
    "                      trainble=trainable)\n",
    "    x = FixedBatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ab0443663a49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#FixedBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitialziers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#FixedBatchNormalization\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras import initialziers, regularizers\n",
    "from keras import backend as K\n",
    "\n",
    "class FixedBatchNormalization(Layer):\n",
    "    def __init__(self, epsilon=1e-3, axis=-1,\n",
    "                weights=None, beta_init='zero', gamma_init='one',\n",
    "                gamma_regularizer=None, beta_regularizer=None,\n",
    "                **kwargs):\n",
    "        \n",
    "        self.supports_masking = True\n",
    "        self.beta_init = initializiers.get(beta_init)\n",
    "        print(self.beta_init)\n",
    "        #初期化方法を定義\n",
    "        self.gamma_init = initializiers.get(gamma_init)\n",
    "        print(self.gamma_init)\n",
    "        self.epsilon = epsilon\n",
    "        self.axis = axis\n",
    "        #正規化の方法を定義\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        print(self.gamma_regularizer)\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        print(self.beta_regularizer)\n",
    "        self.initial_weights = weights\n",
    "        super(FixedBatchNormalization, self).__init__(**kwargs)\n",
    "        \n",
    "    #初期値を定義する\n",
    "    def build(self, input_shape):\n",
    "#         add_weight（）を呼び出してから、スーパーのbuild（）を呼び出します\n",
    "#         （self.built = Trueに設定します。これは、ユーザーが最初の__call__の\n",
    "#         前にbuild（）を手動で呼び出したい場合に便利です）。\n",
    "        \n",
    "        #つまりbuildを呼び出す前のadd_weightの設定を行う\n",
    "        #built=Trueにすることでカスタムのbuildの設定を完了する\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        shape = (input_shape[self.axis],)#(C,)\n",
    "        #shape=(C,)でgamma,beta,mean,stdを定義\n",
    "        self.gamma = self.add_weight(shape,\n",
    "                                    initializer=self.gamma_init,\n",
    "                                    regularizer=self.gamma_regularizer,\n",
    "                                    name='{}_gamma'.format(self.name),\n",
    "                                    trainable=False)\n",
    "        self.beta = self.add_weight(shape,\n",
    "                                   initializer=self.beta_init,\n",
    "                                   regularizer=self.beta_regularizer,\n",
    "                                   name='{}_beta'.format(self.name),\n",
    "                                   trainable=False)\n",
    "        self.running_mean = self.add_weight(shape,initializer='zero',\n",
    "                                           name='{}_running_mean'.format(self.name))\n",
    "        self.running_std = self.add_weight(shape, initializer='one',\n",
    "                                          name='{}_running_std'.format(self.name))\n",
    "        \n",
    "        print(self.running_std)\n",
    "        \n",
    "        if self.initial_weights is not None:\n",
    "            #引数にweightがあればweightを設定する\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "            \n",
    "        self.built = True\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        #assert 条件式　エラー文\n",
    "        #条件式がfalseの場合、エラー文を投げる。\n",
    "        #この場合buildが完了しているか確認している\n",
    "        assert self.built, 'Layer must be built before being called'\n",
    "        \n",
    "        input_shape = K.int_shape(x)#xのshape(tuple)を獲得\n",
    "        reduction_axes = list(range(len(input_shape)))#shapeのリスト\n",
    "        del reduction_axes[self.axis]#channel方向を削除\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題3 学習済みの重みによる推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際にbboxを付した画像は、Google colab上で行なっていたため、セッションが切れた際に紛失しました。ログが残っているのでそちらを記します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-5d298dbf273e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-5d298dbf273e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Found 1 boxes for img\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Found 1 boxes for img\n",
    "person 0.73 (26, 79) (554, 409)\n",
    "4.272179343000062\n",
    "Input image filename:/content/keras-yolo3/simpsons_dataset/carl_carlson/pic_0004.jpg\n",
    "(416, 416, 3)\n",
    "Found 0 boxes for img\n",
    "1.7000756250004088\n",
    "Input image filename:/content/keras-yolo3/simpsons_dataset/carl_carlson/pic_0001.jpg\n",
    "(416, 416, 3)\n",
    "Found 1 boxes for img\n",
    "person 0.91 (227, 82) (320, 450)\n",
    "1.6344884119998824\n",
    "Input image filename:/content/keras-yolo3/simpsons_dataset/carl_carlson/pic_0085.jpg\n",
    "(416, 416, 3)\n",
    "Found 0 boxes for img\n",
    "1.6449777230000109\n",
    "Input image filename:/content/keras-yolo3/simpsons_dataset/carl_carlson/pic_0085.jpg\n",
    "(416, 416, 3)\n",
    "Found 0 boxes for img\n",
    "1.6431265849996635\n",
    "Input image filename:/content/keras-yolo3/simpsons_dataset/carl_carlson/pic_0077.jpg\n",
    "(416, 416, 3)\n",
    "Found 1 boxes for img\n",
    "fire hydrant 0.40 (97, 28) (250, 242)\n",
    "1.6575630780007486\n",
    "Input image filename:/content/keras-yolo3/simpsons_dataset/barney_gumble/pic_0001.jpg\n",
    "(416, 416, 3)\n",
    "Found 0 boxes for img\n",
    "1.6473533620001035\n",
    "Input image filename:/content/keras-yolo3/simpsons_dataset/barney_gumble/pic_0005.jpg\n",
    "(416, 416, 3)\n",
    "Found 0 boxes for img\n",
    "1.6330609899996489\n",
    "Input image filename:/content/keras-yolo3/simpsons_dataset/barney_gumble/pic_0011.jpg\n",
    "(416, 416, 3)\n",
    "Found 0 boxes for img\n",
    "1.6330044970000017\n",
    "Input image filename:/content/keras-yolo3/simpsons_dataset/chief_wiggum/pic_0003.jpg\n",
    "(416, 416, 3)\n",
    "Found 0 boxes for img\n",
    "1.6340531550004016\n",
    "Input image filename:/content/keras-yolo3/simpsons_dataset/homer_simpson/pic_0002.jpg\n",
    "(416, 416, 3)\n",
    "Found 0 boxes for img\n",
    "1.954918448999706\n",
    "Input image filename:/content/keras-yolo3/simpsons_dataset/homer_simpson/pic_0005.jpg\n",
    "(416, 416, 3)\n",
    "Found 0 boxes for img\n",
    "1.6352981849995558\n",
    "Input image filename:/content/keras-yolo3/simpsons_dataset/gil/pic_0007.jpg\n",
    "(416, 416, 3)\n",
    "Found 1 boxes for img\n",
    "kite 0.47 (107, 13) (619, 346)\n",
    "1.6652927129998716\n",
    "Input image filename:Traceback (most recent call last):\n",
    "  File \"yolo_video.py\", line 72, in <module>\n",
    "    detect_img(YOLO(**vars(FLAGS)))\n",
    "  File \"yolo_video.py\", line 8, in detect_img\n",
    "    img = input('Input image filename:')\n",
    "KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題4 学習のためのファイルを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "annotation.csv参照"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題5 学習が行えることの確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習が実行できたことを示すログを下記に添付します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-519264450b9a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-519264450b9a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Using TensorFlow backend.\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Using TensorFlow backend.\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
    "\n",
    "2019-12-18 11:41:24.903793: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
    "2019-12-18 11:41:24.904023: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2114bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    "2019-12-18 11:41:24.904057: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    "2019-12-18 11:41:24.906129: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
    "2019-12-18 11:41:24.908098: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
    "2019-12-18 11:41:24.908137: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (2589ef97a2b3): /proc/driver/nvidia/version does not exist\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
    "\n",
    "Create YOLOv3 model with 9 anchors and 18 classes.\n",
    "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1281: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 69) vs (255, 1024, 1, 1)).\n",
    "  weight_values[i].shape))\n",
    "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1281: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((69,) vs (255,)).\n",
    "  weight_values[i].shape))\n",
    "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1281: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 69) vs (255, 512, 1, 1)).\n",
    "  weight_values[i].shape))\n",
    "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1281: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((69,) vs (255,)).\n",
    "  weight_values[i].shape))\n",
    "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1281: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 69) vs (255, 256, 1, 1)).\n",
    "  weight_values[i].shape))\n",
    "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1281: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((69,) vs (255,)).\n",
    "  weight_values[i].shape))\n",
    "Load weights model_data/yolo_weights.h5.\n",
    "Freeze the first 249 layers of total 252 layers.\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3351: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
    "\n",
    "Train on 6077 samples, val on 675 samples, with batch size 32.\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
    "\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
    "\n",
    "Epoch 1/50\n",
    "2019-12-18 11:41:44.705497: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] shape_optimizer failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
    "2019-12-18 11:41:44.800962: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
    "2019-12-18 11:41:45.665726: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] shape_optimizer failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
    "2019-12-18 11:41:45.738936: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:533] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
    "2019-12-18 11:41:47.321074: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 708837376 exceeds 10% of system memory.\n",
    "2019-12-18 11:41:53.047770: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 712249344 exceeds 10% of system memory.\n",
    "2019-12-18 11:41:55.280101: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 354418688 exceeds 10% of system memory.\n",
    "tcmalloc: large alloc 1594982400 bytes == 0xd5504000 @  0x7f7fc7dc91e7 0x7f7f8df6f192 0x7f7f91b4416a 0x7f7f91b87019 0x7f7f91b891e7 0x7f7f91b899f1 0x7f7f91bcf8db 0x7f7f91bcff7c 0x7f7f91bd133c 0x7f7f893e7f36 0x7f7f893da585 0x7f7f894986b9 0x7f7f89495d88 0x7f7fc66ab66f 0x7f7fc778d6db 0x7f7fc7ac688f\n",
    "2019-12-18 11:41:57.988557: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 354418688 exceeds 10% of system memory.\n",
    "2019-12-18 11:42:00.784998: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 354418688 exceeds 10% of system memory.\n",
    "tcmalloc: large alloc 1594982400 bytes == 0xbffc2000 @  0x7f7fc7dc91e7 0x7f7f8df6f192 0x7f7f91b4416a 0x7f7f91b87019 0x7f7f91b891e7 0x7f7f91b899f1 0x7f7f91bcf8db 0x7f7f91bcff7c 0x7f7f91bd133c 0x7f7f893e7f36 0x7f7f893da585 0x7f7f894986b9 0x7f7f89495d88 0x7f7fc66ab66f 0x7f7fc778d6db 0x7f7fc7ac688f\n",
    "  1/189 [..............................] - ETA: 4:20:21 - loss: 8217.9639tcmalloc: large alloc 1594982400 bytes == 0x149856000 @  0x7f7fc7dc91e7 0x7f7f8df6f192 0x7f7f91b4416a 0x7f7f91b87019 0x7f7f91b891e7 0x7f7f91b899f1 0x7f7f91bcf8db 0x7f7f91bcff7c 0x7f7f91bd133c 0x7f7f893e7f36 0x7f7f893da585 0x7f7f894986b9 0x7f7f89495d88 0x7f7fc66ab66f 0x7f7fc778d6db 0x7f7fc7ac688f\n",
    "tcmalloc: large alloc 1594982400 bytes == 0x134314000 @  0x7f7fc7dc91e7 0x7f7f8df6f192 0x7f7f91b4416a 0x7f7f91b87019 0x7f7f91b891e7 0x7f7f91b899f1 0x7f7f91bcf8db 0x7f7f91bcff7c 0x7f7f91bd133c 0x7f7f893e7f36 0x7f7f893da585 0x7f7f894986b9 0x7f7f89495d88 0x7f7fc66ab66f 0x7f7fc778d6db 0x7f7fc7ac688f\n",
    " 12/189 [>.............................] - ETA: 2:37:12 - loss: 4657.3961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
