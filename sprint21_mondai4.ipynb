{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_dataset = \\\n",
    "  [\"This movie is very good.\",\n",
    "  \"This film is a good\",\n",
    "  \"Very bad. Very, very bad.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['This', 'movie', 'is', 'very', 'good'], ['This', 'film', 'is', 'a', 'good'], ['Very', 'bad', 'Very,', 'very', 'bad']]\n"
     ]
    }
   ],
   "source": [
    "data_set = []\n",
    "for s in mini_dataset:\n",
    "    s = s.replace('.', '')\n",
    "    s = s.replace(',', )\n",
    "    s_list = s.split(' ')\n",
    "    data_set.append(s_list)\n",
    "    \n",
    "print(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = mini_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'r', '.', 's', 'V', 'y', 'v', ' ', 'b', 'l', 'h', 'm', 'o', 'g', ',', 'e', 'i', 'a', 'd', 'f']\n",
      "{'T': 1.2876820724517808, 'r': 1.2876820724517808, '.': 1.2876820724517808, 's': 1.2876820724517808, 'V': 1.6931471805599454, 'y': 1.2876820724517808, 'v': 1.2876820724517808, ' ': 1.0, 'b': 1.6931471805599454, 'l': 1.6931471805599454, 'h': 1.2876820724517808, 'm': 1.2876820724517808, 'o': 1.2876820724517808, 'g': 1.2876820724517808, ',': 1.6931471805599454, 'e': 1.2876820724517808, 'i': 1.2876820724517808, 'a': 1.2876820724517808, 'd': 1.0, 'f': 1.6931471805599454}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "featurenames = list(set([w for s in D for w in s]))\n",
    "print(featurenames)\n",
    "n_samples = len(D)\n",
    "word_dict = {}\n",
    "count = 1\n",
    "for w in featurenames:\n",
    "    word_dict[w] = count\n",
    "    count +=1\n",
    "id_corpus = []\n",
    "for d in D:\n",
    "    id_corpus.append(list(set([word_dict[w] for w in d])))\n",
    "num_feature = len(featurenames)\n",
    "X = []\n",
    "for corpus in id_corpus:\n",
    "    b = np.zeros(num_feature)\n",
    "    for i in corpus:\n",
    "        b[i-1] = 1\n",
    "    X.append(b)\n",
    "X = np.array(X)\n",
    "word_idf_dict = {}\n",
    "for w in featurenames:\n",
    "    df = np.sum(X[:,word_dict[w] - 1])\n",
    "    word_idf_dict[w] = np.log((n_samples + 1.0) / (df + 1.0) ) + 1.0\n",
    "print(word_idf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
