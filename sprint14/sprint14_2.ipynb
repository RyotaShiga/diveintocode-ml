{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題1 公式チュートリアルモデルを分担して実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaskingNoiseAutoencoderRunner.ipynbを参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題3 Iris(2値分類)をKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"../Sprint13/Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1209 11:54:06.991743 4799473088 deprecation.py:506] From //anaconda3/envs/aistudio/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,451\n",
      "Trainable params: 5,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Sequentialモデルの使用\n",
    "from keras import backend as K \n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation=tf.nn.relu,\n",
    "                               input_shape=(4, )))\n",
    "model.add(tf.keras.layers.Dense(100, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1209 11:56:34.229336 4799473088 deprecation.py:323] From //anaconda3/envs/aistudio/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.8250 - acc: 0.5000 - val_loss: 0.6324 - val_acc: 0.6250\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 650us/sample - loss: 0.6050 - acc: 0.6719 - val_loss: 0.6658 - val_acc: 0.3750\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 670us/sample - loss: 0.5220 - acc: 0.7969 - val_loss: 0.4259 - val_acc: 0.8750\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 712us/sample - loss: 0.4330 - acc: 0.8281 - val_loss: 0.4796 - val_acc: 0.6875\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 535us/sample - loss: 0.3813 - acc: 0.7969 - val_loss: 0.3377 - val_acc: 0.8125\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 654us/sample - loss: 0.2604 - acc: 0.9062 - val_loss: 0.1457 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 533us/sample - loss: 0.1915 - acc: 0.9375 - val_loss: 0.1080 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.2049 - acc: 0.9062 - val_loss: 0.1500 - val_acc: 0.9375\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 675us/sample - loss: 0.2566 - acc: 0.9219 - val_loss: 0.3724 - val_acc: 0.8125\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 714us/sample - loss: 0.2108 - acc: 0.9375 - val_loss: 0.0754 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 725us/sample - loss: 0.1359 - acc: 0.9375 - val_loss: 0.0611 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 523us/sample - loss: 0.1124 - acc: 0.9531 - val_loss: 0.0661 - val_acc: 0.9375\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 803us/sample - loss: 0.1540 - acc: 0.9531 - val_loss: 0.0513 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 712us/sample - loss: 0.1667 - acc: 0.9219 - val_loss: 0.1164 - val_acc: 0.9375\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 681us/sample - loss: 0.0775 - acc: 0.9844 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0100 - acc: 1.000 - 0s 787us/sample - loss: 0.0525 - acc: 0.9844 - val_loss: 0.2291 - val_acc: 0.8750\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 743us/sample - loss: 0.4408 - acc: 0.8594 - val_loss: 0.2206 - val_acc: 0.8125\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 924us/sample - loss: 0.3084 - acc: 0.8281 - val_loss: 0.1567 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 511us/sample - loss: 0.2288 - acc: 0.8750 - val_loss: 0.3162 - val_acc: 0.8125\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 642us/sample - loss: 0.1240 - acc: 0.9531 - val_loss: 0.0583 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 644us/sample - loss: 0.0890 - acc: 0.9688 - val_loss: 0.1153 - val_acc: 0.9375\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 537us/sample - loss: 0.1325 - acc: 0.9375 - val_loss: 0.0454 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 658us/sample - loss: 0.1550 - acc: 0.9531 - val_loss: 0.0448 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 696us/sample - loss: 0.1201 - acc: 0.9531 - val_loss: 0.0432 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 692us/sample - loss: 0.1102 - acc: 0.9531 - val_loss: 0.0664 - val_acc: 0.9375\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 681us/sample - loss: 0.0942 - acc: 0.9531 - val_loss: 0.0492 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 812us/sample - loss: 0.0537 - acc: 1.0000 - val_loss: 0.0801 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 633us/sample - loss: 0.1135 - acc: 0.9531 - val_loss: 0.0289 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 662us/sample - loss: 0.1008 - acc: 0.9688 - val_loss: 0.0928 - val_acc: 0.9375\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 629us/sample - loss: 0.1579 - acc: 0.9219 - val_loss: 0.0724 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 660us/sample - loss: 0.0723 - acc: 0.9688 - val_loss: 0.1613 - val_acc: 0.9375\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 544us/sample - loss: 0.1212 - acc: 0.9375 - val_loss: 0.0882 - val_acc: 0.9375\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 678us/sample - loss: 0.1480 - acc: 0.9531 - val_loss: 0.5669 - val_acc: 0.8750\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 795us/sample - loss: 0.3268 - acc: 0.8750 - val_loss: 0.2088 - val_acc: 0.8750\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 785us/sample - loss: 0.1281 - acc: 0.9531 - val_loss: 0.0443 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.0763 - acc: 0.9688 - val_loss: 0.0326 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 814us/sample - loss: 0.0974 - acc: 0.9688 - val_loss: 0.2155 - val_acc: 0.8750\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 526us/sample - loss: 0.1493 - acc: 0.9219 - val_loss: 0.0511 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 508us/sample - loss: 0.1184 - acc: 0.9531 - val_loss: 0.0397 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 614us/sample - loss: 0.1306 - acc: 0.9531 - val_loss: 0.3820 - val_acc: 0.8750\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 532us/sample - loss: 0.3617 - acc: 0.8906 - val_loss: 0.1388 - val_acc: 0.9375\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 593us/sample - loss: 0.1458 - acc: 0.9375 - val_loss: 0.0517 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 570us/sample - loss: 0.1189 - acc: 0.9688 - val_loss: 0.1969 - val_acc: 0.8125\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 606us/sample - loss: 0.5799 - acc: 0.8125 - val_loss: 0.3953 - val_acc: 0.7500\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 623us/sample - loss: 0.2876 - acc: 0.8750 - val_loss: 0.2094 - val_acc: 0.9375\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 640us/sample - loss: 0.1321 - acc: 0.9844 - val_loss: 0.0633 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 648us/sample - loss: 0.0955 - acc: 0.9531 - val_loss: 0.2455 - val_acc: 0.9375\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 736us/sample - loss: 0.1320 - acc: 0.9375 - val_loss: 0.0364 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 743us/sample - loss: 0.1490 - acc: 0.9531 - val_loss: 0.0647 - val_acc: 0.9375\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0074 - acc: 1.000 - 0s 816us/sample - loss: 0.2038 - acc: 0.8906 - val_loss: 0.3598 - val_acc: 0.8750\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 768us/sample - loss: 0.2820 - acc: 0.8750 - val_loss: 0.1069 - val_acc: 0.9375\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 606us/sample - loss: 0.2327 - acc: 0.9219 - val_loss: 0.1050 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 601us/sample - loss: 0.1208 - acc: 0.9688 - val_loss: 0.2632 - val_acc: 0.7500\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 686us/sample - loss: 0.1862 - acc: 0.9531 - val_loss: 0.0451 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 889us/sample - loss: 0.0939 - acc: 0.9688 - val_loss: 0.1312 - val_acc: 0.9375\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 687us/sample - loss: 0.2386 - acc: 0.9062 - val_loss: 0.0431 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 622us/sample - loss: 0.0938 - acc: 0.9688 - val_loss: 0.0480 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 747us/sample - loss: 0.1297 - acc: 0.9688 - val_loss: 0.0677 - val_acc: 0.9375\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 715us/sample - loss: 0.0907 - acc: 0.9531 - val_loss: 0.0421 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 721us/sample - loss: 0.0943 - acc: 0.9688 - val_loss: 0.1486 - val_acc: 0.9375\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 675us/sample - loss: 0.1991 - acc: 0.8906 - val_loss: 0.0276 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 541us/sample - loss: 0.1433 - acc: 0.9375 - val_loss: 0.0286 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 576us/sample - loss: 0.1280 - acc: 0.9531 - val_loss: 0.0319 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 524us/sample - loss: 0.0768 - acc: 0.9688 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 503us/sample - loss: 0.1565 - acc: 0.9375 - val_loss: 0.1324 - val_acc: 0.9375\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 504us/sample - loss: 0.1372 - acc: 0.9219 - val_loss: 0.1517 - val_acc: 0.9375\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 452us/sample - loss: 0.1465 - acc: 0.9375 - val_loss: 0.0710 - val_acc: 0.9375\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 477us/sample - loss: 0.0617 - acc: 1.0000 - val_loss: 0.0347 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 488us/sample - loss: 0.1328 - acc: 0.9375 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 420us/sample - loss: 0.2076 - acc: 0.9219 - val_loss: 0.1185 - val_acc: 0.9375\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 481us/sample - loss: 0.1345 - acc: 0.9219 - val_loss: 0.0550 - val_acc: 0.9375\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 591us/sample - loss: 0.1045 - acc: 0.9531 - val_loss: 0.0437 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 521us/sample - loss: 0.0826 - acc: 0.9688 - val_loss: 0.0282 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 572us/sample - loss: 0.0648 - acc: 0.9688 - val_loss: 0.0378 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 501us/sample - loss: 0.1086 - acc: 0.9375 - val_loss: 0.0521 - val_acc: 0.9375\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 471us/sample - loss: 0.1679 - acc: 0.9375 - val_loss: 0.0289 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 474us/sample - loss: 0.0895 - acc: 0.9688 - val_loss: 0.0249 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 486us/sample - loss: 0.0798 - acc: 0.9688 - val_loss: 0.0200 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 502us/sample - loss: 0.0836 - acc: 0.9531 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 505us/sample - loss: 0.0782 - acc: 0.9375 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 555us/sample - loss: 0.0898 - acc: 0.9375 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 674us/sample - loss: 0.0692 - acc: 0.9844 - val_loss: 0.0142 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 671us/sample - loss: 0.0830 - acc: 0.9531 - val_loss: 0.0237 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 489us/sample - loss: 0.0583 - acc: 0.9531 - val_loss: 0.0285 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 472us/sample - loss: 0.1247 - acc: 0.9531 - val_loss: 0.0293 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 508us/sample - loss: 0.2385 - acc: 0.8906 - val_loss: 0.0642 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 428us/sample - loss: 0.1578 - acc: 0.9219 - val_loss: 0.0570 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 452us/sample - loss: 0.0555 - acc: 0.9688 - val_loss: 0.0790 - val_acc: 0.9375\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 483us/sample - loss: 0.0801 - acc: 0.9688 - val_loss: 0.0738 - val_acc: 0.9375\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 584us/sample - loss: 0.0904 - acc: 0.9375 - val_loss: 0.0643 - val_acc: 0.9375\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 597us/sample - loss: 0.0875 - acc: 0.9375 - val_loss: 0.0304 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 584us/sample - loss: 0.0601 - acc: 0.9844 - val_loss: 0.0274 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 668us/sample - loss: 0.0557 - acc: 0.9688 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 547us/sample - loss: 0.0515 - acc: 0.9844 - val_loss: 0.0843 - val_acc: 0.9375\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 552us/sample - loss: 0.1304 - acc: 0.9375 - val_loss: 0.1296 - val_acc: 0.9375\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 559us/sample - loss: 0.0791 - acc: 0.9688 - val_loss: 0.0591 - val_acc: 0.9375\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 546us/sample - loss: 0.0406 - acc: 0.9844 - val_loss: 0.0296 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 575us/sample - loss: 0.1591 - acc: 0.9219 - val_loss: 0.1692 - val_acc: 0.8750\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 585us/sample - loss: 0.4822 - acc: 0.8594 - val_loss: 0.1430 - val_acc: 0.8750\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 504us/sample - loss: 0.1124 - acc: 0.9375 - val_loss: 0.0747 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=4, epochs=100,\n",
    "                   validation_data = (X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  0.23741699755191803\n",
      "train acc:  0.9375\n",
      "test loss:  0.6763339042663574\n",
      "test acc:  0.8\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('train loss: ', score[0])\n",
    "print('train acc: ', score[1])\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('test loss: ', score[0])\n",
    "print('test acc: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題4 Iris(多値分類)をKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# データセットの読み込み\n",
    "dataset_path =\"../Sprint13/Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "#df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y[y=='Iris-setosa'] = 2\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "y_onehot = ohe.fit_transform(y.reshape(-1,1))\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 3)\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1209 12:11:12.270226 4799473088 deprecation_wrapper.py:119] From //anaconda3/envs/aistudio/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W1209 12:11:12.271608 4799473088 deprecation_wrapper.py:119] From //anaconda3/envs/aistudio/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1209 12:11:12.276983 4799473088 deprecation_wrapper.py:119] From //anaconda3/envs/aistudio/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 5,653\n",
      "Trainable params: 5,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#functional APIを使用する\n",
    "\n",
    "K.clear_session()\n",
    "input_data = tf.keras.layers.Input(shape=(4, ))\n",
    "x = tf.keras.layers.Dense(50, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(100, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(3, activation=tf.nn.softmax)(x)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 24 samples\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.6361 - acc: 0.7396 - val_loss: 0.4299 - val_acc: 0.7083\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 0s 499us/sample - loss: 0.3372 - acc: 0.8854 - val_loss: 0.2267 - val_acc: 0.9167\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 0s 601us/sample - loss: 0.3147 - acc: 0.8333 - val_loss: 0.6956 - val_acc: 0.7083\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 0s 546us/sample - loss: 0.2231 - acc: 0.9375 - val_loss: 0.2451 - val_acc: 0.9167\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 0s 549us/sample - loss: 0.1212 - acc: 0.9479 - val_loss: 0.2985 - val_acc: 0.9167\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 0s 428us/sample - loss: 0.4728 - acc: 0.8854 - val_loss: 0.5476 - val_acc: 0.7083\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 0s 527us/sample - loss: 0.1980 - acc: 0.9375 - val_loss: 0.2577 - val_acc: 0.8750\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 0s 537us/sample - loss: 0.1003 - acc: 0.9688 - val_loss: 0.1733 - val_acc: 0.9167\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 0s 546us/sample - loss: 0.0716 - acc: 0.9792 - val_loss: 0.2210 - val_acc: 0.9167\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 0s 576us/sample - loss: 0.3129 - acc: 0.8958 - val_loss: 0.3189 - val_acc: 0.9167\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 0s 524us/sample - loss: 0.1003 - acc: 0.9896 - val_loss: 0.2605 - val_acc: 0.9167\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 0s 513us/sample - loss: 0.1388 - acc: 0.9375 - val_loss: 0.1775 - val_acc: 0.9167\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 0s 555us/sample - loss: 0.0909 - acc: 0.9583 - val_loss: 0.1593 - val_acc: 0.9167\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 0s 546us/sample - loss: 0.0971 - acc: 0.9583 - val_loss: 0.2140 - val_acc: 0.9167\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 0s 570us/sample - loss: 0.0799 - acc: 0.9583 - val_loss: 0.2276 - val_acc: 0.8750\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 0s 502us/sample - loss: 0.0733 - acc: 0.9583 - val_loss: 0.3040 - val_acc: 0.9167\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 0s 485us/sample - loss: 0.2161 - acc: 0.9271 - val_loss: 0.1747 - val_acc: 0.9167\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 0s 612us/sample - loss: 0.0598 - acc: 0.9896 - val_loss: 0.2192 - val_acc: 0.9167\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 0s 529us/sample - loss: 0.0926 - acc: 0.9479 - val_loss: 0.2307 - val_acc: 0.9167\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 0s 541us/sample - loss: 0.1936 - acc: 0.9375 - val_loss: 0.2097 - val_acc: 0.8750\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 0s 663us/sample - loss: 0.1888 - acc: 0.9167 - val_loss: 0.2557 - val_acc: 0.9167\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 0s 575us/sample - loss: 0.0702 - acc: 0.9792 - val_loss: 0.3109 - val_acc: 0.9167\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 0s 449us/sample - loss: 0.0675 - acc: 0.9688 - val_loss: 0.2317 - val_acc: 0.9167\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 0s 424us/sample - loss: 0.1891 - acc: 0.9271 - val_loss: 0.5048 - val_acc: 0.8333\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 0s 558us/sample - loss: 0.1996 - acc: 0.9271 - val_loss: 0.2694 - val_acc: 0.9167\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 0s 465us/sample - loss: 0.0821 - acc: 0.9792 - val_loss: 0.3244 - val_acc: 0.9167\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 0s 460us/sample - loss: 0.1252 - acc: 0.9583 - val_loss: 0.6924 - val_acc: 0.7500\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 0s 832us/sample - loss: 0.0595 - acc: 0.9896 - val_loss: 0.1982 - val_acc: 0.8750\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 0s 709us/sample - loss: 0.1424 - acc: 0.9375 - val_loss: 0.4895 - val_acc: 0.8333\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 0s 808us/sample - loss: 0.1976 - acc: 0.9167 - val_loss: 0.6231 - val_acc: 0.7500\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 0s 661us/sample - loss: 0.1291 - acc: 0.9479 - val_loss: 0.2467 - val_acc: 0.9167\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 0s 580us/sample - loss: 0.0524 - acc: 0.9688 - val_loss: 0.1991 - val_acc: 0.9167\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 0s 643us/sample - loss: 0.1246 - acc: 0.9583 - val_loss: 0.3764 - val_acc: 0.9167\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 0s 780us/sample - loss: 0.0612 - acc: 0.9688 - val_loss: 0.3185 - val_acc: 0.9167\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 0s 671us/sample - loss: 0.0739 - acc: 0.9792 - val_loss: 0.6070 - val_acc: 0.7917\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 0s 552us/sample - loss: 0.2155 - acc: 0.8958 - val_loss: 0.4495 - val_acc: 0.7500\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 0s 658us/sample - loss: 0.1035 - acc: 0.9479 - val_loss: 0.2478 - val_acc: 0.9167\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - 0s 580us/sample - loss: 0.0743 - acc: 0.9583 - val_loss: 0.1440 - val_acc: 0.9583\n",
      "Epoch 39/100\n",
      "96/96 [==============================] - 0s 445us/sample - loss: 0.0880 - acc: 0.9792 - val_loss: 0.1452 - val_acc: 0.9583\n",
      "Epoch 40/100\n",
      "96/96 [==============================] - 0s 524us/sample - loss: 0.1072 - acc: 0.9583 - val_loss: 0.1906 - val_acc: 0.9167\n",
      "Epoch 41/100\n",
      "96/96 [==============================] - 0s 385us/sample - loss: 0.1050 - acc: 0.9479 - val_loss: 0.3422 - val_acc: 0.9167\n",
      "Epoch 42/100\n",
      "96/96 [==============================] - 0s 442us/sample - loss: 0.3227 - acc: 0.8854 - val_loss: 0.3812 - val_acc: 0.7500\n",
      "Epoch 43/100\n",
      "96/96 [==============================] - 0s 387us/sample - loss: 0.1177 - acc: 0.9583 - val_loss: 0.2368 - val_acc: 0.8750\n",
      "Epoch 44/100\n",
      "96/96 [==============================] - 0s 419us/sample - loss: 0.0873 - acc: 0.9583 - val_loss: 0.6480 - val_acc: 0.8333\n",
      "Epoch 45/100\n",
      "96/96 [==============================] - 0s 379us/sample - loss: 0.1198 - acc: 0.9375 - val_loss: 0.1760 - val_acc: 0.8750\n",
      "Epoch 46/100\n",
      "96/96 [==============================] - 0s 415us/sample - loss: 0.0948 - acc: 0.9583 - val_loss: 0.2377 - val_acc: 0.8750\n",
      "Epoch 47/100\n",
      "96/96 [==============================] - 0s 374us/sample - loss: 0.1071 - acc: 0.9479 - val_loss: 0.3792 - val_acc: 0.9167\n",
      "Epoch 48/100\n",
      "96/96 [==============================] - 0s 431us/sample - loss: 0.0763 - acc: 0.9688 - val_loss: 0.2433 - val_acc: 0.9167\n",
      "Epoch 49/100\n",
      "96/96 [==============================] - 0s 421us/sample - loss: 0.0572 - acc: 0.9792 - val_loss: 0.1555 - val_acc: 0.9583\n",
      "Epoch 50/100\n",
      "96/96 [==============================] - 0s 480us/sample - loss: 0.1390 - acc: 0.9479 - val_loss: 0.3295 - val_acc: 0.9167\n",
      "Epoch 51/100\n",
      "96/96 [==============================] - 0s 484us/sample - loss: 0.0819 - acc: 0.9688 - val_loss: 0.7376 - val_acc: 0.7500\n",
      "Epoch 52/100\n",
      "96/96 [==============================] - 0s 555us/sample - loss: 0.2874 - acc: 0.8958 - val_loss: 0.8838 - val_acc: 0.7083\n",
      "Epoch 53/100\n",
      "96/96 [==============================] - 0s 525us/sample - loss: 0.1351 - acc: 0.9479 - val_loss: 0.2514 - val_acc: 0.9167\n",
      "Epoch 54/100\n",
      "96/96 [==============================] - 0s 518us/sample - loss: 0.0599 - acc: 0.9896 - val_loss: 0.2289 - val_acc: 0.9167\n",
      "Epoch 55/100\n",
      "96/96 [==============================] - 0s 515us/sample - loss: 0.1259 - acc: 0.9583 - val_loss: 0.3793 - val_acc: 0.9167\n",
      "Epoch 56/100\n",
      "96/96 [==============================] - 0s 482us/sample - loss: 0.0505 - acc: 0.9792 - val_loss: 0.4415 - val_acc: 0.8333\n",
      "Epoch 57/100\n",
      "96/96 [==============================] - 0s 466us/sample - loss: 0.0663 - acc: 0.9688 - val_loss: 0.3021 - val_acc: 0.9167\n",
      "Epoch 58/100\n",
      "96/96 [==============================] - 0s 487us/sample - loss: 0.0443 - acc: 0.9792 - val_loss: 0.5096 - val_acc: 0.8333\n",
      "Epoch 59/100\n",
      "96/96 [==============================] - 0s 462us/sample - loss: 0.0867 - acc: 0.9583 - val_loss: 0.5623 - val_acc: 0.8333\n",
      "Epoch 60/100\n",
      "96/96 [==============================] - 0s 447us/sample - loss: 0.1245 - acc: 0.9583 - val_loss: 0.2353 - val_acc: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "96/96 [==============================] - 0s 513us/sample - loss: 0.0408 - acc: 0.9792 - val_loss: 0.2028 - val_acc: 0.8750\n",
      "Epoch 62/100\n",
      "96/96 [==============================] - 0s 449us/sample - loss: 0.0406 - acc: 1.0000 - val_loss: 0.3054 - val_acc: 0.9167\n",
      "Epoch 63/100\n",
      "96/96 [==============================] - 0s 449us/sample - loss: 0.0307 - acc: 0.9896 - val_loss: 0.1960 - val_acc: 0.9167\n",
      "Epoch 64/100\n",
      "96/96 [==============================] - 0s 412us/sample - loss: 0.0371 - acc: 0.9896 - val_loss: 0.3970 - val_acc: 0.9167\n",
      "Epoch 65/100\n",
      "96/96 [==============================] - 0s 369us/sample - loss: 0.0727 - acc: 0.9792 - val_loss: 0.2300 - val_acc: 0.9167\n",
      "Epoch 66/100\n",
      "96/96 [==============================] - 0s 359us/sample - loss: 0.0514 - acc: 0.9792 - val_loss: 0.4047 - val_acc: 0.9167\n",
      "Epoch 67/100\n",
      "96/96 [==============================] - 0s 372us/sample - loss: 0.1935 - acc: 0.8854 - val_loss: 0.2621 - val_acc: 0.9167\n",
      "Epoch 68/100\n",
      "96/96 [==============================] - 0s 422us/sample - loss: 0.1527 - acc: 0.9479 - val_loss: 0.1966 - val_acc: 0.9167\n",
      "Epoch 69/100\n",
      "96/96 [==============================] - 0s 368us/sample - loss: 0.1371 - acc: 0.9479 - val_loss: 0.1853 - val_acc: 0.9167\n",
      "Epoch 70/100\n",
      "96/96 [==============================] - 0s 392us/sample - loss: 0.0743 - acc: 0.9688 - val_loss: 0.2338 - val_acc: 0.9167\n",
      "Epoch 71/100\n",
      "96/96 [==============================] - 0s 363us/sample - loss: 0.0665 - acc: 0.9688 - val_loss: 0.1853 - val_acc: 0.9167\n",
      "Epoch 72/100\n",
      "96/96 [==============================] - 0s 390us/sample - loss: 0.0367 - acc: 0.9792 - val_loss: 0.1954 - val_acc: 0.9167\n",
      "Epoch 73/100\n",
      "96/96 [==============================] - 0s 391us/sample - loss: 0.0465 - acc: 0.9792 - val_loss: 0.3100 - val_acc: 0.9167\n",
      "Epoch 74/100\n",
      "96/96 [==============================] - 0s 604us/sample - loss: 0.0390 - acc: 0.9896 - val_loss: 0.1757 - val_acc: 0.8750\n",
      "Epoch 75/100\n",
      "96/96 [==============================] - 0s 541us/sample - loss: 0.0448 - acc: 0.9896 - val_loss: 0.2738 - val_acc: 0.9167\n",
      "Epoch 76/100\n",
      "96/96 [==============================] - 0s 513us/sample - loss: 0.0364 - acc: 0.9896 - val_loss: 0.3305 - val_acc: 0.9167\n",
      "Epoch 77/100\n",
      "96/96 [==============================] - 0s 411us/sample - loss: 0.0631 - acc: 0.9688 - val_loss: 0.2486 - val_acc: 0.9167\n",
      "Epoch 78/100\n",
      "96/96 [==============================] - 0s 480us/sample - loss: 0.0485 - acc: 0.9896 - val_loss: 0.1500 - val_acc: 0.9583\n",
      "Epoch 79/100\n",
      "96/96 [==============================] - 0s 464us/sample - loss: 0.0678 - acc: 0.9688 - val_loss: 0.1521 - val_acc: 0.9167\n",
      "Epoch 80/100\n",
      "96/96 [==============================] - 0s 425us/sample - loss: 0.0678 - acc: 0.9479 - val_loss: 0.3048 - val_acc: 0.8750\n",
      "Epoch 81/100\n",
      "96/96 [==============================] - 0s 405us/sample - loss: 0.0351 - acc: 0.9688 - val_loss: 0.3099 - val_acc: 0.9167\n",
      "Epoch 82/100\n",
      "96/96 [==============================] - 0s 399us/sample - loss: 0.1138 - acc: 0.9583 - val_loss: 0.6143 - val_acc: 0.8333\n",
      "Epoch 83/100\n",
      "96/96 [==============================] - 0s 420us/sample - loss: 0.2311 - acc: 0.8958 - val_loss: 0.2672 - val_acc: 0.9167\n",
      "Epoch 84/100\n",
      "96/96 [==============================] - 0s 419us/sample - loss: 0.0745 - acc: 0.9688 - val_loss: 0.1813 - val_acc: 0.9167\n",
      "Epoch 85/100\n",
      "96/96 [==============================] - 0s 408us/sample - loss: 0.0387 - acc: 0.9896 - val_loss: 0.2553 - val_acc: 0.9167\n",
      "Epoch 86/100\n",
      "96/96 [==============================] - 0s 379us/sample - loss: 0.0481 - acc: 0.9896 - val_loss: 0.2339 - val_acc: 0.9167\n",
      "Epoch 87/100\n",
      "96/96 [==============================] - 0s 375us/sample - loss: 0.0544 - acc: 0.9688 - val_loss: 0.1804 - val_acc: 0.9167\n",
      "Epoch 88/100\n",
      "96/96 [==============================] - 0s 384us/sample - loss: 0.1230 - acc: 0.9375 - val_loss: 0.2371 - val_acc: 0.9167\n",
      "Epoch 89/100\n",
      "96/96 [==============================] - 0s 376us/sample - loss: 0.1268 - acc: 0.9479 - val_loss: 0.2365 - val_acc: 0.9167\n",
      "Epoch 90/100\n",
      "96/96 [==============================] - 0s 410us/sample - loss: 0.0473 - acc: 0.9688 - val_loss: 0.2448 - val_acc: 0.9167\n",
      "Epoch 91/100\n",
      "96/96 [==============================] - 0s 375us/sample - loss: 0.0504 - acc: 0.9792 - val_loss: 0.4091 - val_acc: 0.9167\n",
      "Epoch 92/100\n",
      "96/96 [==============================] - 0s 380us/sample - loss: 0.1764 - acc: 0.9375 - val_loss: 0.3549 - val_acc: 0.8333\n",
      "Epoch 93/100\n",
      "96/96 [==============================] - 0s 394us/sample - loss: 0.1357 - acc: 0.9375 - val_loss: 0.1705 - val_acc: 0.9167\n",
      "Epoch 94/100\n",
      "96/96 [==============================] - 0s 409us/sample - loss: 0.0483 - acc: 0.9896 - val_loss: 0.3172 - val_acc: 0.9167\n",
      "Epoch 95/100\n",
      "96/96 [==============================] - 0s 379us/sample - loss: 0.0579 - acc: 0.9792 - val_loss: 0.2171 - val_acc: 0.9167\n",
      "Epoch 96/100\n",
      "96/96 [==============================] - 0s 415us/sample - loss: 0.1257 - acc: 0.9375 - val_loss: 0.1642 - val_acc: 0.9167\n",
      "Epoch 97/100\n",
      "96/96 [==============================] - 0s 356us/sample - loss: 0.0498 - acc: 0.9688 - val_loss: 0.1526 - val_acc: 0.9583\n",
      "Epoch 98/100\n",
      "96/96 [==============================] - 0s 414us/sample - loss: 0.0529 - acc: 0.9792 - val_loss: 0.1872 - val_acc: 0.9167\n",
      "Epoch 99/100\n",
      "96/96 [==============================] - 0s 402us/sample - loss: 0.0899 - acc: 0.9583 - val_loss: 0.3299 - val_acc: 0.9167\n",
      "Epoch 100/100\n",
      "96/96 [==============================] - 0s 451us/sample - loss: 0.0441 - acc: 0.9792 - val_loss: 0.1988 - val_acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, verbose=1, batch_size=4,\n",
    "                   epochs=100, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  0.10026301257312298\n",
      "train acc:  0.9583333\n",
      "test loss:  0.06912560760974884\n",
      "test acc:  0.96666664\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('train loss: ', score[0])\n",
    "print('train acc: ', score[1])\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('test loss: ', score[0])\n",
    "print('test acc: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題5 House PriceをKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df_house = pd.read_csv('../train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_house.loc[:,['GrLivArea', 'YearBuilt']])\n",
    "y = np.array(df_house.loc[:, 'SalePrice']).reshape(-1,1)\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y,random_state=0,\n",
    "                                                  test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,\n",
    "                                                 random_state=0, test_size=0.2)\n",
    "sr = StandardScaler()\n",
    "X_train_std = sr.fit_transform(X_train)\n",
    "X_test_std = sr.transform(X_test)\n",
    "X_val_std = sr.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model subclassingの書き方\n",
    "\n",
    "class RegModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        #keras.Modelを継承して、initを呼び出している\n",
    "        super(RegModel, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(50,\n",
    "                                            activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(100, \n",
    "                                               activation=tf.nn.relu)\n",
    "        self.dense3 = tf.keras.layers.Dense(1)\n",
    "            \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.cast(inputs, tf.float64)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = X_train_std.astype(np.float64)\n",
    "X_test_std = X_test_std.astype(np.float64)\n",
    "X_val_std = X_val_std.astype(np.float64)\n",
    "\n",
    "y_train = y_train.astype(np.float64)\n",
    "y_test = y_test.astype(np.float64)\n",
    "y_val = y_val.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer = tf.train.AdamOptimizer(learning_rate = 0.01),\n",
    "             metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 234 samples\n",
      "Epoch 1/100\n",
      "934/934 [==============================] - 0s 381us/step - loss: 14372513755.3747 - mean_squared_error: 14372513755.3747 - val_loss: 1575644055.2479 - val_mean_squared_error: 1575644055.2479\n",
      "Epoch 2/100\n",
      "934/934 [==============================] - 0s 282us/step - loss: 2120273576.8051 - mean_squared_error: 2120273576.8051 - val_loss: 1529375152.5470 - val_mean_squared_error: 1529375152.5470\n",
      "Epoch 3/100\n",
      "934/934 [==============================] - 0s 318us/step - loss: 2129129061.2934 - mean_squared_error: 2129129061.2934 - val_loss: 1530335000.2051 - val_mean_squared_error: 1530335000.2051\n",
      "Epoch 4/100\n",
      "934/934 [==============================] - 0s 293us/step - loss: 2103588869.4133 - mean_squared_error: 2103588869.4133 - val_loss: 1502913670.1538 - val_mean_squared_error: 1502913670.1538\n",
      "Epoch 5/100\n",
      "934/934 [==============================] - 0s 306us/step - loss: 2091524361.9358 - mean_squared_error: 2091524361.9358 - val_loss: 1504651004.8547 - val_mean_squared_error: 1504651004.8547\n",
      "Epoch 6/100\n",
      "934/934 [==============================] - 0s 310us/step - loss: 2068376226.9979 - mean_squared_error: 2068376226.9979 - val_loss: 1513265525.9487 - val_mean_squared_error: 1513265525.9487\n",
      "Epoch 7/100\n",
      "934/934 [==============================] - 0s 259us/step - loss: 2042330734.3897 - mean_squared_error: 2042330734.3897 - val_loss: 1545494218.0513 - val_mean_squared_error: 1545494218.0513\n",
      "Epoch 8/100\n",
      "934/934 [==============================] - 0s 375us/step - loss: 2019223517.9957 - mean_squared_error: 2019223517.9957 - val_loss: 1632198306.7350 - val_mean_squared_error: 1632198306.7350\n",
      "Epoch 9/100\n",
      "934/934 [==============================] - 0s 329us/step - loss: 2009049245.2077 - mean_squared_error: 2009049245.2077 - val_loss: 1478236669.4017 - val_mean_squared_error: 1478236669.4017\n",
      "Epoch 10/100\n",
      "934/934 [==============================] - 0s 273us/step - loss: 2039223054.9722 - mean_squared_error: 2039223054.9722 - val_loss: 1462732168.2051 - val_mean_squared_error: 1462732168.2051\n",
      "Epoch 11/100\n",
      "934/934 [==============================] - 0s 338us/step - loss: 2019051068.9165 - mean_squared_error: 2019051068.9165 - val_loss: 1457912640.5470 - val_mean_squared_error: 1457912640.5470\n",
      "Epoch 12/100\n",
      "934/934 [==============================] - 0s 280us/step - loss: 2005601433.6274 - mean_squared_error: 2005601433.6274 - val_loss: 1553677519.7265 - val_mean_squared_error: 1553677519.7265\n",
      "Epoch 13/100\n",
      "934/934 [==============================] - 0s 287us/step - loss: 2016549478.7666 - mean_squared_error: 2016549478.7666 - val_loss: 1561461641.4359 - val_mean_squared_error: 1561461641.4359\n",
      "Epoch 14/100\n",
      "934/934 [==============================] - 0s 302us/step - loss: 1968059240.6852 - mean_squared_error: 1968059240.6852 - val_loss: 1463588890.5299 - val_mean_squared_error: 1463588890.5299\n",
      "Epoch 15/100\n",
      "934/934 [==============================] - 0s 261us/step - loss: 1992681309.3319 - mean_squared_error: 1992681309.3319 - val_loss: 1535397312.4786 - val_mean_squared_error: 1535397312.4786\n",
      "Epoch 16/100\n",
      "934/934 [==============================] - 0s 280us/step - loss: 2006960625.4904 - mean_squared_error: 2006960625.4904 - val_loss: 1485930051.2137 - val_mean_squared_error: 1485930051.2137\n",
      "Epoch 17/100\n",
      "934/934 [==============================] - 0s 319us/step - loss: 1984578604.5439 - mean_squared_error: 1984578604.5439 - val_loss: 1569994350.8376 - val_mean_squared_error: 1569994350.8376\n",
      "Epoch 18/100\n",
      "934/934 [==============================] - 0s 361us/step - loss: 1980363830.6981 - mean_squared_error: 1980363830.6981 - val_loss: 1443123971.9658 - val_mean_squared_error: 1443123971.9658\n",
      "Epoch 19/100\n",
      "934/934 [==============================] - 0s 315us/step - loss: 2002753554.9379 - mean_squared_error: 2002753554.9379 - val_loss: 1470275353.9829 - val_mean_squared_error: 1470275353.9829\n",
      "Epoch 20/100\n",
      "934/934 [==============================] - 0s 269us/step - loss: 2008112452.2484 - mean_squared_error: 2008112452.2484 - val_loss: 1442544326.2222 - val_mean_squared_error: 1442544326.2222\n",
      "Epoch 21/100\n",
      "934/934 [==============================] - 0s 403us/step - loss: 1983043244.4368 - mean_squared_error: 1983043244.4368 - val_loss: 1455261753.7094 - val_mean_squared_error: 1455261753.7094\n",
      "Epoch 22/100\n",
      "934/934 [==============================] - 0s 316us/step - loss: 1984961535.5032 - mean_squared_error: 1984961535.5032 - val_loss: 1491048211.6923 - val_mean_squared_error: 1491048211.6923\n",
      "Epoch 23/100\n",
      "934/934 [==============================] - 0s 269us/step - loss: 1978801258.1927 - mean_squared_error: 1978801258.1927 - val_loss: 1548355653.6068 - val_mean_squared_error: 1548355653.6068\n",
      "Epoch 24/100\n",
      "934/934 [==============================] - 0s 518us/step - loss: 2000464404.0600 - mean_squared_error: 2000464404.0600 - val_loss: 1465103894.1538 - val_mean_squared_error: 1465103894.1538\n",
      "Epoch 25/100\n",
      "934/934 [==============================] - 0s 448us/step - loss: 1980352938.2270 - mean_squared_error: 1980352938.2270 - val_loss: 1525542858.8034 - val_mean_squared_error: 1525542858.8034\n",
      "Epoch 26/100\n",
      "934/934 [==============================] - 0s 337us/step - loss: 1992723041.8501 - mean_squared_error: 1992723041.8501 - val_loss: 1436775214.9060 - val_mean_squared_error: 1436775214.9060\n",
      "Epoch 27/100\n",
      "934/934 [==============================] - 0s 321us/step - loss: 1975680898.5353 - mean_squared_error: 1975680898.5353 - val_loss: 1463376641.9829 - val_mean_squared_error: 1463376641.9829\n",
      "Epoch 28/100\n",
      "934/934 [==============================] - 0s 290us/step - loss: 1993540901.5503 - mean_squared_error: 1993540901.5503 - val_loss: 1533373220.3077 - val_mean_squared_error: 1533373220.3077\n",
      "Epoch 29/100\n",
      "934/934 [==============================] - 0s 323us/step - loss: 1981365637.2934 - mean_squared_error: 1981365637.2934 - val_loss: 1456300262.4274 - val_mean_squared_error: 1456300262.4274\n",
      "Epoch 30/100\n",
      "934/934 [==============================] - 0s 303us/step - loss: 1980451445.0878 - mean_squared_error: 1980451445.0878 - val_loss: 1442468180.7863 - val_mean_squared_error: 1442468180.7863\n",
      "Epoch 31/100\n",
      "934/934 [==============================] - 0s 321us/step - loss: 1973871775.7773 - mean_squared_error: 1973871775.7773 - val_loss: 1577343141.7778 - val_mean_squared_error: 1577343141.7778\n",
      "Epoch 32/100\n",
      "934/934 [==============================] - 0s 265us/step - loss: 1991699181.1478 - mean_squared_error: 1991699181.1478 - val_loss: 1448352379.3504 - val_mean_squared_error: 1448352379.3504\n",
      "Epoch 33/100\n",
      "934/934 [==============================] - 0s 279us/step - loss: 1975884275.4839 - mean_squared_error: 1975884275.4839 - val_loss: 1482999877.2650 - val_mean_squared_error: 1482999877.2650\n",
      "Epoch 34/100\n",
      "934/934 [==============================] - 0s 272us/step - loss: 1973768001.3704 - mean_squared_error: 1973768001.3704 - val_loss: 1473380349.3675 - val_mean_squared_error: 1473380349.3675\n",
      "Epoch 35/100\n",
      "934/934 [==============================] - 0s 324us/step - loss: 1973568390.7495 - mean_squared_error: 1973568390.7495 - val_loss: 1535522451.0769 - val_mean_squared_error: 1535522451.0769\n",
      "Epoch 36/100\n",
      "934/934 [==============================] - 0s 394us/step - loss: 1963856753.2848 - mean_squared_error: 1963856753.2848 - val_loss: 1469941429.2308 - val_mean_squared_error: 1469941429.2308\n",
      "Epoch 37/100\n",
      "934/934 [==============================] - 0s 329us/step - loss: 1977539092.5396 - mean_squared_error: 1977539092.5396 - val_loss: 1448404957.8120 - val_mean_squared_error: 1448404957.8120\n",
      "Epoch 38/100\n",
      "934/934 [==============================] - 0s 346us/step - loss: 1940104584.1713 - mean_squared_error: 1940104584.1713 - val_loss: 1507017046.9744 - val_mean_squared_error: 1507017046.9744\n",
      "Epoch 39/100\n",
      "934/934 [==============================] - 0s 285us/step - loss: 1978136508.1156 - mean_squared_error: 1978136508.1156 - val_loss: 1423272196.4444 - val_mean_squared_error: 1423272196.4444\n",
      "Epoch 40/100\n",
      "934/934 [==============================] - 0s 342us/step - loss: 1982447984.1542 - mean_squared_error: 1982447984.1542 - val_loss: 1525877159.5897 - val_mean_squared_error: 1525877159.5897\n",
      "Epoch 41/100\n",
      "934/934 [==============================] - 0s 284us/step - loss: 1964270142.4754 - mean_squared_error: 1964270142.4754 - val_loss: 1413127556.5812 - val_mean_squared_error: 1413127556.5812\n",
      "Epoch 42/100\n",
      "934/934 [==============================] - 0s 302us/step - loss: 1973609926.3041 - mean_squared_error: 1973609926.3041 - val_loss: 1536909888.9915 - val_mean_squared_error: 1536909888.9915\n",
      "Epoch 43/100\n",
      "934/934 [==============================] - 0s 344us/step - loss: 1958925108.9336 - mean_squared_error: 1958925108.9336 - val_loss: 1445182135.2479 - val_mean_squared_error: 1445182135.2479\n",
      "Epoch 44/100\n",
      "934/934 [==============================] - 0s 262us/step - loss: 1967572066.2184 - mean_squared_error: 1967572066.2184 - val_loss: 1445650869.6068 - val_mean_squared_error: 1445650869.6068\n",
      "Epoch 45/100\n",
      "934/934 [==============================] - 0s 261us/step - loss: 1973338711.3062 - mean_squared_error: 1973338711.3062 - val_loss: 1417958511.5214 - val_mean_squared_error: 1417958511.5214\n",
      "Epoch 46/100\n",
      "934/934 [==============================] - 0s 338us/step - loss: 1968115806.2441 - mean_squared_error: 1968115806.2441 - val_loss: 1442209964.0342 - val_mean_squared_error: 1442209964.0342\n",
      "Epoch 47/100\n",
      "934/934 [==============================] - 0s 269us/step - loss: 1966801126.2355 - mean_squared_error: 1966801126.2355 - val_loss: 1463870518.3248 - val_mean_squared_error: 1463870518.3248\n",
      "Epoch 48/100\n",
      "934/934 [==============================] - 0s 275us/step - loss: 1950215286.1842 - mean_squared_error: 1950215286.1842 - val_loss: 1426167725.4701 - val_mean_squared_error: 1426167725.4701\n",
      "Epoch 49/100\n",
      "934/934 [==============================] - 0s 281us/step - loss: 1962648425.4732 - mean_squared_error: 1962648425.4732 - val_loss: 1408407367.3846 - val_mean_squared_error: 1408407367.3846\n",
      "Epoch 50/100\n",
      "934/934 [==============================] - 0s 350us/step - loss: 1961415003.9486 - mean_squared_error: 1961415003.9486 - val_loss: 1434536514.5641 - val_mean_squared_error: 1434536514.5641\n",
      "Epoch 51/100\n",
      "934/934 [==============================] - 0s 359us/step - loss: 1960172711.7088 - mean_squared_error: 1960172711.7088 - val_loss: 1496008222.8376 - val_mean_squared_error: 1496008222.8376\n",
      "Epoch 52/100\n",
      "934/934 [==============================] - 0s 356us/step - loss: 1968143523.9058 - mean_squared_error: 1968143523.9058 - val_loss: 1430617544.1368 - val_mean_squared_error: 1430617544.1368\n",
      "Epoch 53/100\n",
      "934/934 [==============================] - 0s 285us/step - loss: 1956252987.9400 - mean_squared_error: 1956252987.9400 - val_loss: 1445683466.0513 - val_mean_squared_error: 1445683466.0513\n",
      "Epoch 54/100\n",
      "934/934 [==============================] - 0s 261us/step - loss: 1966234450.2784 - mean_squared_error: 1966234450.2784 - val_loss: 1463684189.7094 - val_mean_squared_error: 1463684189.7094\n",
      "Epoch 55/100\n",
      "934/934 [==============================] - 0s 265us/step - loss: 1947937612.0343 - mean_squared_error: 1947937612.0343 - val_loss: 1416708164.0342 - val_mean_squared_error: 1416708164.0342\n",
      "Epoch 56/100\n",
      "934/934 [==============================] - 0s 344us/step - loss: 1964793538.1242 - mean_squared_error: 1964793538.1242 - val_loss: 1413996870.8034 - val_mean_squared_error: 1413996870.8034\n",
      "Epoch 57/100\n",
      "934/934 [==============================] - 0s 363us/step - loss: 1983387879.1949 - mean_squared_error: 1983387879.1949 - val_loss: 1443145063.3846 - val_mean_squared_error: 1443145063.3846\n",
      "Epoch 58/100\n",
      "934/934 [==============================] - 0s 367us/step - loss: 1957061692.2655 - mean_squared_error: 1957061692.2655 - val_loss: 1475470286.7692 - val_mean_squared_error: 1475470286.7692\n",
      "Epoch 59/100\n",
      "934/934 [==============================] - 0s 293us/step - loss: 1950517623.7345 - mean_squared_error: 1950517623.7345 - val_loss: 1415153551.4872 - val_mean_squared_error: 1415153551.4872\n",
      "Epoch 60/100\n",
      "934/934 [==============================] - 0s 361us/step - loss: 1953548938.0086 - mean_squared_error: 1953548938.0086 - val_loss: 1437882433.4017 - val_mean_squared_error: 1437882433.4017\n",
      "Epoch 61/100\n",
      "934/934 [==============================] - 0s 338us/step - loss: 1951233615.4946 - mean_squared_error: 1951233615.4946 - val_loss: 1419731371.2821 - val_mean_squared_error: 1419731371.2821\n",
      "Epoch 62/100\n",
      "934/934 [==============================] - 0s 270us/step - loss: 1942281998.0300 - mean_squared_error: 1942281998.0300 - val_loss: 1564048306.4957 - val_mean_squared_error: 1564048306.4957\n",
      "Epoch 63/100\n",
      "934/934 [==============================] - 0s 253us/step - loss: 1966816601.8287 - mean_squared_error: 1966816601.8287 - val_loss: 1424142601.4359 - val_mean_squared_error: 1424142601.4359\n",
      "Epoch 64/100\n",
      "934/934 [==============================] - 0s 341us/step - loss: 1943831742.4240 - mean_squared_error: 1943831742.4240 - val_loss: 1488629753.6068 - val_mean_squared_error: 1488629753.6068\n",
      "Epoch 65/100\n",
      "934/934 [==============================] - 0s 316us/step - loss: 1942629339.8544 - mean_squared_error: 1942629339.8544 - val_loss: 1479563844.6154 - val_mean_squared_error: 1479563844.6154\n",
      "Epoch 66/100\n",
      "934/934 [==============================] - 0s 358us/step - loss: 1944587319.8287 - mean_squared_error: 1944587319.8287 - val_loss: 1394556012.5812 - val_mean_squared_error: 1394556012.5812\n",
      "Epoch 67/100\n",
      "934/934 [==============================] - 0s 316us/step - loss: 1936024727.4004 - mean_squared_error: 1936024727.4004 - val_loss: 1438134673.5726 - val_mean_squared_error: 1438134673.5726\n",
      "Epoch 68/100\n",
      "934/934 [==============================] - 0s 340us/step - loss: 1928398599.6403 - mean_squared_error: 1928398599.6403 - val_loss: 1525659511.7265 - val_mean_squared_error: 1525659511.7265\n",
      "Epoch 69/100\n",
      "934/934 [==============================] - 0s 323us/step - loss: 1929118027.2377 - mean_squared_error: 1929118027.2377 - val_loss: 1431691936.8205 - val_mean_squared_error: 1431691936.8205\n",
      "Epoch 70/100\n",
      "934/934 [==============================] - 0s 374us/step - loss: 1913085825.4304 - mean_squared_error: 1913085825.4304 - val_loss: 1627261516.9231 - val_mean_squared_error: 1627261516.9231\n",
      "Epoch 71/100\n",
      "934/934 [==============================] - 0s 323us/step - loss: 1959871237.4818 - mean_squared_error: 1959871237.4818 - val_loss: 1498260766.6325 - val_mean_squared_error: 1498260766.6325\n",
      "Epoch 72/100\n",
      "934/934 [==============================] - 0s 328us/step - loss: 1948681739.8287 - mean_squared_error: 1948681739.8287 - val_loss: 1397790689.0256 - val_mean_squared_error: 1397790689.0256\n",
      "Epoch 73/100\n",
      "934/934 [==============================] - 0s 355us/step - loss: 1942542508.8480 - mean_squared_error: 1942542508.8480 - val_loss: 1486713327.4188 - val_mean_squared_error: 1486713327.4188\n",
      "Epoch 74/100\n",
      "934/934 [==============================] - 0s 355us/step - loss: 1937370607.5546 - mean_squared_error: 1937370607.5546 - val_loss: 1392940924.3077 - val_mean_squared_error: 1392940924.3077\n",
      "Epoch 75/100\n",
      "934/934 [==============================] - 0s 302us/step - loss: 1937501585.1221 - mean_squared_error: 1937501585.1221 - val_loss: 1435100482.5983 - val_mean_squared_error: 1435100482.5983\n",
      "Epoch 76/100\n",
      "934/934 [==============================] - 0s 358us/step - loss: 1941322428.7623 - mean_squared_error: 1941322428.7623 - val_loss: 1505269918.5299 - val_mean_squared_error: 1505269918.5299\n",
      "Epoch 77/100\n",
      "934/934 [==============================] - 0s 367us/step - loss: 1939157997.3790 - mean_squared_error: 1939157997.3790 - val_loss: 1570836458.3590 - val_mean_squared_error: 1570836458.3590\n",
      "Epoch 78/100\n",
      "934/934 [==============================] - 0s 294us/step - loss: 1930885077.5760 - mean_squared_error: 1930885077.5760 - val_loss: 1518581674.5641 - val_mean_squared_error: 1518581674.5641\n",
      "Epoch 79/100\n",
      "934/934 [==============================] - 0s 380us/step - loss: 1949496230.8437 - mean_squared_error: 1949496230.8437 - val_loss: 1449396313.4359 - val_mean_squared_error: 1449396313.4359\n",
      "Epoch 80/100\n",
      "934/934 [==============================] - 0s 353us/step - loss: 1930573585.0107 - mean_squared_error: 1930573585.0107 - val_loss: 1393101258.1197 - val_mean_squared_error: 1393101258.1197\n",
      "Epoch 81/100\n",
      "934/934 [==============================] - 0s 278us/step - loss: 1937698829.3105 - mean_squared_error: 1937698829.3105 - val_loss: 1387852431.4530 - val_mean_squared_error: 1387852431.4530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "934/934 [==============================] - 0s 233us/step - loss: 1945442464.2570 - mean_squared_error: 1945442464.2570 - val_loss: 1388513396.4444 - val_mean_squared_error: 1388513396.4444\n",
      "Epoch 83/100\n",
      "934/934 [==============================] - 0s 339us/step - loss: 1934744718.5096 - mean_squared_error: 1934744718.5096 - val_loss: 1452592883.6239 - val_mean_squared_error: 1452592883.6239\n",
      "Epoch 84/100\n",
      "934/934 [==============================] - 0s 384us/step - loss: 1926367935.2034 - mean_squared_error: 1926367935.2034 - val_loss: 1390765213.3333 - val_mean_squared_error: 1390765213.3333\n",
      "Epoch 85/100\n",
      "934/934 [==============================] - 0s 325us/step - loss: 1926199064.3597 - mean_squared_error: 1926199064.3597 - val_loss: 1447783708.1026 - val_mean_squared_error: 1447783708.1026\n",
      "Epoch 86/100\n",
      "934/934 [==============================] - 0s 350us/step - loss: 1924989172.0771 - mean_squared_error: 1924989172.0771 - val_loss: 1458088693.8803 - val_mean_squared_error: 1458088693.8803\n",
      "Epoch 87/100\n",
      "934/934 [==============================] - 0s 264us/step - loss: 1941669672.4283 - mean_squared_error: 1941669672.4283 - val_loss: 1440312278.3590 - val_mean_squared_error: 1440312278.3590\n",
      "Epoch 88/100\n",
      "934/934 [==============================] - 0s 260us/step - loss: 1911729551.3405 - mean_squared_error: 1911729551.3405 - val_loss: 1376823879.9316 - val_mean_squared_error: 1376823879.9316\n",
      "Epoch 89/100\n",
      "934/934 [==============================] - 0s 285us/step - loss: 1928024035.0150 - mean_squared_error: 1928024035.0150 - val_loss: 1461192159.1111 - val_mean_squared_error: 1461192159.1111\n",
      "Epoch 90/100\n",
      "934/934 [==============================] - 0s 267us/step - loss: 1923890047.3405 - mean_squared_error: 1923890047.3405 - val_loss: 1524789832.0684 - val_mean_squared_error: 1524789832.0684\n",
      "Epoch 91/100\n",
      "934/934 [==============================] - 0s 243us/step - loss: 1939161357.6788 - mean_squared_error: 1939161357.6788 - val_loss: 1494650362.9060 - val_mean_squared_error: 1494650362.9060\n",
      "Epoch 92/100\n",
      "934/934 [==============================] - 0s 254us/step - loss: 1921932393.9957 - mean_squared_error: 1921932393.9957 - val_loss: 1389047293.9145 - val_mean_squared_error: 1389047293.9145\n",
      "Epoch 93/100\n",
      "934/934 [==============================] - 0s 272us/step - loss: 1938058372.5653 - mean_squared_error: 1938058372.5653 - val_loss: 1395691694.0171 - val_mean_squared_error: 1395691694.0171\n",
      "Epoch 94/100\n",
      "934/934 [==============================] - 0s 267us/step - loss: 1923077041.2934 - mean_squared_error: 1923077041.2934 - val_loss: 1389361962.1880 - val_mean_squared_error: 1389361962.1880\n",
      "Epoch 95/100\n",
      "934/934 [==============================] - 0s 254us/step - loss: 1925998823.4347 - mean_squared_error: 1925998823.4347 - val_loss: 1467926403.7094 - val_mean_squared_error: 1467926403.7094\n",
      "Epoch 96/100\n",
      "934/934 [==============================] - 0s 261us/step - loss: 1910334551.1092 - mean_squared_error: 1910334551.1092 - val_loss: 1377248655.8632 - val_mean_squared_error: 1377248655.8632\n",
      "Epoch 97/100\n",
      "934/934 [==============================] - 0s 267us/step - loss: 1937566164.8822 - mean_squared_error: 1937566164.8822 - val_loss: 1383757172.8889 - val_mean_squared_error: 1383757172.8889\n",
      "Epoch 98/100\n",
      "934/934 [==============================] - 0s 265us/step - loss: 1926060890.8522 - mean_squared_error: 1926060890.8522 - val_loss: 1387497262.7009 - val_mean_squared_error: 1387497262.7009\n",
      "Epoch 99/100\n",
      "934/934 [==============================] - 0s 275us/step - loss: 1926105468.0086 - mean_squared_error: 1926105468.0086 - val_loss: 1409294826.2564 - val_mean_squared_error: 1409294826.2564\n",
      "Epoch 100/100\n",
      "934/934 [==============================] - 0s 380us/step - loss: 1925502323.5803 - mean_squared_error: 1925502323.5803 - val_loss: 1444891766.6325 - val_mean_squared_error: 1444891766.6325\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_std, y_train, batch_size=4, epochs=100,\n",
    "                   verbose=1, validation_data=(X_val_std, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1402d57b8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3df5xcdX3v8ddnzvza37vZ3UCySUhAQCLKDxcI4lVQ0AQVtCoVpdpebPS2Wm3VK7QWqz76uLa9tdY+UC5aStUrXgSvUgyCKFyoChIgYn5BAglkE5Jsks1u9tf8/N4/vjO7s78nyWw2Z/J+Ph77SObM2TPfM+fM+/s9nznnrDnnEBGR8IvMdQNERKQyFOgiIlVCgS4iUiUU6CIiVUKBLiJSJRToIiJVYk4D3cxuM7O9Zra+jHnfYGZPmVnWzN4z7rkPmdmWws+HZq/FIiLHr7keod8OrCxz3peAPwS+VzrRzOYBnwcuAi4EPm9mLZVroohIOMxpoDvnHgEOlE4zs9PM7Kdm9qSZPWpmryzMu9059wyQH7eYtwI/c84dcM71AD+j/E5CRKRqROe6AZO4Ffioc26LmV0EfB140zTzdwA7Sh53FaaJiJxQjqtAN7N64HXAD8ysODkx069NMk33MxCRE85xFej4EtBB59y5h/E7XcClJY8XAQ9XsE0iIqEw11+KjuGc6wO2mdl7Acw7Z4Zfux94i5m1FL4MfUthmojICWWuT1u8A/g1cKaZdZnZ9cAHgOvN7LfABuDqwrwXmFkX8F7gf5nZBgDn3AHgS8AThZ8vFqaJiJxQTLfPFRGpDsdVyUVERI7cnH0p2tbW5pYuXTpXLy8iEkpPPvnkPudc+2TPzVmgL126lLVr187Vy4uIhJKZvTjVcyq5iIhUCQW6iEiVUKCLiFSJ4+1KURGRaWUyGbq6uhgeHp7rpsyqZDLJokWLiMViZf+OAl1EQqWrq4uGhgaWLl1KyT2fqopzjv3799PV1cWyZcvK/j2VXEQkVIaHh2ltba3aMAcwM1pbWw/7KESBLiKhU81hXnQk6xi6QH929yH+8YFn2defmuumiIgcV0IX6M939/Mvv9jK/v70XDdFRE5ABw8e5Otf//ph/96VV17JwYMHZ6FFo0IX6EHEH4Zk8+P/Ep2IyOybKtBzudy0v7dmzRqam5tnq1lACM9yiRYCPZfXXSJF5Ni74YYbeP755zn33HOJxWLU19ezYMEC1q1bx8aNG3nnO9/Jjh07GB4e5hOf+ASrV68GRm930t/fz6pVq3j961/Pr371Kzo6Ovjxj39MTU3NUbdtxkA3s9uAtwN7nXNnTzPfBcBjwO875+466pZNoThCz+QU6CInui/8xwY27uqr6DKXL2zk8+941ZTPf/nLX2b9+vWsW7eOhx9+mLe97W2sX79+5PTC2267jXnz5jE0NMQFF1zAu9/9blpbW8csY8uWLdxxxx1885vf5JprruHuu+/muuuuO+q2l1NyuR1YOd0MZhYAf8cx+EtB0YhvskboInI8uPDCC8ecK/61r32Nc845hxUrVrBjxw62bNky4XeWLVvGuef6v7T52te+lu3bt1ekLTOO0J1zj5jZ0hlm+zhwN3BBBdo0rWigGrqIeNONpI+Vurq6kf8//PDDPPjgg/z617+mtraWSy+9dNJzyROJxMj/gyBgaGioIm056i9FzawDeBdwSxnzrjaztWa2tru7+4heTzV0EZlLDQ0NHDp0aNLnent7aWlpoba2ls2bN/PYY48d07ZV4kvRrwKfdc7lZjoR3jl3K3ArQGdn5xEl8uhZLgp0ETn2WltbueSSSzj77LOpqanhpJNOGnlu5cqV3HLLLbzmNa/hzDPPZMWKFce0bZUI9E7g+4UwbwOuNLOsc+5HFVj2BMUaelZfiorIHPne97436fREIsF999036XPFOnlbWxvr168fmf7pT3+6Yu066kB3zo18G2BmtwP3zlaYw2gNPacauojIGOWctngHcCnQZmZdwOeBGIBzbsa6eaVFVXIREZlUOWe5XFvuwpxzf3hUrSlDoC9FRUQmFbpL/4s1dF1YJCIyVugCPVANXURkUqEL9Jhq6CIikwpdoKuGLiJz6Uhvnwvw1a9+lcHBwQq3aFToAl3noYvIXDqeAz10t88NdC8XEZlDpbfPveKKK5g/fz533nknqVSKd73rXXzhC19gYGCAa665hq6uLnK5HH/913/Nnj172LVrF5dddhltbW089NBDFW9b6AJd56GLyIj7boDdv6vsMk9+Naz68pRPl94+94EHHuCuu+7iN7/5Dc45rrrqKh555BG6u7tZuHAhP/nJTwB/j5empia+8pWv8NBDD9HW1lbZNheEsORSqKGr5CIic+yBBx7ggQce4LzzzuP8889n8+bNbNmyhVe/+tU8+OCDfPazn+XRRx+lqanpmLQndCN03ZxLREZMM5I+Fpxz3HjjjXzkIx+Z8NyTTz7JmjVruPHGG3nLW97CTTfdNOvtCd0I3cwIIqYauojMidLb5771rW/ltttuo7+/H4CdO3eyd+9edu3aRW1tLddddx2f/vSneeqppyb87mwI3QgdKAS6RugicuyV3j531apVvP/97+fiiy8GoL6+nu9+97ts3bqVz3zmM0QiEWKxGN/4xjcAWL16NatWrWLBggWz8qWoOTc3wdjZ2enWrl17RL/7qpt+yrUXLuFzb19e4VaJyPFu06ZNnHXWWXPdjGNisnU1syedc52TzR+6kgtohC4iMplQBno0iKiGLiIyTigDPYiYLv0XOYHNVan4WDqSdQxloMcipkv/RU5QyWSS/fv3V3WoO+fYv38/yWTysH4vnGe5BBqhi5yoFi1aRFdXF93d3XPdlFmVTCZZtGjRYf1OKAM9GonoS1GRE1QsFmPZsmUzz3gCCmXJRRcWiYhMFMpAj6qGLiIyQTgDXTV0EZEJZgx0M7vNzPaa2fopnv+AmT1T+PmVmZ1T+WaOFaiGLiIyQTkj9NuBldM8vw14o3PuNcCXgFsr0K5pRVVDFxGZYMazXJxzj5jZ0mme/1XJw8eAwzvP5ggEqqGLiExQ6Rr69cB9Uz1pZqvNbK2ZrT2ac0hjqqGLiExQsUA3s8vwgf7ZqeZxzt3qnOt0znW2t7cf8Wuphi4iMlFFLiwys9cA3wJWOef2V2KZ04nqXi4iIhMc9QjdzJYAPwT+wDn33NE3aWZBxMjk9KWoiEipGUfoZnYHcCnQZmZdwOeBGIBz7hbgJqAV+LqZAWSnuvl6pWiELiIyUTlnuVw7w/MfBj5csRaVIRpEFOgiIuOE80pR/cUiEZEJQhno/jx01dBFREqFMtA1QhcRmSicga4Li0REJghnoOvCIhGRCUIZ6Poj0SIiE4Uy0KO6sEhEZIJQBrpG6CIiE4Uy0KOBr6E7p1AXESkKZ6BHDAAN0kVERoUy0INCoKuOLiIyKpSBXhyhq44uIjIqnIEe+GbrXHQRkVHhDHSN0EVEJghloBdr6Nm8augiIkWhDPTiCD2b0whdRKQolIEeqOQiIjJBKAM9pi9FRUQmCGWgj47QVUMXESkKZaBHRy4s0ghdRKQolIGuGrqIyEShDHTV0EVEJpox0M3sNjPba2brp3jezOxrZrbVzJ4xs/Mr38yxVEMXEZmonBH67cDKaZ5fBZxe+FkNfOPomzU9nYcuIjLRjIHunHsEODDNLFcD33beY0CzmS2oVAMnM3qlqAJdRKSoEjX0DmBHyeOuwrQJzGy1ma01s7Xd3d1H/ILRQIEuIjJeJQLdJpk2adI65251znU65zrb29uP+AWjEd9s1dBFREZVItC7gMUljxcBuyqw3CkFqqGLiExQiUC/B/hg4WyXFUCvc+7lCix3Siq5iIhMFJ1pBjO7A7gUaDOzLuDzQAzAOXcLsAa4EtgKDAJ/NFuNLYrqS1ERkQlmDHTn3LUzPO+AP61Yi8qgGrqIyEShvFJUNXQRkYlCGejFGrru5SIiMiqUgV4coWcU6CIiI0IZ6CM19Jxq6CIiReEMdJ22KCIyQTgDXfdDFxGZIJSBrptziYhMFMpAL9bQddqiiMioUAZ6EDHMdGGRiEipUAY6+Dq6Si4iIqNCG+hBxPSlqIhIidAGejQSIaMauojIiNAGuh+hq4YuIlIU2kCPBaqhi4iUCm2gq4YuIjJWaANdNXQRkbFCG+iqoYuIjBXaQI+qhi4iMkZ4A101dBGRMUIb6EEkohG6iEiJ0AZ6NGJk9QcuRERGlBXoZrbSzJ41s61mdsMkzy8xs4fM7Gkze8bMrqx8U8cKdC8XEZExZgx0MwuAm4FVwHLgWjNbPm62zwF3OufOA94HfL3SDR0vFqiGLiJSqpwR+oXAVufcC865NPB94Opx8zigsfD/JmBX5Zo4OY3QRUTGKifQO4AdJY+7CtNK/Q1wnZl1AWuAj0+2IDNbbWZrzWxtd3f3ETR3VDQSUQ1dRKREOYFuk0wbPzS+FrjdObcIuBL4jplNWLZz7lbnXKdzrrO9vf3wW1tCl/6LiIxVTqB3AYtLHi9iYknleuBOAOfcr4Ek0FaJBk5FN+cSERmrnEB/AjjdzJaZWRz/pec94+Z5CXgzgJmdhQ/0o6upzEAjdBGRsWYMdOdcFvgYcD+wCX82ywYz+6KZXVWY7VPAH5vZb4E7gD90zs1q2kZ1YZGIyBjRcmZyzq3Bf9lZOu2mkv9vBC6pbNOmF+jCIhGRMcJ9pahG6CIiI8Ib6LqwSERkjNAGum7OJSIyVmgDXTfnEhEZK7SBrkv/RUTGCm2g6+ZcIiJjhTbQVUMXERkrtIGuP0EnIjJWaAO9eOn/LF+QKiISGqEN9GjE3wRSZRcRES+8gR74pqvsIiLihTfQNUIXERkjtIEeFANdFxeJiAAhDvRooBG6iEip8AZ6RDV0EZFSIQ50jdBFREqFNtCLNfRcToEuIgIhDvRiDT2T15eiIiIQ4kAfGaGr5CIiAoQ40ItfimZVchERAUId6Bqhi4iUKivQzWylmT1rZlvN7IYp5rnGzDaa2QYz+15lmzlRoBq6iMgY0ZlmMLMAuBm4AugCnjCze5xzG0vmOR24EbjEOddjZvNnq8FFGqGLiIxVzgj9QmCrc+4F51wa+D5w9bh5/hi42TnXA+Cc21vZZk6kGrqIyFjlBHoHsKPkcVdhWqkzgDPM7Jdm9piZraxUA6dSPG1RI3QREW/Gkgtgk0wbn6JR4HTgUmAR8KiZne2cOzhmQWargdUAS5YsOezGliqetqgauoiIV84IvQtYXPJ4EbBrknl+7JzLOOe2Ac/iA34M59ytzrlO51xne3v7kbYZKKmhq+QiIgKUF+hPAKeb2TIziwPvA+4ZN8+PgMsAzKwNX4J5oZINHS/QvVxERMaYMdCdc1ngY8D9wCbgTufcBjP7opldVZjtfmC/mW0EHgI+45zbP1uNBojpLxaJiIxRTg0d59waYM24aTeV/N8Bf1H4OSZGR+iqoYuIQBVcKarTFkVEvNAGum7OJSIyVmgDvVhD15eiIiJeaAN9dISuGrqICIQ40Is19Ixq6CIiQIgDXTV0EZGxQhvoIzfnUqCLiABhDvRANXQRkVKhDfTAdOm/iEip0AZ6JGJETBcWiYgUhTbQwdfRNUIXEfHCHeiBqYYuIlIQ6kAPIqYRuohIQagDPRox1dBFRApCHeiBaugiIiNCHejRiGroIiJF4Q70QDV0EZGicAd6xHQvFxGRglAHeqAvRUVERoQ60P2FRaqhi4hA2AM9UMlFRKQo3IGuC4tEREaUFehmttLMnjWzrWZ2wzTzvcfMnJl1Vq6JU1MNXURk1IyBbmYBcDOwClgOXGtmyyeZrwH4M+DxSjdyKqqhi4iMKmeEfiGw1Tn3gnMuDXwfuHqS+b4E/D0wXMH2TSvQaYsiIiPKCfQOYEfJ467CtBFmdh6w2Dl373QLMrPVZrbWzNZ2d3cfdmPH04VFIiKjygl0m2TaSIqaWQT4J+BTMy3IOXerc67TOdfZ3t5efiunoAuLRERGlRPoXcDikseLgF0ljxuAs4GHzWw7sAK451h8MRpEImT0paiICFBeoD8BnG5my8wsDrwPuKf4pHOu1znX5pxb6pxbCjwGXOWcWzsrLS6hm3OJiIyaMdCdc1ngY8D9wCbgTufcBjP7opldNdsNnI5q6CIio6LlzOScWwOsGTftpinmvfTom1Ue1dBFREaF+krRIBLRhUUiIgWhDnR/6b9q6CIiEPJAD3RzLhGREaEO9JhuziUiMiLUgR5EIuRUQxcRAUIe6NHAyKiGLiIChDzQdXMuEZFRoQ501dBFREaFOtCDSATnIK9QFxEJd6BHA38jSNXRRURCHuhBxAe66ugiIiEP9Ggh0FVHFxGpkkDXuegiIiEP9CDwzdcIXUQk5IE+WnLRl6IiIqEO9OKXorqFrohIyAM9FugsFxGRolAHehBRDV1EpCjUga4auojIqFAHumroIiKjQh3oUV0pKiIyoqxAN7OVZvasmW01sxsmef4vzGyjmT1jZj83s1Mq39SJooXz0J/bc4gnth/gl1v38dyeQwyms8fi5UVEjivRmWYwswC4GbgC6AKeMLN7nHMbS2Z7Guh0zg2a2X8D/h74/dlocKm6eADAZ+56ZsJz8+riNNfGaEzGaEhGmd+QpKM5yYLmGha11LC4pZaFzTXEo6E+SBERGTFjoAMXAludcy8AmNn3gauBkUB3zj1UMv9jwHWVbORUzlvSwrc+2EnOOWrjAbEgwp6+Ybp6hth5cIjewQx9wxn6hjJs2dPP3kPDlFZnIgbzG5IsaE6ysLmG1ro4tfEo9YmAQ6ks27oH2LZvgMF0jvmNCU5qSNLWEKepJkZTTYxkLKA/laV/OIsZnLe4hc6lLTTXxnHO0d2f4uWDw/QMpukdytCfytJaF2dBUw0nNSapiQfEAiNixoGBNC/3DrOnb5j+VJZ0Nk8ml6e5NkZHcy2LWmqoS0RxzpHLO4KIkYgGxKMRhjM5dvcNs7t3mHQ2T3tDgpMak9QnohwaztA37Jc3ry7OvLo4scAYSOfY35+idyhDXSJKQzJKQyJGJAKGETH/HYXZaFmrZzBNz0CaZCygpS5OXTwYeb4ScnlHJue/4E7Ggootdy455xjO5EnGIhV9r0QmU06gdwA7Sh53ARdNM//1wH2TPWFmq4HVAEuWLCmziVMLIsbly08qe/5MLs+evmF29gzx0oFBdvQMsevgEC/3DrFxVx89g2kGUlkyOUcsME5prWNZWx118YDu/hRbu/t5fFuKvuHsmLr9+JuEdTTXsK8/RSp7fJ59Ew8ipHMzty1ikIj6Tqc/lWX8VxXxIEIiGiES8R1ApCSw4tEItfGAukSUvHP0DmU4OJghEQ04a0EDyxc0Up+Isml3Hxt39fHSgcExy69PRGmr953ncCbPYCbLcCZPQzJKS22cxmSUTM4xkM4ylM6RzuZJZfOkc3miESMWRIgFRhDxHaaZUZ8ICp1aAqCks8sV5mFkXgPyzjGUzjGUyZF30FDo+JKxgIF0lsFUjnTOd5TFtvYOZdjfn2b/QJruQ6mR/aAuHrB4Xi2LWmppTEZJxCIkooHvoAudtH/PrdBZR6iJR6mNBwyksuwsDFLyzrGgqYYFzUnm1cYx8x2wme8Q8w7MoCYWUBMPqI0H1MQCkrGAROFo1BW2bVON7+BrYgHrd/WydnsP63f2YgYNySj1iejI7xUHD7EgQjwaobDL4xzknCObcyNnm5kZgRnxaISamG9DLu/Y15+i+1CK4WyOtvoE7Q0JGpMxUtk8qWyO4UyeoUyO4bR/X4v7T30i6telsE6l+1np+vcNZTgwkObAYJqmmhjL2vznNxqJ+OkD6TH7RyaX58BAmp7BNHnnaK1LMK8uTjIWoWfQL2s4k6OxJkZLbZz64oDK+W3VXOOrAIlohO7+FC/tH2RX7zDxIEJjMkp9Mjpy4sZIe/GP2+rjzG9MzvgZPFzm3PRfKJrZe4G3Ouc+XHj8B8CFzrmPTzLvdcDHgDc651LTLbezs9OtXbv2iBs+m1LZHIHZSI1+POcc/anRgElEI6SyeX674yBPbD/A1r39zG9M0tFcw4KmJK31cZpq4tQlAvb3j47EhzM5snn/YW6pjbOgKcnJTX5kXfzw9Aym6eoZoqtnkOFMfiQ4c3lHOpcnlckTj0ZY0JTkpMYk8WiE7kPD7D2Uoj+VHSk5FZe1vz/NQDrLvNo4rfUJGpNRhjI5+oYyHEplcc6vX95RCEkflo01MdrqE7TUxUllcvQMpjkwkCGVzfkPdd7hcIX3x//uYDpHfypLxKC51gfeQCrLpt19PLe7n3QuzymttSxf0MjStjqS0YBoYDjn2D+QZl+/P7KpiUWoi/v35NBwloNDafqGssQCozbuP+yjoVN4bwrhns/7YM47H+DFD7aZ0VgTpSEZIxFEcPh58s6NvAdmNhKIZsah4QyHhrOksjnqElHq4lGigbG/P82+/hR9wxmaCyHZWh+nvT5BW0OCppoY3YdSdPUM0tUzxEA6SyqTZziTw8yIRoxI4YOfz/vASBXCDXz4ntyYpKOlBjNjd2/haKyMTvlwndJaSxAxDg37I8/hwvatpGr705HRI/jLaR9942ncsOqVR/R6Zvakc65z0raU8ftdwOKSx4uAXZO8yOXAX1FGmB/vEtHpD/fNjIZkjIaSDjYZC7jo1FYuOrV12t9d0FTD2R1NZbdlXl2c09rry54/LDK5POlsnrpEObvgiSmfdwxlciOd+2TPOXzn44CgMLrP5R3DmRyDhaOL4UyOoXRu5IixOJrvHcrQM5CmP5XljJMaeO0pLbTWJ8a8jnOOTM6NdOyZnO8si503+AFGLIgQDfz4M+cc+bzv1Icyvg0GtDckaK2PE4tE6B3K0N2fom/IH7UlYxGShSOJZMyv71BhQNCfyjKYHl2PfEkPM7L+DhqSMebVxWmpi9EzkGHbvgG27esHoKUuTmtdnHg0QibnjyiigdFSG6elNkYk4sue+/vTpLI5v5zaOMlYUDi6TBcGJ74DdsDBwQw9hekLmpIsnlfLwqYaMrm87xBT2bFtdaOtXtY2O5/pckboUeA54M3ATuAJ4P3OuQ0l85wH3AWsdM5tKeeFj+cRuojI8Wq6EfqMp3g457L4Msr9wCbgTufcBjP7opldVZjtH4B64Admts7M7qlQ20VEpExlHe8659YAa8ZNu6nk/5dXuF3TNcYfM1bSno3w1LeheQlc9FGI6FRGOUH074X//Cq85hpYeO5ct0aOUvgKmC88DPd+EhavgMUXQsdrIZoEHFgEGhdComH6ZaQHYN8W2LsJfvs92PYIRKKQz8LWB+H3vgl109TCnfO/8/wvIDPof2J1cMH10H7m6HzZlH+NtjMgXuunZYZg/Q/hufvgrKvh1e858g5quM+3wyJw+hUQxEafy+chn4FoYurfz2Wg50VoPW3qNmz9OfziS3Dm2+CST0A0PnO7DrwAQQKaOg5vfcC/ty4PkXHfY+Rz0L0Z2l858blqlU3DL//Z7zsXffTo1zubHrv9+nbBt6+Gfc/B47fAxX8Cl/7l6L56JNKD/jO06T8g3Q9LXw/L3gDzX3V8DZRyWf95j1X+TJO5NGMNfbYccQ19x2/8Tr7jcRjonnye2lZoPsWHmcv7MMgO+yBPD8DA3tF5mxbDBR+G8z8IG38E930W6trhTZ+DhgVQOw8SjRDE/U/Xb+DRf4SdT0IkBol6iNXC4AH/GsuvgrPf43fqjT+G4YN+vo7zofUVsPknflqiCVK9cNqb4W3/CC1LoX8PHHzJv17LKRCrGW1nLgs922HvBtizAbb/EnY85ndK8G09/0O+Q9n6IDx3v1/Xc34fVvzJaEeT6oddT8P6u337hg7AvFPh3A/AOe+Dxg4f7sN98MBf+SOX2jYY3Afzl8M7vuY7gO7N/iefg3idb+uup+HZ+3xAgO9sz7oKlv4X39HWz4ehHt++LQ9A6pB/3Ve+zXeoz/8CHv4fsGsdXPQReMOnoabFv9f3/jm8/Fu/XS/+GJz3Af+65cim4NBuv6xk4/TzOgd71vv1GO6FM1fBkosn72CK27xp0cydci7jO7oD2+Ck5f5ocDr7tsLd18PL6/zjxSvgXbfAvGUwsB+eXQM92/y+F6/3+8srroBg3Bgtl/Hb+fFboGut3z8v+aTfx//9Hf4z9O5v+eU99W3//l7+N7D8naMBPHTQfzZaT4dTXjdxXTPDsPVn8Lu7/HbNDELNPKhp9usMUH+SX+bZ74ZFF1Q23PM533nE6iauf6n0QKGzudd/PlJ9/vPfehosWeH3uZqWmV8vl/Gf03mnVr5aUIbpaujhC/Qi5/zOsvt3PtQs4sO7d4f/0Bx8yU+PBP65aLKw89f6jdh2hg+5tjPGflh3rYMffMiH51SaT4HXfxLOef9oDz+wHx77OvzmVr+jxGrhlW+HV1wOezfCi7/y/77ict+BLLkY1t4GP/8i5FJgAWSHxr5Ow0LftuFev8wii/gRz+mX++UN98Haf/WjaRwkm/yHO5qE3/3AL3/+cn94PbjPLyNWC2de6T9cm++F7Y/66ZGY/yDm0j5wX/dxP2p74SH4yaegb+fU70sk6kdkZ17pPzwbfzwaSODX0eV9G+vm+w6yr8t3Ro0LfXA3LoLFF8CGH/n1OPWNsPEeHwgrPgqb1/hONV5f8uEzaFwALct8UKb64OAOvy/07RpdZ/Ad58mv9vPWz/fBlkv7I5We7X6g0LvDLzOI+efq2qGj0y938AAM7vfLdIXTBuvaYfFFvtOO1xf2RQcHX4T9z8OB5/2+mi+5JcX8V40eVfXuhEO7/PtRN993VE9/xw9IrvoXP+pd8xlwOVhwDrz068Jrm38vS/eXzv8Kp70J9vzOB/jWB+HQyzDvND9SXv9DP5CI1/vtcd3d/v0G2Pao38b7nvVHQq/7uP88rPseZAb8PB2d/kitrh12PTX6Gqk+3/Evv9p3Gqe83odrb5c/inx2DTz3gN8XGxbCK97k990lF/t9MZrw6++cX6fBA/4odtO9fpt0nO/3q2Vv8AOarT/3yx3c5zuQopp5frsuPB/Oejucepnfnk98C9bdAelDfr8580q/rxv0xqkAAAddSURBVOx/3g9AXl7n97fX/Zl/D838QCCf9Z+jaMIPCp7+jl/OwF6/LS7+GLzqXWOPjovyOd9h9u3yn5vuzb7tezbCue/3GXIEqjPQZ1M25T/cg/v9T+qQ75VzaR8sZ1459Uhg6KDf0RdfVN4Isncn/Opr/sM1rxBIw31+9HVgm58n2eRHls1LfDC3v3Lyw+Ke7XBojx8ZF9s3sA/W/psfzTd2+EBrOwNOu2xs+w684EelA91+FJ1NQef1ox928O164ps+9Ocv9x1irMaPjtIDfvk1zWPbdPAl2L3eB1bfLojW+I7o5HMAB1t+5pfZ86IfIZ3/Qf/h2b0eHvgcbPt/cOFH4LK/HB1dv/Q4PPN930bwH7renf4969vpw6ppsR85N3X4AGk42X8Id6/3g4DeHX57Flng5z/pbD8qP+OtPmi2/sx3KN2bfRDUtPijtrr5Pjgs4juilx7zr18qWuNHca2n+ve87UxoXuznf+5+38njoP5k36Hl0v79H9gHy/4LXH2znw4+GH/yKd9RnbkKznqHD5RsygfaS4/59/H5X4y+fk2LH9l3/pHv4CMRvw2fvB2e+ym89W9h4Xlj25zPwYb/C4/8g1/nIA6vfq/fF15e5/fV0sFO4yLf6Z79blj2xulHyMN9fh979ie+dDrcO/W8RU1LYOkl/sj8wPOj05NNcOqlfjsnGvy2Kh59H9oNL/7SLz9I+E4kiPsjhPOug1MumdjO3b+DX/yt70SmYwGcsRKWXARPf9d3BjXz/D6XHfbbI5f25c7SDryo+RQ46VX+PT3792Ze/8maoECXUJqqnj6dXMYfKcx0KOycH1X2d/vRVWPH9GFUjmLHn/cXBFHbOn1pIT1YKOWNe92j+eJ/3xYfTgvOObqSQD7vjwRaXwENJVdj53O+rAJ+FNxQ/pXaY+SyvmPb/UxJEGYK7TV/5HvqZf5oqrgO3c/5oJ6/fOygZdLlZ2D7f/qOs74dzvug/3cmO56AF//TdwSxpA/wXNq3MZr0HWnDyYX3Iu+PTjb80Lc5migcacT8PhjE/ZFMY4c/gmx9xczf75VBgS4iUiWO6jx0EREJBwW6iEiVUKCLiFQJBbqISJVQoIuIVAkFuohIlVCgi4hUCQW6iEiVmLMLi8ysG3jxCH+9Ddg341zV50Rc7xNxneHEXO8TcZ3h8Nf7FOfcpJe9zlmgHw0zWzvVlVLV7ERc7xNxneHEXO8TcZ2hsuutkouISJVQoIuIVImwBvqtc92AOXIirveJuM5wYq73ibjOUMH1DmUNXUREJgrrCF1ERMZRoIuIVInQBbqZrTSzZ81sq5ndMNftmQ1mttjMHjKzTWa2wcw+UZg+z8x+ZmZbCv+W8Rdtw8fMAjN72szuLTxeZmaPF9b7/5hZfKZlhImZNZvZXWa2ubDNLz4RtrWZ/Xlh/15vZneYWbIat7WZ3WZme81sfcm0SbeveV8r5NszZnb+4bxWqALdzALgZmAVsBy41syWz22rZkUW+JRz7ixgBfCnhfW8Afi5c+504OeFx9XoE8Cmksd/B/xTYb17gOvnpFWz55+BnzrnXgmcg1/3qt7WZtYB/BnQ6Zw7GwiA91Gd2/p2YOW4aVNt31XA6YWf1cA3DueFQhXowIXAVufcC865NPB94Oo5blPFOededs49Vfj/IfwHvAO/rv9emO3fgXfOTQtnj5ktAt4GfKvw2IA3AXcVZqmq9TazRuANwL8COOfSzrmDnADbGogCNWYWBWqBl6nCbe2cewQ4MG7yVNv3auDbznsMaDazBeW+VtgCvQPYUfK4qzCtapnZUuA84HHgJOfcy+BDH5g/dy2bNV8F/juQLzxuBQ4654p/Qr3atvmpQDfwb4Uy07fMrI4q39bOuZ3A/wRewgd5L/Ak1b2tS021fY8q48IW6JP9CfOqPe/SzOqBu4FPOuf65ro9s83M3g7sdc49WTp5klmraZtHgfOBbzjnzgMGqLLyymQKNeOrgWXAQqAOX24Yr5q2dTmOan8PW6B3AYtLHi8Cds1RW2aVmcXwYf6/nXM/LEzeUzz8Kvy7d67aN0suAa4ys+34ctqb8CP25sJhOVTfNu8Cupxzjxce34UP+Grf1pcD25xz3c65DPBD4HVU97YuNdX2PaqMC1ugPwGcXvgmPI7/EuWeOW5TxRXqxv8KbHLOfaXkqXuADxX+/yHgx8e6bbPJOXejc26Rc24pftv+wjn3AeAh4D2F2apqvZ1zu4EdZnZmYdKbgY1U+bbGl1pWmFltYX8vrnfVbutxptq+9wAfLJztsgLoLZZmyuKcC9UPcCXwHPA88Fdz3Z5ZWsfX4w+zngHWFX6uxNeTfw5sKfw7b67bOovvwaXAvYX/nwr8BtgK/ABIzHX7Kryu5wJrC9v7R0DLibCtgS8Am4H1wHeARDVua+AO/PcEGfwI/Pqpti++5HJzId9+hz8LqOzX0qX/IiJVImwlFxERmYICXUSkSijQRUSqhAJdRKRKKNBFRKqEAl1EpEoo0EVEqsT/Bw+QoH8Rcth3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['mean_squared_error'],label='train')\n",
    "plt.plot(history.history['val_mean_squared_error'], label='test')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "934/934 [==============================] - 1s 538us/step - loss: 29700164660.6253 - mean_squared_error: 29700164660.6253\n",
      "Epoch 2/10\n",
      "934/934 [==============================] - 0s 286us/step - loss: 2518846072.0857 - mean_squared_error: 2518846072.0857\n",
      "Epoch 3/10\n",
      "934/934 [==============================] - 0s 258us/step - loss: 2096293544.2355 - mean_squared_error: 2096293544.2355\n",
      "Epoch 4/10\n",
      "934/934 [==============================] - 0s 256us/step - loss: 2080969206.5096 - mean_squared_error: 2080969206.5096\n",
      "Epoch 5/10\n",
      "934/934 [==============================] - 0s 249us/step - loss: 2083066061.0193 - mean_squared_error: 2083066061.0193\n",
      "Epoch 6/10\n",
      "934/934 [==============================] - 0s 252us/step - loss: 2077859416.6938 - mean_squared_error: 2077859416.6938\n",
      "Epoch 7/10\n",
      "934/934 [==============================] - 0s 255us/step - loss: 2118327731.5974 - mean_squared_error: 2118327731.5974\n",
      "Epoch 8/10\n",
      "934/934 [==============================] - 0s 261us/step - loss: 2075632000.7794 - mean_squared_error: 2075632000.7794\n",
      "Epoch 9/10\n",
      "934/934 [==============================] - 0s 290us/step - loss: 2072164782.7880 - mean_squared_error: 2072164782.7880\n",
      "Epoch 10/10\n",
      "934/934 [==============================] - 0s 308us/step - loss: 2077602048.3940 - mean_squared_error: 2077602048.3940\n"
     ]
    }
   ],
   "source": [
    "#Kerasパッケージの使用\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(2, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.01),\n",
    "             metrics=['mse'])\n",
    "history = model.fit(X_train_std, y_train, batch_size=4, epochs=10,\n",
    "                   verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x142290160>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mean_squared_error'],label='train')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題6 MNISTでKerasを学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(60000, 28, 28, 1)\n",
      "(60000,)\n",
      "(60000, 10)\n",
      "float32\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max())\n",
    "print(X_train.min())\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_train = X_train[:, :, :, np.newaxis]\n",
    "X_test = X_test[:, :, :, np.newaxis]\n",
    "print(X_train.shape)\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=10)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64\n",
    "print(type(y_train_one_hot))\n",
    "\n",
    "\n",
    "X_train, X_val, y_train_one_hot,y_val_one_hot = \\\n",
    "train_test_split(X_train, y_train_one_hot,\n",
    "                                                 test_size=0.2)\n",
    "\n",
    "y_train_one_hot = y_train_one_hot[:, np.newaxis, np.newaxis, :]\n",
    "y_test_one_hot = y_test_one_hot[:, np.newaxis, np.newaxis, :]\n",
    "y_val_one_hot = y_val_one_hot[:, np.newaxis, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(28,28,1))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(6, (5,5),padding='SAME',\n",
    "                           activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, (5,5), padding='VALID',\n",
    "                          activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(120, (5,5), padding='VALID', \n",
    "                          activation=tf.nn.relu)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(84, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(10, activation=tf.nn.softmax)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 1, 84)          10164     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 1, 10)          850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 12s 256us/sample - loss: 0.4954 - acc: 0.8335 - val_loss: 0.1010 - val_acc: 0.9688\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 12s 253us/sample - loss: 0.0836 - acc: 0.9746 - val_loss: 0.0734 - val_acc: 0.9781\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 12s 258us/sample - loss: 0.0546 - acc: 0.9832 - val_loss: 0.0536 - val_acc: 0.9818\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 13s 273us/sample - loss: 0.0408 - acc: 0.9872 - val_loss: 0.0587 - val_acc: 0.9811\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 14s 283us/sample - loss: 0.0316 - acc: 0.9896 - val_loss: 0.0426 - val_acc: 0.9872\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 14s 292us/sample - loss: 0.0270 - acc: 0.9912 - val_loss: 0.0482 - val_acc: 0.9862\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 14s 294us/sample - loss: 0.0229 - acc: 0.9927 - val_loss: 0.0475 - val_acc: 0.9862\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 14s 300us/sample - loss: 0.0199 - acc: 0.9934 - val_loss: 0.0495 - val_acc: 0.9851\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 14s 298us/sample - loss: 0.0180 - acc: 0.9942 - val_loss: 0.0416 - val_acc: 0.9883\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 15s 304us/sample - loss: 0.0137 - acc: 0.9956 - val_loss: 0.0448 - val_acc: 0.9883\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 14s 301us/sample - loss: 0.0128 - acc: 0.9958 - val_loss: 0.0456 - val_acc: 0.9878\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0165 - acc: 0.9944 - val_loss: 0.0493 - val_acc: 0.9869\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 15s 307us/sample - loss: 0.0174 - acc: 0.9939 - val_loss: 0.0665 - val_acc: 0.9845\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 15s 309us/sample - loss: 0.0132 - acc: 0.9953 - val_loss: 0.0423 - val_acc: 0.9892\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 16s 326us/sample - loss: 0.0121 - acc: 0.9955 - val_loss: 0.0485 - val_acc: 0.9887\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 15s 315us/sample - loss: 0.0091 - acc: 0.9967 - val_loss: 0.0549 - val_acc: 0.9887\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 15s 308us/sample - loss: 0.0080 - acc: 0.9972 - val_loss: 0.0643 - val_acc: 0.9874\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 15s 320us/sample - loss: 0.0122 - acc: 0.9961 - val_loss: 0.0651 - val_acc: 0.9885\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 15s 308us/sample - loss: 0.0087 - acc: 0.9970 - val_loss: 0.0572 - val_acc: 0.9894\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 14s 299us/sample - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0592 - val_acc: 0.9888\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer = tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train_one_hot, verbose=1,\n",
    "                    validation_data =(X_val,y_val_one_hot),\n",
    "                   batch_size=1000, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  0.006391601896663578\n",
      "train acc:  0.9978125\n",
      "test loss:  0.057867146629622286\n",
      "test acc:  0.9881\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train_one_hot, verbose=0)\n",
    "print('train loss: ', score[0])\n",
    "print('train acc: ', score[1])\n",
    "score = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
    "print('test loss: ', score[0])\n",
    "print('test acc: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x142caa6a0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label = 'train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本課題範囲ここまで"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題7 PyTorchへの書き換え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-aa86f1a2107c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                   \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1307\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.3081\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m               ])),\n\u001b[0;32m----> 8\u001b[0;31m     batch_size = args.batch_size, shuffle=True, **kwargs)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m test_loader = torch.utils.data.DataLoader(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "torchvision.datasets.MNIST('../data', train=True,\n",
    "              download=True, transform =\\\n",
    "                           transforms.Compose([\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize((0.1307,), (0.3081,))\n",
    "              ])),\n",
    "    batch_size = args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "datasets.MNIST('../data', train=False, transform=\\\n",
    "               transforms.Compose([\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize((0.1307,), (0.3081,))\n",
    "              ])),\n",
    "    batch_size = args.batch_size, shuffle=True, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1632e+33, 5.6003e-02],\n",
      "        [7.0374e+22, 2.7556e-40]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(2,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = [[1, 2, 3], [4, 5, 6]]\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.Tensor(list)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6897, 0.7909],\n",
       "        [0.7640, 0.5116]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3344, -0.0547],\n",
       "        [ 0.7391, -0.8190]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.2039e-45],\n",
       "        [0.0000e+00],\n",
       "        [9.5584e-31],\n",
       "        [1.4013e-45]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,  10.,  20.,  30.,  40.,  50.,  60.,  70.,  80.,  90., 100.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0,100,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [1., 1.]])\n",
      "tensor([[3., 2.],\n",
      "        [1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[2,2], [1,1]])\n",
    "y = torch.Tensor([[3, 2], [1,2]])\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 4.],\n",
      "        [2., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 4.],\n",
      "        [2., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 4.],\n",
      "        [1., 2.]])\n",
      "tensor([[6., 4.],\n",
      "        [1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "print(x * y)\n",
    "print(torch.mul(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8., 8.],\n",
      "        [4., 4.]])\n"
     ]
    }
   ],
   "source": [
    "#行列積\n",
    "print(torch.mm(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5774)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(df_house.loc[:,['GrLivArea', 'YearBuilt']])\n",
    "y = np.array(df_house.loc[:, 'SalePrice']).reshape(-1,1)\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y,random_state=0,\n",
    "                                                  test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,\n",
    "                                                 random_state=0, test_size=0.2)\n",
    "sr = StandardScaler()\n",
    "X_train_std = sr.fit_transform(X_train)\n",
    "X_test_std = sr.transform(X_test)\n",
    "X_val_std = sr.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#線形回帰\n",
    "model = torch.nn.Linear(2,1)\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Trainer(X,y, model, epochs=2000):\n",
    "    for epoch in range(epochs):\n",
    "        inputs = torch.from_numpy(X.astype(np.float32))\n",
    "        #inputs = torch.float(inputs)\n",
    "        \n",
    "        targets = torch.from_numpy(y.astype(np.float32))\n",
    "        #targets = torch.float(targets)\n",
    "        \n",
    "        #誤差の算出\n",
    "        outputs = model(inputs)\n",
    "        cost = loss(outputs, targets)\n",
    "        \n",
    "        #Backprop\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 1000,\n",
    "                                                       cost.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 2104096256.0000\n",
      "Epoch [200/1000], Loss: 2104096256.0000\n",
      "Epoch [300/1000], Loss: 2104096256.0000\n",
      "Epoch [400/1000], Loss: 2104096256.0000\n",
      "Epoch [500/1000], Loss: 2104096256.0000\n",
      "Epoch [600/1000], Loss: 2104096256.0000\n",
      "Epoch [700/1000], Loss: 2104096256.0000\n",
      "Epoch [800/1000], Loss: 2104096256.0000\n",
      "Epoch [900/1000], Loss: 2104096256.0000\n",
      "Epoch [1000/1000], Loss: 2104096256.0000\n",
      "Epoch [1100/1000], Loss: 2104096256.0000\n",
      "Epoch [1200/1000], Loss: 2104096256.0000\n",
      "Epoch [1300/1000], Loss: 2104096256.0000\n",
      "Epoch [1400/1000], Loss: 2104096256.0000\n",
      "Epoch [1500/1000], Loss: 2104096256.0000\n",
      "Epoch [1600/1000], Loss: 2104096256.0000\n",
      "Epoch [1700/1000], Loss: 2104096256.0000\n",
      "Epoch [1800/1000], Loss: 2104096256.0000\n",
      "Epoch [1900/1000], Loss: 2104096256.0000\n",
      "Epoch [2000/1000], Loss: 2104096256.0000\n"
     ]
    }
   ],
   "source": [
    "Trainer(X_train_std, y_train, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1108 1930]\n",
      " [1964 1911]\n",
      " [1506 2008]\n",
      " ...\n",
      " [1601 1958]\n",
      " [2098 2005]\n",
      " [1368 2005]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
