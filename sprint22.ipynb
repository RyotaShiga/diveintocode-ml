{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 1, 5, 3], [2, 1, 6, 4], [7, 1, 3, 8, 4]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text \n",
    "texts = [\"I have a pen.\", \"I have an apple\", \"You have pen and apple.\"]\n",
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "list_tokenized = tokenizer.texts_to_sequences(texts)\n",
    "print(list_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題1 SimpleRNNのフォワードプロパゲーション実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class ScratchSimpleRNNClassifier:\n",
    "    \n",
    "    def __init__(self, batch_size, n_features, n_nodes):\n",
    "        self.batch_size = batch_size\n",
    "        self.n_features = n_features\n",
    "        self.n_nodes = n_nodes\n",
    "        self.initializer_Wx = Initializer(self.n_features, self.n_nodes)\n",
    "        self.initializer_Wh = Initializer(self.n_nodes, self.n_nodes)\n",
    "        self.optimizer = SGD(lr=0.001)\n",
    "        \n",
    "#         self.Wx = self.initializer_Wx.W()\n",
    "#         self.Wb = self.initializer_Wx.B()\n",
    "#         self.Wh = self.initializer_Wh.W()\n",
    "        self.Wx = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n",
    "        self.Wh = np.array([[1, 3, 5, 7], [2, 4, 6, 8],\n",
    "                        [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n",
    "        self.Wb = np.array([1., 1., 1., 1.])\n",
    "        self.t = 0\n",
    "        self.h_list = []\n",
    "        self.at_list = []\n",
    "        self.X = []\n",
    "        self.dX=[]\n",
    "        self.params = {}\n",
    "        self.grads = {}\n",
    "        self.params['Wx'] = self.Wx\n",
    "        self.grads['Wx'] = np.zeros_like(self.Wx)\n",
    "        self.params['Wb'] = self.Wb\n",
    "        self.grads['Wb'] = np.zeros_like(self.Wb)\n",
    "        self.params['Wh'] = self.Wh\n",
    "        self.grads['Wh'] = np.zeros_like(self.Wh)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, xt, h):\n",
    "        self.t += 1\n",
    "        \n",
    "        Wx = self.params['Wx']\n",
    "        Wh = self.params['Wh']\n",
    "        Wb = self.params['Wb']\n",
    "        \n",
    "        \n",
    "        if len(self.h_list) == 0:\n",
    "            self.h_list.append(h)\n",
    "        #(N, D)dot(D,H) + (N,H)dot(H,H) + (H,) = (N,H)\n",
    "        at = np.dot(xt, Wx) + np.dot(h, Wh) + Wb\n",
    "        new_h = np.tanh(at)\n",
    "        \n",
    "        self.X.append(xt)\n",
    "        self.at_list.append(at)\n",
    "        self.h_list.append(new_h)\n",
    "        return new_h\n",
    "    \n",
    "    def backward(self, dout, dh):\n",
    "        \n",
    "        xt = self.X[self.t-1]\n",
    "        ht = self.h_list[self.t-1]\n",
    "        at = self.at_list[self.t-1]\n",
    "        \n",
    "        dout = dout + dh\n",
    "        dA = dout * (1. - np.tanh(at)**2)\n",
    "        dWb = np.sum(dA, axis=0)\n",
    "        #(D,H) = (D,N)dot(N,H)\n",
    "        dWx = np.dot(xt.T, dA)\n",
    "        #(H,H)= (H,N)dot(N,H)\n",
    "        dWh = np.dot(ht.T, dA)\n",
    "        #(N,D) = (N,H)dot(H,D)\n",
    "        dxt = np.dot(dA, self.Wx.T)\n",
    "        #(N,H)=(N,H)dot(H,H)\n",
    "        dht = np.dot(dA, self.Wh.T)\n",
    "        \n",
    "        self.grads['Wx'] = dWx\n",
    "        self.grads['Wh'] = dWh\n",
    "        self.grads['Wb'] = dWb\n",
    "        \n",
    "        self.optimizer.update(self)\n",
    "        \n",
    "        self.dX.append(dxt)\n",
    "        \n",
    "        return dht\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Initializer:\n",
    "    def __init__(self, n_nodes1, n_nodes2):\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        \n",
    "    def W(self):\n",
    "        W = np.random.randn(self.n_nodes1, self.n_nodes2) * 0.01\n",
    "        return W\n",
    "    \n",
    "    def B(self):\n",
    "        B = np.random.randn(self.n_nodes2, )\n",
    "        return B\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        self.params = layer.params\n",
    "        self.grads = layer.grads\n",
    "        \n",
    "        for key in self.params.keys():\n",
    "            self.params[key] -= self.lr * self.grads[key]\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題2 小さな配列でのフォワードプロパゲーションの実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100\n",
    "print(x.shape)\n",
    "\n",
    "rnn = ScratchSimpleRNNClassifier(batch_size=x.shape[0],\n",
    "                                 n_features=x.shape[2], n_nodes=4)\n",
    "\n",
    "h = np.zeros((x.shape[0], 4)) # (batch_size, n_nodes)\n",
    "for t in range(x.shape[1]):\n",
    "    xt = x[:, t, :]\n",
    "    h = rnn.forward(xt, h)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79494228 0.81839002 0.83939649 0.85584174]]\n"
     ]
    }
   ],
   "source": [
    "print(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題3 バックプロパゲーションの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., 0.]]),\n",
       " array([[0.76188798, 0.76213958, 0.76239095, 0.76255841]]),\n",
       " array([[0.792209  , 0.8141834 , 0.83404912, 0.84977719]]),\n",
       " array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]])]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.h_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.01, 0.02]]), array([[0.02, 0.03]]), array([[0.03, 0.04]])]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.0007, 1.0013, 1.0019, 1.0023]]),\n",
       " array([[1.07733574, 1.13931527, 1.20129481, 1.25535044]]),\n",
       " array([[1.08471832, 1.15192269, 1.21912707, 1.27759095]])]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.at_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dX = []\n",
    "dh = np.ones((1, 3, 4))\n",
    "dh_prev = 0\n",
    "for idx, t in enumerate(np.flip(np.arange(rnn.t))):\n",
    "    dh_prev = rnn.backward(dh[:, t, :], dh_prev)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04998308 0.06343091 0.07396354 0.09033399]]\n"
     ]
    }
   ],
   "source": [
    "print(dh_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.04708592, 0.06963563]]), array([[0.05045678, 0.07438174]]), array([[0.05065903, 0.07466772]])]\n"
     ]
    }
   ],
   "source": [
    "print(rnn.dX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, batch_size, n_features, n_nodes):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time=tごとにRNNを生成する\n",
    "\n",
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh),\n",
    "                      np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
    "        h_next = np.tanh(t)\n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "    \n",
    "    #dh_nextとdh[:,t,:]をすでに合算した状態でbackwardに流す\n",
    "    def backward(self, dh_next):\n",
    "        x, h_prev, h_next = self.cache\n",
    "        dt = h_next * (1 - np.tanh(h_next)**2)\n",
    "        db = np.sum(dt, axis=0)\n",
    "        dWx = np.dot(x.T, dt)\n",
    "        dWh = np.dot(h_prev.T, dt)\n",
    "        dx = np.dot(dt, dWx.T)\n",
    "        dh_prev = np.dot(dt, Wh.T)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        return dx, dh_prev\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.76188798 0.76213958 0.76239095 0.76255841]]\n"
     ]
    }
   ],
   "source": [
    "#テスト\n",
    "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_features)\n",
    "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n",
    "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n",
    "batch_size = x.shape[0] # 1\n",
    "n_sequences = x.shape[1] # 3\n",
    "n_features = x.shape[2] # 2\n",
    "n_nodes = w_x.shape[1] # 4\n",
    "h = np.zeros((batch_size, n_nodes)) # (batch_size, n_nodes)\n",
    "b = np.array([1., 1., 1., 1.]) # (n_nodes,)\n",
    "\n",
    "rnn_model = RNN(w_x, w_h, b)\n",
    "\n",
    "\n",
    "h = rnn_model.forward(x[:, 0, :], h)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#正解\n",
    "array([[0.76188798, 0.76213958, 0.76239095, 0.76255841]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh),\n",
    "                      np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        self.h, self.dh = None\n",
    "        \n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "        \n",
    "        \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wh.shape\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N,H), dtype='f')\n",
    "            \n",
    "            \n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h)\n",
    "            hs[:,t,:] = self.h\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return hs#次の層に渡すh\n",
    "    \n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = dhs\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = []\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
